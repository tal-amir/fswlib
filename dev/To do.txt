Now:
    - Create example_graph.py script with an example of using FSWEmbedding in graph mode
    - Create example_training.py, where a simple module of embed+MLP will be created and trained to distinguish
      spheres and simplices of different radii and randomly-rotated.
      Show the use of learnable_slices and learnable_frequencies.
    - Create example_sliced_wasserstein.py, where the SW distance will be approximated with different embedding
      dimensions, and for each dimension, the STD will be estimated.
      Show the difference between optimized and unoptimized embedding parameters.

    v - Replace string enums by Enum or Literal
    v - Settle the issue on how modules' extra parameters (e.g. some boolean fields of the class) are saved and loaded.
    v - For each constructor input argument, think carefully of its name and default value.
    v - For each field, decide whether to expose it as a property or hide it
    v - Check whether the .to() code is inherited properly, and whether .reset_parameters() should also be inherited, and
        whether its implementation is ok.

Later:
    - Read and improve all the generated HTML documentation:
      1. Add 'see also' where applicable, especially in the definitions of Enum values, or where these values are
         provided as input arguments.
      2. Add some missing references to equations in the paper, e.g. in different Enum options for the total mass encoding
         method and function
      3. Test pdoc's math support. Add math in the relevant places (e.g. total mass encoding methods)
    - Make the "create dummy bins" command available standalone
    - Add that dummy creation command and a cleanup to the prepare_for_upload script
    - Create examples and tests

Later-later:
    - Convert the PyTorch sparce tensors to manual (inds,vals) pairs
    - Use full type hinting all over the code
    - Fix the memory waste thing

Fix pycharm's undos - make them less aggressive
