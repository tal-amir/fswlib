<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.3"/>
    <title>fswlibfswlib documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style><script>
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
    };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    /* Re-invoke MathJax when DOM content changes, for example during search. */
    document.addEventListener("DOMContentLoaded", () => {
        new MutationObserver(() => MathJax.typeset()).observe(
            document.querySelector("main.pdoc").parentNode,
            {childList: true}
        );
    })
</script>
<style>
    mjx-container {
        overflow-x: auto;
        overflow-y: hidden;
    }
</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>
            <img src="logo.png" class="logo" alt="project logo"/>

            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>

            <h2>Contents</h2>
            <ul>
  <li><a href="#fswlib-a-pytorch-library-for-the-fourier-sliced-wasserstein-fsw-embedding">fswlib: A PyTorch Library for the Fourier Sliced-Wasserstein (FSW) Embedding</a>
  <ul>
    <li><a href="#requirements">üì¶ Requirements</a></li>
    <li><a href="#installation">üîß Installation</a></li>
    <li><a href="#usage-example">üìò Usage Example</a></li>
    <li><a href="#citation">üìÑ Citation</a></li>
    <li><a href="#links">üîó Links</a></li>
    <li><a href="#maintainer">üë®üèª‚Äçüîß Maintainer</a></li>
  </ul></li>
</ul>



        <h2>fswlib documentation</h2>
            <ul class="memberlist">

            <li>
                    <a class="class" href="#FSWEmbedding">FSWEmbedding</a>
                            <ul class="memberlist">

                        <li>
                                <a class="function" href="#FSWEmbedding.__init__">FSWEmbedding</a>
                        </li>
                        <li>
                                <a class="function" href="#FSWEmbedding.from_config">from_config</a>
                        </li>
                        <li>
                                <a class="function" href="#FSWEmbedding.reset_parameters">reset_parameters</a>
                        </li>
                        <li>
                                <a class="function" href="#FSWEmbedding.to">to</a>
                        </li>
                        <li>
                                <a class="function" href="#FSWEmbedding.forward">forward</a>
                        </li>


                        <li>
                            <a class="method" href="#FSWEmbedding.slice_vectors">slice_vectors</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.frequencies">frequencies</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.bias">bias</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.num_slices">num_slices</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.num_frequencies">num_frequencies</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.cartesian_mode">cartesian_mode</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.flatten_cartesian_axes">flatten_cartesian_axes</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.learnable_slices">learnable_slices</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.learnable_frequencies">learnable_frequencies</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.enable_bias">enable_bias</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.encode_total_mass">encode_total_mass</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.total_mass_encoding_transformation">total_mass_encoding_transformation</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.total_mass_encoding_method">total_mass_encoding_method</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.total_mass_encoding_scale">total_mass_encoding_scale</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.total_mass_padding_thresh">total_mass_padding_thresh</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.d_in">d_in</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.d_out">d_out</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.device">device</a>
                        </li>
                        <li>
                            <a class="method" href="#FSWEmbedding.dtype">dtype</a>
                        </li>

                </ul>

            </li>
            <li>
                    <a class="class" href="#FSWCustomCudaExtensionLoadWarning">FSWCustomCudaExtensionLoadWarning</a>
                            <ul class="memberlist">




                </ul>

            </li>
            <li>
                    <a class="class" href="#FSWCustomCudaExtensionLoadError">FSWCustomCudaExtensionLoadError</a>
                            <ul class="memberlist">




                </ul>

            </li>
            <li>
                    <a class="class" href="#EnumWithResolve">EnumWithResolve</a>
                            <ul class="memberlist">

                        <li>
                                <a class="function" href="#EnumWithResolve.resolve">resolve</a>
                        </li>



                </ul>

            </li>
            <li>
                    <a class="class" href="#TotalMassEncodingTransformation">TotalMassEncodingTransformation</a>
                            <ul class="memberlist">



                        <li>
                            <a class="method" href="#TotalMassEncodingTransformation.IDENTITY">IDENTITY</a>
                        </li>
                        <li>
                            <a class="method" href="#TotalMassEncodingTransformation.SQRT">SQRT</a>
                        </li>
                        <li>
                            <a class="method" href="#TotalMassEncodingTransformation.LOG">LOG</a>
                        </li>

                </ul>

            </li>
            <li>
                    <a class="class" href="#TotalMassEncodingMethod">TotalMassEncodingMethod</a>
                            <ul class="memberlist">



                        <li>
                            <a class="method" href="#TotalMassEncodingMethod.DECOUPLED">DECOUPLED</a>
                        </li>
                        <li>
                            <a class="method" href="#TotalMassEncodingMethod.SCALED">SCALED</a>
                        </li>
                        <li>
                            <a class="method" href="#TotalMassEncodingMethod.HOMOGENEOUS">HOMOGENEOUS</a>
                        </li>
                        <li>
                            <a class="method" href="#TotalMassEncodingMethod.HOMOGENEOUS_SCALED">HOMOGENEOUS_SCALED</a>
                        </li>
                        <li>
                            <a class="method" href="#TotalMassEncodingMethod.HOMOGENEOUS_LEGACY">HOMOGENEOUS_LEGACY</a>
                        </li>

                </ul>

            </li>
            <li>
                    <a class="class" href="#FrequencyInitMethod">FrequencyInitMethod</a>
                            <ul class="memberlist">



                        <li>
                            <a class="method" href="#FrequencyInitMethod.RANDOM">RANDOM</a>
                        </li>
                        <li>
                            <a class="method" href="#FrequencyInitMethod.EVEN">EVEN</a>
                        </li>

                </ul>

            </li>
            <li>
                    <a class="function" href="#test_fsw_embedding">test_fsw_embedding</a>
            </li>



    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
fswlib    </h1>

                        <div class="docstring"><h1 id="fswlib-a-pytorch-library-for-the-fourier-sliced-wasserstein-fsw-embedding">fswlib: A PyTorch Library for the Fourier Sliced-Wasserstein (FSW) Embedding</h1>

<p>This package provides an implementation of the <strong>Fourier Sliced-Wasserstein (FSW) embedding</strong>, introduced in our <a href="https://iclr.cc/virtual/2025/poster/30562">ICLR 2025 paper</a></p>

<blockquote>
  <p><strong>Fourier Sliced-Wasserstein Embedding for Multisets and Measures</strong><br />
  Tal Amir &amp; Nadav Dym<br />
  <em>International Conference on Learning Representations (ICLR)</em>, 2025</p>
</blockquote>

<hr />

<h2 id="requirements">üì¶ Requirements</h2>

<ul>
<li><strong>Python</strong> ‚â• 3.10.3 (released March 2022)  </li>
<li><strong>PyTorch</strong> ‚â• 2.1.0 (released October 2023)  </li>
<li><strong>NumPy</strong> ‚â• 1.24.4 (released June 2023)  </li>
</ul>

<p>The core package has been tested on <strong>Linux</strong> and <strong>Windows</strong>.<br />
It may also run on <strong>macOS</strong>, though this has not been verified.  </p>

<hr />

<h2 id="installation">üîß Installation</h2>

<p>To install the package:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>fswlib
</code></pre>
</div>

<p>The core package runs on both <strong>CPU</strong> and <strong>CUDA-enabled GPUs</strong>, using PyTorch's standard CUDA backend.  </p>

<p>In addition, it includes an optional <strong>custom CUDA extension</strong> that can provide up to 2√ó speedup for sparse weight matrices (e.g., sparse graphs). This extension is currently supported only on <strong>Linux</strong>.</p>

<p>To compile the optional extension, run:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code>fswlib-build
</code></pre>
</div>

<hr />

<h2 id="usage-example">üìò Usage Example</h2>

<p>Below is a basic usage example of the <code><a href="#FSWEmbedding">FSWEmbedding</a></code> class.  </p>

<p>For more examples, see the <code>examples/</code> <a href="https://github.com/tal-amir/fswlib/tree/main/examples">directory</a> of the GitHub repository.<br />
Full API documentation is available at <a href="https://tal-amir.github.io/fswlib">https://tal-amir.github.io/fswlib</a>.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">fswlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">FSWEmbedding</span>

<span class="c1"># Configuration</span>
<span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">15</span>     <span class="c1"># Dimension of multiset elements</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>     <span class="c1"># Multiset size</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">123</span>    <span class="c1"># Embedding output dimension</span>

<span class="c1"># Create FSW embedding module for multisets/measures over ‚Ñù^d</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">d_out</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># --- Single input multiset ---</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>  <span class="c1"># Optional weights</span>

<span class="n">X_emb</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>  <span class="c1"># Embeds a weighted multiset</span>
<span class="n">X_emb</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>     <span class="c1"># Embeds X assuming uniform weights</span>

<span class="c1"># --- A batch of input multisets ---</span>
<span class="n">batch_dims</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">)</span>
<span class="n">Xb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">batch_dims</span><span class="o">+</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">Wb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_dims</span><span class="o">+</span><span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">Xb_emb</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">Wb</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dimension of multiset elements: </span><span class="si">{</span><span class="n">d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Embedding dimension: </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">One multiset X of size </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X shape:&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;embed(X) shape:&quot;</span><span class="p">,</span> <span class="n">X_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">batch_dim_str</span> <span class="o">=</span> <span class="s2">&quot;√ó&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch_dims</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Batch of </span><span class="si">{</span><span class="n">batch_dim_str</span><span class="si">}</span><span class="s2"> multisets, each of size </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Xb shape:&quot;</span><span class="p">,</span> <span class="n">Xb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;embed(Xb) shape:&quot;</span><span class="p">,</span> <span class="n">Xb_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre>
</div>

<p>Output:</p>

<pre><code>Dimension of multiset elements: 15
Embedding dimension: 123

One multiset X of size 50:
X shape: torch.Size([50, 15])
embed(X) shape: torch.Size([123])

Batch of 5√ó3√ó7√ó9 multisets, each of size 50:
Xb shape: torch.Size([5, 3, 7, 9, 50, 15])
embed(Xb) shape: torch.Size([5, 3, 7, 9, 123])
</code></pre>

<p>The example below illustrates the difference between the core embedding, which is invariant to the input multiset size, and an embedding that explicitly encodes it.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="c1"># --- Encoding multiset size (total mass) ---</span>
<span class="c1"># By default, the embedding is invariant to the input multiset size, since it</span>
<span class="c1"># treats inputs as *probability measures*.</span>
<span class="c1"># Set `encode_total_mass = True` to make the embedding encode the size of the</span>
<span class="c1"># input multisets, or, more generally, the total mass (i.e. sum of weights).</span>
<span class="n">embed_total_mass_invariant</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">d_out</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">embed_total_mass_aware</span> <span class="o">=</span>     <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">d_out</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">encode_total_mass</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># Two multisets of different size but identical element proportions</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">v3</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="n">X1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">v3</span><span class="p">])</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">v1</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="n">v3</span><span class="p">,</span> <span class="n">v3</span><span class="p">])</span>

<span class="c1"># Embedding *without* total mass encoding</span>
<span class="n">X1_emb</span> <span class="o">=</span> <span class="n">embed_total_mass_invariant</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
<span class="n">X2_emb</span> <span class="o">=</span> <span class="n">embed_total_mass_invariant</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>

<span class="c1"># Embedding *with* total mass encoding</span>
<span class="n">X1_emb_aware</span> <span class="o">=</span> <span class="n">embed_total_mass_aware</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>
<span class="n">X2_emb_aware</span> <span class="o">=</span> <span class="n">embed_total_mass_aware</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>

<span class="c1"># Measure the differences</span>
<span class="n">diff_invariant</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X1_emb</span> <span class="o">-</span> <span class="n">X2_emb</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">diff_aware</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X1_emb_aware</span> <span class="o">-</span> <span class="n">X2_emb_aware</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Two different-size multisets with identical element proportions:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X‚ÇÅ = {v1, v2, v3},   X‚ÇÇ = {v1, v1, v2, v2, v3, v3}&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Embedding difference: ‚ÄñEmbed(X‚ÇÅ) ‚àí Embed(X‚ÇÇ)‚Äñ‚ÇÇ&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;With total mass encoding:     </span><span class="si">{</span><span class="n">diff_aware</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Without total mass encoding:  </span><span class="si">{</span><span class="n">diff_invariant</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre>
</div>

<p>Output:</p>

<pre><code>Two different-size multisets with identical element proportions:
X‚ÇÅ = {v1, v2, v3},   X‚ÇÇ = {v1, v1, v2, v2, v3, v3}
Embedding difference: ‚ÄñEmbed(X‚ÇÅ) ‚àí Embed(X‚ÇÇ)‚Äñ‚ÇÇ
With total mass encoding:     3.0
Without total mass encoding:  5.09e-07
</code></pre>

<hr />

<h2 id="citation">üìÑ Citation</h2>

<p>If you use this library in your research, please cite our paper:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">amir2025fsw</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Fourier Sliced-{W}asserstein Embedding for Multisets and Measures}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Tal Amir and Nadav Dym}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{International Conference on Learning Representations (ICLR)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2025}</span>
<span class="p">}</span>
</code></pre>
</div>

<hr />

<h2 id="links">üîó Links</h2>

<ul>
<li><strong>Paper</strong>: <a href="https://iclr.cc/virtual/2025/poster/30562">ICLR 2025</a>  </li>
<li><strong>Code</strong>: <a href="https://github.com/tal-amir/fswlib">GitHub repository</a></li>
</ul>

<hr />

<h2 id="maintainer">üë®üèª‚Äçüîß Maintainer</h2>

<p>This library is maintained by <strong>Tal Amir</strong><br />
Homepage: <a href="https://tal-amir.github.io">https://tal-amir.github.io</a><br />
EMail: <a href="mailto:talamir@technion.ac.il">talamir@technion.ac.il</a></p>
</div>

                        <input id="mod-fswlib-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-fswlib-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="c1"># src/fswlib/__init__.py</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a><span class="sd">.. include:: ../../dev/README_PyPI.md</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.fsw_embedding.fsw_embedding</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span><span class="n">FSWEmbedding</span><span class="p">,</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a>                                          <span class="n">TotalMassEncodingTransformation</span><span class="p">,</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a>                                          <span class="n">TotalMassEncodingMethod</span><span class="p">,</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a>                                          <span class="n">EnumWithResolve</span><span class="p">,</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a>                                          <span class="n">FrequencyInitMethod</span><span class="p">,</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a>                                          <span class="n">FSWCustomCudaExtensionLoadWarning</span><span class="p">,</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a>                                          <span class="n">FSWCustomCudaExtensionLoadError</span><span class="p">)</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">13</span></a>
</span><span id="L-14"><a href="#L-14"><span class="linenos">14</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">.fsw_embedding.test_fsw_embedding</span><span class="w"> </span><span class="kn">import</span> <span class="n">main</span> <span class="k">as</span> <span class="n">test_fsw_embedding</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos">15</span></a>
</span><span id="L-16"><a href="#L-16"><span class="linenos">16</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;FSWEmbedding&quot;</span><span class="p">,</span> <span class="s2">&quot;FSWCustomCudaExtensionLoadWarning&quot;</span><span class="p">,</span> <span class="s2">&quot;FSWCustomCudaExtensionLoadError&quot;</span><span class="p">,</span> <span class="s2">&quot;EnumWithResolve&quot;</span><span class="p">,</span> <span class="s2">&quot;TotalMassEncodingTransformation&quot;</span><span class="p">,</span> <span class="s2">&quot;TotalMassEncodingMethod&quot;</span><span class="p">,</span> <span class="s2">&quot;FrequencyInitMethod&quot;</span><span class="p">,</span> <span class="s2">&quot;test_fsw_embedding&quot;</span><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="FSWEmbedding">
                            <input id="FSWEmbedding-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">FSWEmbedding</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="FSWEmbedding-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding-270"><a href="#FSWEmbedding-270"><span class="linenos"> 270</span></a><span class="k">class</span><span class="w"> </span><span class="nc">FSWEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="FSWEmbedding-271"><a href="#FSWEmbedding-271"><span class="linenos"> 271</span></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-272"><a href="#FSWEmbedding-272"><span class="linenos"> 272</span></a><span class="sd">    Fourier Sliced-Wasserstein (FSW) embedding module.</span>
</span><span id="FSWEmbedding-273"><a href="#FSWEmbedding-273"><span class="linenos"> 273</span></a>
</span><span id="FSWEmbedding-274"><a href="#FSWEmbedding-274"><span class="linenos"> 274</span></a><span class="sd">    Maps input multisets (or, more generally, discrete measures) in</span>
</span><span id="FSWEmbedding-275"><a href="#FSWEmbedding-275"><span class="linenos"> 275</span></a><span class="sd">    $\mathbb{R}^{d_\text{in}}$ to fixed-length vectors in</span>
</span><span id="FSWEmbedding-276"><a href="#FSWEmbedding-276"><span class="linenos"> 276</span></a><span class="sd">    $\mathbb{R}^{d_\text{out}}$ via the Fourier Sliced-Wasserstein</span>
</span><span id="FSWEmbedding-277"><a href="#FSWEmbedding-277"><span class="linenos"> 277</span></a><span class="sd">    embedding as described in [Amir &amp; Dym, ICLR 2025].</span>
</span><span id="FSWEmbedding-278"><a href="#FSWEmbedding-278"><span class="linenos"> 278</span></a>
</span><span id="FSWEmbedding-279"><a href="#FSWEmbedding-279"><span class="linenos"> 279</span></a><span class="sd">    Features</span>
</span><span id="FSWEmbedding-280"><a href="#FSWEmbedding-280"><span class="linenos"> 280</span></a><span class="sd">    --------</span>
</span><span id="FSWEmbedding-281"><a href="#FSWEmbedding-281"><span class="linenos"> 281</span></a><span class="sd">    ‚Ä¢ **Batched inputs**: eupports arbitrary number of batch dimensions.</span>
</span><span id="FSWEmbedding-282"><a href="#FSWEmbedding-282"><span class="linenos"> 282</span></a><span class="sd">    ‚Ä¢ **Graph mode**: efficient message-aggregation, including sparse adjacency support.</span>
</span><span id="FSWEmbedding-283"><a href="#FSWEmbedding-283"><span class="linenos"> 283</span></a><span class="sd">    ‚Ä¢ **Differentiability**: Full autograd/gradient support.</span>
</span><span id="FSWEmbedding-284"><a href="#FSWEmbedding-284"><span class="linenos"> 284</span></a>
</span><span id="FSWEmbedding-285"><a href="#FSWEmbedding-285"><span class="linenos"> 285</span></a><span class="sd">    See Also</span>
</span><span id="FSWEmbedding-286"><a href="#FSWEmbedding-286"><span class="linenos"> 286</span></a><span class="sd">    --------</span>
</span><span id="FSWEmbedding-287"><a href="#FSWEmbedding-287"><span class="linenos"> 287</span></a><span class="sd">    `FSWEmbedding.__init__` : Constructor parameters.</span>
</span><span id="FSWEmbedding-288"><a href="#FSWEmbedding-288"><span class="linenos"> 288</span></a><span class="sd">    `FSWEmbedding.forward` : Input/output tensor shapes and options.</span>
</span><span id="FSWEmbedding-289"><a href="#FSWEmbedding-289"><span class="linenos"> 289</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-290"><a href="#FSWEmbedding-290"><span class="linenos"> 290</span></a>
</span><span id="FSWEmbedding-291"><a href="#FSWEmbedding-291"><span class="linenos"> 291</span></a>
</span><span id="FSWEmbedding-292"><a href="#FSWEmbedding-292"><span class="linenos"> 292</span></a>
</span><span id="FSWEmbedding-293"><a href="#FSWEmbedding-293"><span class="linenos"> 293</span></a>
</span><span id="FSWEmbedding-294"><a href="#FSWEmbedding-294"><span class="linenos"> 294</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FSWEmbedding-295"><a href="#FSWEmbedding-295"><span class="linenos"> 295</span></a>                 <span class="n">d_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="FSWEmbedding-296"><a href="#FSWEmbedding-296"><span class="linenos"> 296</span></a>                 <span class="n">d_out</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-297"><a href="#FSWEmbedding-297"><span class="linenos"> 297</span></a>                 <span class="n">num_slices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-298"><a href="#FSWEmbedding-298"><span class="linenos"> 298</span></a>                 <span class="n">num_frequencies</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-299"><a href="#FSWEmbedding-299"><span class="linenos"> 299</span></a>                 <span class="n">flatten_cartesian_axes</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-300"><a href="#FSWEmbedding-300"><span class="linenos"> 300</span></a>                 <span class="n">d_edge</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="FSWEmbedding-301"><a href="#FSWEmbedding-301"><span class="linenos"> 301</span></a>                 <span class="n">encode_total_mass</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-302"><a href="#FSWEmbedding-302"><span class="linenos"> 302</span></a>                 <span class="n">total_mass_encoding_transformation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">TotalMassEncodingTransformation</span> <span class="o">=</span> <span class="s1">&#39;identity&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding-303"><a href="#FSWEmbedding-303"><span class="linenos"> 303</span></a>                 <span class="n">total_mass_encoding_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">TotalMassEncodingMethod</span> <span class="o">=</span> <span class="s1">&#39;decoupled&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding-304"><a href="#FSWEmbedding-304"><span class="linenos"> 304</span></a>                 <span class="n">total_mass_encoding_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="FSWEmbedding-305"><a href="#FSWEmbedding-305"><span class="linenos"> 305</span></a>                 <span class="n">total_mass_padding_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="FSWEmbedding-306"><a href="#FSWEmbedding-306"><span class="linenos"> 306</span></a>                 <span class="n">learnable_slices</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-307"><a href="#FSWEmbedding-307"><span class="linenos"> 307</span></a>                 <span class="n">learnable_frequencies</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-308"><a href="#FSWEmbedding-308"><span class="linenos"> 308</span></a>                 <span class="n">frequency_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">FrequencyInitMethod</span> <span class="o">=</span> <span class="s1">&#39;random&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding-309"><a href="#FSWEmbedding-309"><span class="linenos"> 309</span></a>                 <span class="n">minimize_slice_coherence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-310"><a href="#FSWEmbedding-310"><span class="linenos"> 310</span></a>                 <span class="n">enable_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="FSWEmbedding-311"><a href="#FSWEmbedding-311"><span class="linenos"> 311</span></a>                 <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-312"><a href="#FSWEmbedding-312"><span class="linenos"> 312</span></a>                 <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-313"><a href="#FSWEmbedding-313"><span class="linenos"> 313</span></a>                 <span class="n">use_custom_cuda_extension_if_available</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-314"><a href="#FSWEmbedding-314"><span class="linenos"> 314</span></a>                 <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-315"><a href="#FSWEmbedding-315"><span class="linenos"> 315</span></a>                 <span class="n">report</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-316"><a href="#FSWEmbedding-316"><span class="linenos"> 316</span></a>                 <span class="n">report_on_coherence_minimization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="FSWEmbedding-317"><a href="#FSWEmbedding-317"><span class="linenos"> 317</span></a><span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-318"><a href="#FSWEmbedding-318"><span class="linenos"> 318</span></a><span class="sd">        Initialize an FSWEmbedding module.</span>
</span><span id="FSWEmbedding-319"><a href="#FSWEmbedding-319"><span class="linenos"> 319</span></a>
</span><span id="FSWEmbedding-320"><a href="#FSWEmbedding-320"><span class="linenos"> 320</span></a><span class="sd">        Parameters</span>
</span><span id="FSWEmbedding-321"><a href="#FSWEmbedding-321"><span class="linenos"> 321</span></a><span class="sd">        ----------</span>
</span><span id="FSWEmbedding-322"><a href="#FSWEmbedding-322"><span class="linenos"> 322</span></a><span class="sd">        d_in : int</span>
</span><span id="FSWEmbedding-323"><a href="#FSWEmbedding-323"><span class="linenos"> 323</span></a><span class="sd">            The dimension of input multiset elements or, more generally, measure support points.  </span>
</span><span id="FSWEmbedding-324"><a href="#FSWEmbedding-324"><span class="linenos"> 324</span></a><span class="sd">            Coresponds to $d$ in $\mathcal{S}_{\leq N}\left(\mathbb{R}^d\right)$, $\mathcal{P}_{\leq N}\left(\mathbb{R}^d\right)$, or $\mathcal{M}_{\leq N}\left(\mathbb{R}^d\right)$ in our paper. </span>
</span><span id="FSWEmbedding-325"><a href="#FSWEmbedding-325"><span class="linenos"> 325</span></a><span class="sd">        d_out : int; optional</span>
</span><span id="FSWEmbedding-326"><a href="#FSWEmbedding-326"><span class="linenos"> 326</span></a><span class="sd">            Desired embedding dimension.  </span>
</span><span id="FSWEmbedding-327"><a href="#FSWEmbedding-327"><span class="linenos"> 327</span></a><span class="sd">            If not set, both `num_slices` and `num_frequencies` must be explicitly provided.</span>
</span><span id="FSWEmbedding-328"><a href="#FSWEmbedding-328"><span class="linenos"> 328</span></a><span class="sd">        num_slices : int; optional</span>
</span><span id="FSWEmbedding-329"><a href="#FSWEmbedding-329"><span class="linenos"> 329</span></a><span class="sd">            Number of slices.  </span>
</span><span id="FSWEmbedding-330"><a href="#FSWEmbedding-330"><span class="linenos"> 330</span></a><span class="sd">            When provided, activates `cartesian_mode`, and `d_out` should be left None.  </span>
</span><span id="FSWEmbedding-331"><a href="#FSWEmbedding-331"><span class="linenos"> 331</span></a><span class="sd">            See also: `flatten_cartesian_axes`</span>
</span><span id="FSWEmbedding-332"><a href="#FSWEmbedding-332"><span class="linenos"> 332</span></a><span class="sd">        num_frequencies : int; optional</span>
</span><span id="FSWEmbedding-333"><a href="#FSWEmbedding-333"><span class="linenos"> 333</span></a><span class="sd">            Number of frequencies per slice.  </span>
</span><span id="FSWEmbedding-334"><a href="#FSWEmbedding-334"><span class="linenos"> 334</span></a><span class="sd">            When provided, activates `cartesian_mode`, and `d_out` should be left None.  </span>
</span><span id="FSWEmbedding-335"><a href="#FSWEmbedding-335"><span class="linenos"> 335</span></a><span class="sd">            See also: `flatten_cartesian_axes`</span>
</span><span id="FSWEmbedding-336"><a href="#FSWEmbedding-336"><span class="linenos"> 336</span></a><span class="sd">        flatten_cartesian_axes : bool; default=False</span>
</span><span id="FSWEmbedding-337"><a href="#FSWEmbedding-337"><span class="linenos"> 337</span></a><span class="sd">            If True, flattens the slice and frequency dimensions into a single output axis.  </span>
</span><span id="FSWEmbedding-338"><a href="#FSWEmbedding-338"><span class="linenos"> 338</span></a><span class="sd">            Only relevant if `num_slices` and `num_frequencies` are provided.</span>
</span><span id="FSWEmbedding-339"><a href="#FSWEmbedding-339"><span class="linenos"> 339</span></a><span class="sd">        d_edge : int; default=0</span>
</span><span id="FSWEmbedding-340"><a href="#FSWEmbedding-340"><span class="linenos"> 340</span></a><span class="sd">            Dimension of edge feature vectors. Used only for graph inputs.  </span>
</span><span id="FSWEmbedding-341"><a href="#FSWEmbedding-341"><span class="linenos"> 341</span></a><span class="sd">            See the `graph_mode` argument of `FSWEmbedding.forward` for details.</span>
</span><span id="FSWEmbedding-342"><a href="#FSWEmbedding-342"><span class="linenos"> 342</span></a><span class="sd">        encode_total_mass : bool; default=False</span>
</span><span id="FSWEmbedding-343"><a href="#FSWEmbedding-343"><span class="linenos"> 343</span></a><span class="sd">            Whether to incorporate the input multiset size (or, more generally, the *total mass* of the input measure)</span>
</span><span id="FSWEmbedding-344"><a href="#FSWEmbedding-344"><span class="linenos"> 344</span></a><span class="sd">            into the embedding output.</span>
</span><span id="FSWEmbedding-345"><a href="#FSWEmbedding-345"><span class="linenos"> 345</span></a><span class="sd">        total_mass_encoding_transformation : {&#39;identity&#39;, &#39;sqrt&#39;, &#39;log&#39;} or TotalMassEncodingFunction; default=&#39;identity&#39;</span>
</span><span id="FSWEmbedding-346"><a href="#FSWEmbedding-346"><span class="linenos"> 346</span></a><span class="sd">            Transformation applied to the total mass *before* embedding.  </span>
</span><span id="FSWEmbedding-347"><a href="#FSWEmbedding-347"><span class="linenos"> 347</span></a><span class="sd">            See also: `TotalMassEncodingFunction`</span>
</span><span id="FSWEmbedding-348"><a href="#FSWEmbedding-348"><span class="linenos"> 348</span></a><span class="sd">        total_mass_encoding_method : {&#39;decoupled&#39;, &#39;scaled&#39;, &#39;homogeneous&#39;, &#39;homogeneous_scaled&#39;, &#39;homogeneous_legacy&#39;} or TotalMassEncodingMethod; default=&#39;decoupled&#39;</span>
</span><span id="FSWEmbedding-349"><a href="#FSWEmbedding-349"><span class="linenos"> 349</span></a><span class="sd">            Strategy for combining the total mass with the core embedding.  </span>
</span><span id="FSWEmbedding-350"><a href="#FSWEmbedding-350"><span class="linenos"> 350</span></a><span class="sd">            See also: `TotalMassEncodingMethod`</span>
</span><span id="FSWEmbedding-351"><a href="#FSWEmbedding-351"><span class="linenos"> 351</span></a><span class="sd">        total_mass_encoding_scale : float; default=1.0</span>
</span><span id="FSWEmbedding-352"><a href="#FSWEmbedding-352"><span class="linenos"> 352</span></a><span class="sd">            The encoded total mass is multiplied by this scaling factor.  </span>
</span><span id="FSWEmbedding-353"><a href="#FSWEmbedding-353"><span class="linenos"> 353</span></a><span class="sd">            See also: `TotalMassEncodingMethod`</span>
</span><span id="FSWEmbedding-354"><a href="#FSWEmbedding-354"><span class="linenos"> 354</span></a><span class="sd">        total_mass_padding_thresh : float or int; default=1.0</span>
</span><span id="FSWEmbedding-355"><a href="#FSWEmbedding-355"><span class="linenos"> 355</span></a><span class="sd">            Inputs with total mass below this threshold are padded with the zero vector to reach it; see</span>
</span><span id="FSWEmbedding-356"><a href="#FSWEmbedding-356"><span class="linenos"> 356</span></a><span class="sd">            in [Amir and Dym, ICLR 2025], Appendix A.1.  </span>
</span><span id="FSWEmbedding-357"><a href="#FSWEmbedding-357"><span class="linenos"> 357</span></a><span class="sd">            See also: `TotalMassEncodingMethod`</span>
</span><span id="FSWEmbedding-358"><a href="#FSWEmbedding-358"><span class="linenos"> 358</span></a><span class="sd">        learnable_slices : bool; default=False</span>
</span><span id="FSWEmbedding-359"><a href="#FSWEmbedding-359"><span class="linenos"> 359</span></a><span class="sd">            If True, slice vectors are learnable parameters.  </span>
</span><span id="FSWEmbedding-360"><a href="#FSWEmbedding-360"><span class="linenos"> 360</span></a><span class="sd">        learnable_frequencies : bool; default=False</span>
</span><span id="FSWEmbedding-361"><a href="#FSWEmbedding-361"><span class="linenos"> 361</span></a><span class="sd">            If True, frequency values are learnable parameters.</span>
</span><span id="FSWEmbedding-362"><a href="#FSWEmbedding-362"><span class="linenos"> 362</span></a><span class="sd">        frequency_init : float, str, tuple of float, or FrequencyInitMethod; default=&#39;random&#39;</span>
</span><span id="FSWEmbedding-363"><a href="#FSWEmbedding-363"><span class="linenos"> 363</span></a><span class="sd">            Initialization scheme for frequencies:</span>
</span><span id="FSWEmbedding-364"><a href="#FSWEmbedding-364"><span class="linenos"> 364</span></a><span class="sd">              - A float: sets all frequencies to the same value.</span>
</span><span id="FSWEmbedding-365"><a href="#FSWEmbedding-365"><span class="linenos"> 365</span></a><span class="sd">              - A tuple `(low, high)` of floats: sets evenly spaced values in that interval.</span>
</span><span id="FSWEmbedding-366"><a href="#FSWEmbedding-366"><span class="linenos"> 366</span></a><span class="sd">              - &#39;random&#39;: frequencies are drawn independently from the distribution $\mathcal{D_{\xi}}$, defined in</span>
</span><span id="FSWEmbedding-367"><a href="#FSWEmbedding-367"><span class="linenos"> 367</span></a><span class="sd">                          [Amir and Dym, ICLR 2025], Section 3.</span>
</span><span id="FSWEmbedding-368"><a href="#FSWEmbedding-368"><span class="linenos"> 368</span></a><span class="sd">              - &#39;even&#39;: frequencies are spaced evenly according to their distribution $\mathcal{D_{\xi}}$, with spaces</span>
</span><span id="FSWEmbedding-369"><a href="#FSWEmbedding-369"><span class="linenos"> 369</span></a><span class="sd">                        inversely proportional to the density.  </span>
</span><span id="FSWEmbedding-370"><a href="#FSWEmbedding-370"><span class="linenos"> 370</span></a><span class="sd">            See also: `FrequencyInitMethod`</span>
</span><span id="FSWEmbedding-371"><a href="#FSWEmbedding-371"><span class="linenos"> 371</span></a><span class="sd">        minimize_slice_coherence : bool; default=False</span>
</span><span id="FSWEmbedding-372"><a href="#FSWEmbedding-372"><span class="linenos"> 372</span></a><span class="sd">            If True, minimizes the *mutual coherence* between slices for a more uniform spread on the unit sphere.  </span>
</span><span id="FSWEmbedding-373"><a href="#FSWEmbedding-373"><span class="linenos"> 373</span></a><span class="sd">            If False, slice vectors are drawn uniformly at random from the unit sphere.</span>
</span><span id="FSWEmbedding-374"><a href="#FSWEmbedding-374"><span class="linenos"> 374</span></a><span class="sd">        enable_bias : bool; default=True</span>
</span><span id="FSWEmbedding-375"><a href="#FSWEmbedding-375"><span class="linenos"> 375</span></a><span class="sd">            If True, adds a learnable bias vector to the output embedding. When enabled, the bias is initialized</span>
</span><span id="FSWEmbedding-376"><a href="#FSWEmbedding-376"><span class="linenos"> 376</span></a><span class="sd">            to zero.  </span>
</span><span id="FSWEmbedding-377"><a href="#FSWEmbedding-377"><span class="linenos"> 377</span></a><span class="sd">        device : torch.device, int, str, or None, optional</span>
</span><span id="FSWEmbedding-378"><a href="#FSWEmbedding-378"><span class="linenos"> 378</span></a><span class="sd">            The torch device on which to allocate tensors (e.g., &#39;cpu&#39;, &#39;cuda&#39;, or an index).  </span>
</span><span id="FSWEmbedding-379"><a href="#FSWEmbedding-379"><span class="linenos"> 379</span></a><span class="sd">            If not provided, the default device defined in Torch is used.</span>
</span><span id="FSWEmbedding-380"><a href="#FSWEmbedding-380"><span class="linenos"> 380</span></a><span class="sd">        dtype : torch.dtype, optional</span>
</span><span id="FSWEmbedding-381"><a href="#FSWEmbedding-381"><span class="linenos"> 381</span></a><span class="sd">            Data type of input and output tensors (e.g., torch.float32).</span>
</span><span id="FSWEmbedding-382"><a href="#FSWEmbedding-382"><span class="linenos"> 382</span></a><span class="sd">            If not provided, the default dtype defined in Torch is used.</span>
</span><span id="FSWEmbedding-383"><a href="#FSWEmbedding-383"><span class="linenos"> 383</span></a><span class="sd">        use_custom_cuda_extension_if_available : bool or None, optional</span>
</span><span id="FSWEmbedding-384"><a href="#FSWEmbedding-384"><span class="linenos"> 384</span></a><span class="sd">            Whether to use the custom CUDA kernel if present.</span>
</span><span id="FSWEmbedding-385"><a href="#FSWEmbedding-385"><span class="linenos"> 385</span></a><span class="sd">            Default: Linux: True, all other systems: False</span>
</span><span id="FSWEmbedding-386"><a href="#FSWEmbedding-386"><span class="linenos"> 386</span></a><span class="sd">        fail_if_cuda_extension_load_fails : bool; default=False</span>
</span><span id="FSWEmbedding-387"><a href="#FSWEmbedding-387"><span class="linenos"> 387</span></a><span class="sd">            Whether to raise a runtime error (rather than a warning) if the CUDA extension failes to load.</span>
</span><span id="FSWEmbedding-388"><a href="#FSWEmbedding-388"><span class="linenos"> 388</span></a><span class="sd">        report : bool; default=False</span>
</span><span id="FSWEmbedding-389"><a href="#FSWEmbedding-389"><span class="linenos"> 389</span></a><span class="sd">            If True, prints a report with diagnostic information during initialization and forward computation.</span>
</span><span id="FSWEmbedding-390"><a href="#FSWEmbedding-390"><span class="linenos"> 390</span></a><span class="sd">        report_on_coherence_minimization : bool; default=False</span>
</span><span id="FSWEmbedding-391"><a href="#FSWEmbedding-391"><span class="linenos"> 391</span></a><span class="sd">            If True, prints special diagnostics during slice coherence minimization.</span>
</span><span id="FSWEmbedding-392"><a href="#FSWEmbedding-392"><span class="linenos"> 392</span></a>
</span><span id="FSWEmbedding-393"><a href="#FSWEmbedding-393"><span class="linenos"> 393</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding-394"><a href="#FSWEmbedding-394"><span class="linenos"> 394</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding-395"><a href="#FSWEmbedding-395"><span class="linenos"> 395</span></a><span class="sd">        If Cartesian mode is activated and `encode_total_mass` is True, `flatten_cartesian_axes` must be True.</span>
</span><span id="FSWEmbedding-396"><a href="#FSWEmbedding-396"><span class="linenos"> 396</span></a>
</span><span id="FSWEmbedding-397"><a href="#FSWEmbedding-397"><span class="linenos"> 397</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding-398"><a href="#FSWEmbedding-398"><span class="linenos"> 398</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding-399"><a href="#FSWEmbedding-399"><span class="linenos"> 399</span></a><span class="sd">        FrequencyInitMethod :</span>
</span><span id="FSWEmbedding-400"><a href="#FSWEmbedding-400"><span class="linenos"> 400</span></a><span class="sd">            Enum for selecting frequency initialization strategies.</span>
</span><span id="FSWEmbedding-401"><a href="#FSWEmbedding-401"><span class="linenos"> 401</span></a><span class="sd">        TotalMassEncodingTransformation :</span>
</span><span id="FSWEmbedding-402"><a href="#FSWEmbedding-402"><span class="linenos"> 402</span></a><span class="sd">            Enum for total mass transformations.</span>
</span><span id="FSWEmbedding-403"><a href="#FSWEmbedding-403"><span class="linenos"> 403</span></a><span class="sd">        TotalMassEncodingMethod :</span>
</span><span id="FSWEmbedding-404"><a href="#FSWEmbedding-404"><span class="linenos"> 404</span></a><span class="sd">            Enum for strategies to incorporate total mass into the embedding.</span>
</span><span id="FSWEmbedding-405"><a href="#FSWEmbedding-405"><span class="linenos"> 405</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-406"><a href="#FSWEmbedding-406"><span class="linenos"> 406</span></a>
</span><span id="FSWEmbedding-407"><a href="#FSWEmbedding-407"><span class="linenos"> 407</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="FSWEmbedding-408"><a href="#FSWEmbedding-408"><span class="linenos"> 408</span></a>
</span><span id="FSWEmbedding-409"><a href="#FSWEmbedding-409"><span class="linenos"> 409</span></a>        <span class="c1"># Process sizes</span>
</span><span id="FSWEmbedding-410"><a href="#FSWEmbedding-410"><span class="linenos"> 410</span></a>        <span class="k">assert</span> <span class="n">d_in</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;d_in must be nonnegative&#39;</span>
</span><span id="FSWEmbedding-411"><a href="#FSWEmbedding-411"><span class="linenos"> 411</span></a>        <span class="k">assert</span> <span class="n">d_edge</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;d_edge must be nonnegative&#39;</span>
</span><span id="FSWEmbedding-412"><a href="#FSWEmbedding-412"><span class="linenos"> 412</span></a>        <span class="k">assert</span> <span class="p">(</span><span class="n">d_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">d_out</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;d_out must be nonnegative or None&#39;</span>
</span><span id="FSWEmbedding-413"><a href="#FSWEmbedding-413"><span class="linenos"> 413</span></a>
</span><span id="FSWEmbedding-414"><a href="#FSWEmbedding-414"><span class="linenos"> 414</span></a>        <span class="k">if</span> <span class="n">d_out</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-415"><a href="#FSWEmbedding-415"><span class="linenos"> 415</span></a>            <span class="c1"># If the output should be empty, we force encode_total_mass to be False</span>
</span><span id="FSWEmbedding-416"><a href="#FSWEmbedding-416"><span class="linenos"> 416</span></a>            <span class="n">encode_total_mass</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="FSWEmbedding-417"><a href="#FSWEmbedding-417"><span class="linenos"> 417</span></a>
</span><span id="FSWEmbedding-418"><a href="#FSWEmbedding-418"><span class="linenos"> 418</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">d_in</span>
</span><span id="FSWEmbedding-419"><a href="#FSWEmbedding-419"><span class="linenos"> 419</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">d_edge</span>
</span><span id="FSWEmbedding-420"><a href="#FSWEmbedding-420"><span class="linenos"> 420</span></a>
</span><span id="FSWEmbedding-421"><a href="#FSWEmbedding-421"><span class="linenos"> 421</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">encode_total_mass</span>
</span><span id="FSWEmbedding-422"><a href="#FSWEmbedding-422"><span class="linenos"> 422</span></a>
</span><span id="FSWEmbedding-423"><a href="#FSWEmbedding-423"><span class="linenos"> 423</span></a>        <span class="n">total_mass_padding_thresh</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_mass_padding_thresh</span><span class="p">)</span>
</span><span id="FSWEmbedding-424"><a href="#FSWEmbedding-424"><span class="linenos"> 424</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">total_mass_padding_thresh</span><span class="p">),</span> <span class="s1">&#39;total_mass_padding_thresh cannot be inf&#39;</span>
</span><span id="FSWEmbedding-425"><a href="#FSWEmbedding-425"><span class="linenos"> 425</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">total_mass_padding_thresh</span><span class="p">),</span> <span class="s1">&#39;total_mass_padding_thresh cannot be NaN&#39;</span>
</span><span id="FSWEmbedding-426"><a href="#FSWEmbedding-426"><span class="linenos"> 426</span></a>        <span class="k">assert</span> <span class="n">total_mass_padding_thresh</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;total_mass_padding_thresh must be positive&#39;</span>
</span><span id="FSWEmbedding-427"><a href="#FSWEmbedding-427"><span class="linenos"> 427</span></a>
</span><span id="FSWEmbedding-428"><a href="#FSWEmbedding-428"><span class="linenos"> 428</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">total_mass_padding_thresh</span>
</span><span id="FSWEmbedding-429"><a href="#FSWEmbedding-429"><span class="linenos"> 429</span></a>        <span class="k">del</span> <span class="n">total_mass_padding_thresh</span>
</span><span id="FSWEmbedding-430"><a href="#FSWEmbedding-430"><span class="linenos"> 430</span></a>
</span><span id="FSWEmbedding-431"><a href="#FSWEmbedding-431"><span class="linenos"> 431</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span> <span class="o">=</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">resolve</span><span class="p">(</span><span class="n">total_mass_encoding_method</span><span class="p">)</span>
</span><span id="FSWEmbedding-432"><a href="#FSWEmbedding-432"><span class="linenos"> 432</span></a>        <span class="k">del</span> <span class="n">total_mass_encoding_method</span>
</span><span id="FSWEmbedding-433"><a href="#FSWEmbedding-433"><span class="linenos"> 433</span></a>
</span><span id="FSWEmbedding-434"><a href="#FSWEmbedding-434"><span class="linenos"> 434</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_scale</span> <span class="o">=</span> <span class="n">total_mass_encoding_scale</span>
</span><span id="FSWEmbedding-435"><a href="#FSWEmbedding-435"><span class="linenos"> 435</span></a>        <span class="k">del</span> <span class="n">total_mass_encoding_scale</span>
</span><span id="FSWEmbedding-436"><a href="#FSWEmbedding-436"><span class="linenos"> 436</span></a>
</span><span id="FSWEmbedding-437"><a href="#FSWEmbedding-437"><span class="linenos"> 437</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span> <span class="o">=</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">resolve</span><span class="p">(</span><span class="n">total_mass_encoding_transformation</span><span class="p">)</span>
</span><span id="FSWEmbedding-438"><a href="#FSWEmbedding-438"><span class="linenos"> 438</span></a>        <span class="k">del</span> <span class="n">total_mass_encoding_transformation</span>
</span><span id="FSWEmbedding-439"><a href="#FSWEmbedding-439"><span class="linenos"> 439</span></a>
</span><span id="FSWEmbedding-440"><a href="#FSWEmbedding-440"><span class="linenos"> 440</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-441"><a href="#FSWEmbedding-441"><span class="linenos"> 441</span></a>            <span class="n">input_space_name</span> <span class="o">=</span> <span class="s1">&#39;R^</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span>
</span><span id="FSWEmbedding-442"><a href="#FSWEmbedding-442"><span class="linenos"> 442</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-443"><a href="#FSWEmbedding-443"><span class="linenos"> 443</span></a>            <span class="n">input_space_name</span> <span class="o">=</span> <span class="s1">&#39;R^(</span><span class="si">%d</span><span class="s1">+</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">)</span>
</span><span id="FSWEmbedding-444"><a href="#FSWEmbedding-444"><span class="linenos"> 444</span></a>
</span><span id="FSWEmbedding-445"><a href="#FSWEmbedding-445"><span class="linenos"> 445</span></a>        <span class="n">total_mass_encoding_dim</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span> <span class="k">else</span> <span class="mi">0</span>
</span><span id="FSWEmbedding-446"><a href="#FSWEmbedding-446"><span class="linenos"> 446</span></a>
</span><span id="FSWEmbedding-447"><a href="#FSWEmbedding-447"><span class="linenos"> 447</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">d_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_slices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_frequencies</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding-448"><a href="#FSWEmbedding-448"><span class="linenos"> 448</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FSWEmbedding-449"><a href="#FSWEmbedding-449"><span class="linenos"> 449</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>  <span class="o">=</span> <span class="kc">False</span>
</span><span id="FSWEmbedding-450"><a href="#FSWEmbedding-450"><span class="linenos"> 450</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">=</span> <span class="n">d_out</span>
</span><span id="FSWEmbedding-451"><a href="#FSWEmbedding-451"><span class="linenos"> 451</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">=</span> <span class="n">d_out</span> <span class="o">-</span> <span class="n">total_mass_encoding_dim</span>
</span><span id="FSWEmbedding-452"><a href="#FSWEmbedding-452"><span class="linenos"> 452</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span> <span class="o">=</span> <span class="n">d_out</span> <span class="o">-</span> <span class="n">total_mass_encoding_dim</span>
</span><span id="FSWEmbedding-453"><a href="#FSWEmbedding-453"><span class="linenos"> 453</span></a>            <span class="n">output_space_name</span> <span class="o">=</span> <span class="s1">&#39;R^</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span>
</span><span id="FSWEmbedding-454"><a href="#FSWEmbedding-454"><span class="linenos"> 454</span></a>
</span><span id="FSWEmbedding-455"><a href="#FSWEmbedding-455"><span class="linenos"> 455</span></a>        <span class="k">elif</span> <span class="p">(</span><span class="n">d_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_slices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_frequencies</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding-456"><a href="#FSWEmbedding-456"><span class="linenos"> 456</span></a>            <span class="k">assert</span> <span class="n">flatten_cartesian_axes</span>  <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">encode_total_mass</span><span class="p">),</span> <span class="s1">&#39;Cartesian mode with flatten_cartesian_axes =False is not supported when encode_total_mass=True&#39;</span>
</span><span id="FSWEmbedding-457"><a href="#FSWEmbedding-457"><span class="linenos"> 457</span></a>
</span><span id="FSWEmbedding-458"><a href="#FSWEmbedding-458"><span class="linenos"> 458</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="FSWEmbedding-459"><a href="#FSWEmbedding-459"><span class="linenos"> 459</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>  <span class="o">=</span> <span class="n">flatten_cartesian_axes</span>
</span><span id="FSWEmbedding-460"><a href="#FSWEmbedding-460"><span class="linenos"> 460</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">=</span> <span class="n">num_slices</span>
</span><span id="FSWEmbedding-461"><a href="#FSWEmbedding-461"><span class="linenos"> 461</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span> <span class="o">=</span> <span class="n">num_frequencies</span>
</span><span id="FSWEmbedding-462"><a href="#FSWEmbedding-462"><span class="linenos"> 462</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">=</span> <span class="n">num_slices</span> <span class="o">*</span> <span class="n">num_frequencies</span> <span class="o">+</span> <span class="n">total_mass_encoding_dim</span>
</span><span id="FSWEmbedding-463"><a href="#FSWEmbedding-463"><span class="linenos"> 463</span></a>            <span class="n">output_space_name</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;R^</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>  <span class="k">else</span> <span class="p">(</span><span class="s1">&#39;R^(</span><span class="si">%d</span><span class="se">\u00d7</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">))</span>
</span><span id="FSWEmbedding-464"><a href="#FSWEmbedding-464"><span class="linenos"> 464</span></a>
</span><span id="FSWEmbedding-465"><a href="#FSWEmbedding-465"><span class="linenos"> 465</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-466"><a href="#FSWEmbedding-466"><span class="linenos"> 466</span></a>            <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;Expected exactly one of (d_out != None) or (num_slices != None and num_frequencies != None)&quot;</span>
</span><span id="FSWEmbedding-467"><a href="#FSWEmbedding-467"><span class="linenos"> 467</span></a>
</span><span id="FSWEmbedding-468"><a href="#FSWEmbedding-468"><span class="linenos"> 468</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;d_out must be nonnegative&#39;</span>
</span><span id="FSWEmbedding-469"><a href="#FSWEmbedding-469"><span class="linenos"> 469</span></a>
</span><span id="FSWEmbedding-470"><a href="#FSWEmbedding-470"><span class="linenos"> 470</span></a>        <span class="c1">#d_out = self.d_out</span>
</span><span id="FSWEmbedding-471"><a href="#FSWEmbedding-471"><span class="linenos"> 471</span></a>        <span class="n">num_slices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span>
</span><span id="FSWEmbedding-472"><a href="#FSWEmbedding-472"><span class="linenos"> 472</span></a>        <span class="n">num_frequencies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span>
</span><span id="FSWEmbedding-473"><a href="#FSWEmbedding-473"><span class="linenos"> 473</span></a>
</span><span id="FSWEmbedding-474"><a href="#FSWEmbedding-474"><span class="linenos"> 474</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span> <span class="o">=</span> <span class="n">minimize_slice_coherence</span>
</span><span id="FSWEmbedding-475"><a href="#FSWEmbedding-475"><span class="linenos"> 475</span></a>
</span><span id="FSWEmbedding-476"><a href="#FSWEmbedding-476"><span class="linenos"> 476</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span> <span class="o">=</span> <span class="n">learnable_slices</span>
</span><span id="FSWEmbedding-477"><a href="#FSWEmbedding-477"><span class="linenos"> 477</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span> <span class="o">=</span> <span class="n">learnable_frequencies</span>
</span><span id="FSWEmbedding-478"><a href="#FSWEmbedding-478"><span class="linenos"> 478</span></a>
</span><span id="FSWEmbedding-479"><a href="#FSWEmbedding-479"><span class="linenos"> 479</span></a>        <span class="c1"># Note: frequency_init is checked for correctness downstream at generate_embedding_parameters()</span>
</span><span id="FSWEmbedding-480"><a href="#FSWEmbedding-480"><span class="linenos"> 480</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span> <span class="o">=</span> <span class="n">frequency_init</span>
</span><span id="FSWEmbedding-481"><a href="#FSWEmbedding-481"><span class="linenos"> 481</span></a>
</span><span id="FSWEmbedding-482"><a href="#FSWEmbedding-482"><span class="linenos"> 482</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span> <span class="o">=</span> <span class="n">enable_bias</span>
</span><span id="FSWEmbedding-483"><a href="#FSWEmbedding-483"><span class="linenos"> 483</span></a>
</span><span id="FSWEmbedding-484"><a href="#FSWEmbedding-484"><span class="linenos"> 484</span></a>        <span class="c1"># _device_new and _dtype_new are only defined here on __init__ and passed on to reset_parameters(), which then deletes them</span>
</span><span id="FSWEmbedding-485"><a href="#FSWEmbedding-485"><span class="linenos"> 485</span></a>        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding-486"><a href="#FSWEmbedding-486"><span class="linenos"> 486</span></a>            <span class="c1"># Use get_default_device if available (PyTorch 2.3+)</span>
</span><span id="FSWEmbedding-487"><a href="#FSWEmbedding-487"><span class="linenos"> 487</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;get_default_device&quot;</span><span class="p">):</span>
</span><span id="FSWEmbedding-488"><a href="#FSWEmbedding-488"><span class="linenos"> 488</span></a>                <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_device</span><span class="p">()</span>
</span><span id="FSWEmbedding-489"><a href="#FSWEmbedding-489"><span class="linenos"> 489</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-490"><a href="#FSWEmbedding-490"><span class="linenos"> 490</span></a>                <span class="c1"># Fallback: infer from a dummy tensor</span>
</span><span id="FSWEmbedding-491"><a href="#FSWEmbedding-491"><span class="linenos"> 491</span></a>                <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span><span class="o">.</span><span class="n">device</span>
</span><span id="FSWEmbedding-492"><a href="#FSWEmbedding-492"><span class="linenos"> 492</span></a>
</span><span id="FSWEmbedding-493"><a href="#FSWEmbedding-493"><span class="linenos"> 493</span></a>        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding-494"><a href="#FSWEmbedding-494"><span class="linenos"> 494</span></a>            <span class="c1"># Use get_default_dtype if available</span>
</span><span id="FSWEmbedding-495"><a href="#FSWEmbedding-495"><span class="linenos"> 495</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;get_default_dtype&quot;</span><span class="p">):</span>
</span><span id="FSWEmbedding-496"><a href="#FSWEmbedding-496"><span class="linenos"> 496</span></a>                <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
</span><span id="FSWEmbedding-497"><a href="#FSWEmbedding-497"><span class="linenos"> 497</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-498"><a href="#FSWEmbedding-498"><span class="linenos"> 498</span></a>                <span class="c1"># Fallback: infer from a dummy tensor</span>
</span><span id="FSWEmbedding-499"><a href="#FSWEmbedding-499"><span class="linenos"> 499</span></a>                <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="FSWEmbedding-500"><a href="#FSWEmbedding-500"><span class="linenos"> 500</span></a>
</span><span id="FSWEmbedding-501"><a href="#FSWEmbedding-501"><span class="linenos"> 501</span></a>        <span class="k">assert</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_floating_point</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_complex</span><span class="p">),</span> <span class="s1">&#39;dtype must be real floating-point; instead got dtype=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">dtype</span>
</span><span id="FSWEmbedding-502"><a href="#FSWEmbedding-502"><span class="linenos"> 502</span></a>
</span><span id="FSWEmbedding-503"><a href="#FSWEmbedding-503"><span class="linenos"> 503</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device_new</span> <span class="o">=</span> <span class="n">device</span>
</span><span id="FSWEmbedding-504"><a href="#FSWEmbedding-504"><span class="linenos"> 504</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_new</span> <span class="o">=</span> <span class="n">dtype</span>
</span><span id="FSWEmbedding-505"><a href="#FSWEmbedding-505"><span class="linenos"> 505</span></a>
</span><span id="FSWEmbedding-506"><a href="#FSWEmbedding-506"><span class="linenos"> 506</span></a>        <span class="k">if</span> <span class="n">use_custom_cuda_extension_if_available</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding-507"><a href="#FSWEmbedding-507"><span class="linenos"> 507</span></a>            <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;Windows&#39;</span><span class="p">,</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">}:</span>
</span><span id="FSWEmbedding-508"><a href="#FSWEmbedding-508"><span class="linenos"> 508</span></a>                <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FSWEmbedding-509"><a href="#FSWEmbedding-509"><span class="linenos"> 509</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-510"><a href="#FSWEmbedding-510"><span class="linenos"> 510</span></a>                <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="FSWEmbedding-511"><a href="#FSWEmbedding-511"><span class="linenos"> 511</span></a>
</span><span id="FSWEmbedding-512"><a href="#FSWEmbedding-512"><span class="linenos"> 512</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="n">use_custom_cuda_extension_if_available</span>
</span><span id="FSWEmbedding-513"><a href="#FSWEmbedding-513"><span class="linenos"> 513</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span> <span class="o">=</span> <span class="n">fail_if_cuda_extension_load_fails</span>
</span><span id="FSWEmbedding-514"><a href="#FSWEmbedding-514"><span class="linenos"> 514</span></a>
</span><span id="FSWEmbedding-515"><a href="#FSWEmbedding-515"><span class="linenos"> 515</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">report</span>
</span><span id="FSWEmbedding-516"><a href="#FSWEmbedding-516"><span class="linenos"> 516</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span> <span class="o">=</span> <span class="n">report_on_coherence_minimization</span>
</span><span id="FSWEmbedding-517"><a href="#FSWEmbedding-517"><span class="linenos"> 517</span></a>
</span><span id="FSWEmbedding-518"><a href="#FSWEmbedding-518"><span class="linenos"> 518</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span><span id="FSWEmbedding-519"><a href="#FSWEmbedding-519"><span class="linenos"> 519</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;Fourier Sliced-Wasserstein Embedding&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-520"><a href="#FSWEmbedding-520"><span class="linenos"> 520</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;version </span><span class="si">%s</span><span class="s1">, </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">version</span><span class="p">,</span> <span class="n">version_date</span><span class="p">))</span>
</span><span id="FSWEmbedding-521"><a href="#FSWEmbedding-521"><span class="linenos"> 521</span></a>
</span><span id="FSWEmbedding-522"><a href="#FSWEmbedding-522"><span class="linenos"> 522</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span><span id="FSWEmbedding-523"><a href="#FSWEmbedding-523"><span class="linenos"> 523</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;Based on our paper titled &quot;Fourier Sliced-Wasserstrin Embedding for Multisets and Measures&quot;, ICLR 2025&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-524"><a href="#FSWEmbedding-524"><span class="linenos"> 524</span></a>
</span><span id="FSWEmbedding-525"><a href="#FSWEmbedding-525"><span class="linenos"> 525</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span><span id="FSWEmbedding-526"><a href="#FSWEmbedding-526"><span class="linenos"> 526</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;Constructing embedding for sets in </span><span class="si">%s</span><span class="s1"> into </span><span class="si">%s</span><span class="s1">  &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">input_space_name</span><span class="p">,</span> <span class="n">output_space_name</span><span class="p">))</span>
</span><span id="FSWEmbedding-527"><a href="#FSWEmbedding-527"><span class="linenos"> 527</span></a>
</span><span id="FSWEmbedding-528"><a href="#FSWEmbedding-528"><span class="linenos"> 528</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding-529"><a href="#FSWEmbedding-529"><span class="linenos"> 529</span></a>            <span class="n">slice_freq_str</span> <span class="o">=</span> <span class="s1">&#39;Using </span><span class="si">%d</span><span class="s1"> slices </span><span class="se">\u00d7</span><span class="s1"> </span><span class="si">%d</span><span class="s1"> frequencies, collapsed to one </span><span class="si">%d</span><span class="s1"> dimensional axis; &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="p">,</span> <span class="n">num_slices</span><span class="o">*</span><span class="n">num_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-530"><a href="#FSWEmbedding-530"><span class="linenos"> 530</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-531"><a href="#FSWEmbedding-531"><span class="linenos"> 531</span></a>            <span class="n">slice_freq_str</span> <span class="o">=</span> <span class="s1">&#39;Using </span><span class="si">%d</span><span class="s1"> slices </span><span class="se">\u00d7</span><span class="s1"> </span><span class="si">%s</span><span class="s1"> frequencies; &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-532"><a href="#FSWEmbedding-532"><span class="linenos"> 532</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-533"><a href="#FSWEmbedding-533"><span class="linenos"> 533</span></a>            <span class="n">slice_freq_str</span> <span class="o">=</span> <span class="s1">&#39;Using </span><span class="si">%d</span><span class="s1"> (slice, frequency) pairs; &#39;</span> <span class="o">%</span> <span class="n">num_slices</span>
</span><span id="FSWEmbedding-534"><a href="#FSWEmbedding-534"><span class="linenos"> 534</span></a>
</span><span id="FSWEmbedding-535"><a href="#FSWEmbedding-535"><span class="linenos"> 535</span></a>        <span class="n">qprint</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="n">slice_freq_str</span><span class="p">)</span>
</span><span id="FSWEmbedding-536"><a href="#FSWEmbedding-536"><span class="linenos"> 536</span></a>
</span><span id="FSWEmbedding-537"><a href="#FSWEmbedding-537"><span class="linenos"> 537</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">:</span>
</span><span id="FSWEmbedding-538"><a href="#FSWEmbedding-538"><span class="linenos"> 538</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding-539"><a href="#FSWEmbedding-539"><span class="linenos"> 539</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices, frequences and biases&#39;</span>
</span><span id="FSWEmbedding-540"><a href="#FSWEmbedding-540"><span class="linenos"> 540</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-541"><a href="#FSWEmbedding-541"><span class="linenos"> 541</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices and frequences, no bias&#39;</span>
</span><span id="FSWEmbedding-542"><a href="#FSWEmbedding-542"><span class="linenos"> 542</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">:</span>
</span><span id="FSWEmbedding-543"><a href="#FSWEmbedding-543"><span class="linenos"> 543</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding-544"><a href="#FSWEmbedding-544"><span class="linenos"> 544</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices and biases, fixed frequencies&#39;</span>
</span><span id="FSWEmbedding-545"><a href="#FSWEmbedding-545"><span class="linenos"> 545</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-546"><a href="#FSWEmbedding-546"><span class="linenos"> 546</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices, fixed frequences, no bias&#39;</span>
</span><span id="FSWEmbedding-547"><a href="#FSWEmbedding-547"><span class="linenos"> 547</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">:</span>
</span><span id="FSWEmbedding-548"><a href="#FSWEmbedding-548"><span class="linenos"> 548</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding-549"><a href="#FSWEmbedding-549"><span class="linenos"> 549</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices, learnable frequencies, fixed biases (initialized to zero)&#39;</span>
</span><span id="FSWEmbedding-550"><a href="#FSWEmbedding-550"><span class="linenos"> 550</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-551"><a href="#FSWEmbedding-551"><span class="linenos"> 551</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices, learnable frequencies, no biases&#39;</span>
</span><span id="FSWEmbedding-552"><a href="#FSWEmbedding-552"><span class="linenos"> 552</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-553"><a href="#FSWEmbedding-553"><span class="linenos"> 553</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding-554"><a href="#FSWEmbedding-554"><span class="linenos"> 554</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices and frequencies, fixed biases (initialized to zero)&#39;</span>
</span><span id="FSWEmbedding-555"><a href="#FSWEmbedding-555"><span class="linenos"> 555</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-556"><a href="#FSWEmbedding-556"><span class="linenos"> 556</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices and frequencies, no bias&#39;</span>
</span><span id="FSWEmbedding-557"><a href="#FSWEmbedding-557"><span class="linenos"> 557</span></a>
</span><span id="FSWEmbedding-558"><a href="#FSWEmbedding-558"><span class="linenos"> 558</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="n">learnable_str</span><span class="p">)</span>
</span><span id="FSWEmbedding-559"><a href="#FSWEmbedding-559"><span class="linenos"> 559</span></a>
</span><span id="FSWEmbedding-560"><a href="#FSWEmbedding-560"><span class="linenos"> 560</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;device: </span><span class="si">%s</span><span class="s1">    dtype: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device_new</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_new</span><span class="p">))</span>
</span><span id="FSWEmbedding-561"><a href="#FSWEmbedding-561"><span class="linenos"> 561</span></a>
</span><span id="FSWEmbedding-562"><a href="#FSWEmbedding-562"><span class="linenos"> 562</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding-563"><a href="#FSWEmbedding-563"><span class="linenos"> 563</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding-564"><a href="#FSWEmbedding-564"><span class="linenos"> 564</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding-565"><a href="#FSWEmbedding-565"><span class="linenos"> 565</span></a>
</span><span id="FSWEmbedding-566"><a href="#FSWEmbedding-566"><span class="linenos"> 566</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
</span><span id="FSWEmbedding-567"><a href="#FSWEmbedding-567"><span class="linenos"> 567</span></a>
</span><span id="FSWEmbedding-568"><a href="#FSWEmbedding-568"><span class="linenos"> 568</span></a>    <span class="nd">@classmethod</span>
</span><span id="FSWEmbedding-569"><a href="#FSWEmbedding-569"><span class="linenos"> 569</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;FSWEmbedding&quot;</span><span class="p">:</span>
</span><span id="FSWEmbedding-570"><a href="#FSWEmbedding-570"><span class="linenos"> 570</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-571"><a href="#FSWEmbedding-571"><span class="linenos"> 571</span></a><span class="sd">        Construct an FSWEmbedding instance from a configuration dictionary.</span>
</span><span id="FSWEmbedding-572"><a href="#FSWEmbedding-572"><span class="linenos"> 572</span></a>
</span><span id="FSWEmbedding-573"><a href="#FSWEmbedding-573"><span class="linenos"> 573</span></a><span class="sd">        Parameters</span>
</span><span id="FSWEmbedding-574"><a href="#FSWEmbedding-574"><span class="linenos"> 574</span></a><span class="sd">        ----------</span>
</span><span id="FSWEmbedding-575"><a href="#FSWEmbedding-575"><span class="linenos"> 575</span></a><span class="sd">        config : dict</span>
</span><span id="FSWEmbedding-576"><a href="#FSWEmbedding-576"><span class="linenos"> 576</span></a><span class="sd">            Dictionary of keyword arguments matching the `__init__` parameters.</span>
</span><span id="FSWEmbedding-577"><a href="#FSWEmbedding-577"><span class="linenos"> 577</span></a>
</span><span id="FSWEmbedding-578"><a href="#FSWEmbedding-578"><span class="linenos"> 578</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding-579"><a href="#FSWEmbedding-579"><span class="linenos"> 579</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding-580"><a href="#FSWEmbedding-580"><span class="linenos"> 580</span></a><span class="sd">        FSWEmbedding</span>
</span><span id="FSWEmbedding-581"><a href="#FSWEmbedding-581"><span class="linenos"> 581</span></a><span class="sd">            A new instance initialized with the provided configuration.</span>
</span><span id="FSWEmbedding-582"><a href="#FSWEmbedding-582"><span class="linenos"> 582</span></a>
</span><span id="FSWEmbedding-583"><a href="#FSWEmbedding-583"><span class="linenos"> 583</span></a><span class="sd">        Raises</span>
</span><span id="FSWEmbedding-584"><a href="#FSWEmbedding-584"><span class="linenos"> 584</span></a><span class="sd">        ------</span>
</span><span id="FSWEmbedding-585"><a href="#FSWEmbedding-585"><span class="linenos"> 585</span></a><span class="sd">        TypeError</span>
</span><span id="FSWEmbedding-586"><a href="#FSWEmbedding-586"><span class="linenos"> 586</span></a><span class="sd">            If any keys in the dictionary are not valid constructor arguments.</span>
</span><span id="FSWEmbedding-587"><a href="#FSWEmbedding-587"><span class="linenos"> 587</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-588"><a href="#FSWEmbedding-588"><span class="linenos"> 588</span></a>        <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
</span><span id="FSWEmbedding-589"><a href="#FSWEmbedding-589"><span class="linenos"> 589</span></a>        <span class="n">valid_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">-</span> <span class="p">{</span><span class="s1">&#39;self&#39;</span><span class="p">}</span>
</span><span id="FSWEmbedding-590"><a href="#FSWEmbedding-590"><span class="linenos"> 590</span></a>        <span class="n">invalid_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="o">-</span> <span class="n">valid_keys</span>
</span><span id="FSWEmbedding-591"><a href="#FSWEmbedding-591"><span class="linenos"> 591</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">invalid_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FSWEmbedding-592"><a href="#FSWEmbedding-592"><span class="linenos"> 592</span></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected config key: &#39;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">invalid_keys</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding-593"><a href="#FSWEmbedding-593"><span class="linenos"> 593</span></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">invalid_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FSWEmbedding-594"><a href="#FSWEmbedding-594"><span class="linenos"> 594</span></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected config keys: </span><span class="si">{</span><span class="n">invalid_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding-595"><a href="#FSWEmbedding-595"><span class="linenos"> 595</span></a>        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
</span><span id="FSWEmbedding-596"><a href="#FSWEmbedding-596"><span class="linenos"> 596</span></a>
</span><span id="FSWEmbedding-597"><a href="#FSWEmbedding-597"><span class="linenos"> 597</span></a>    <span class="c1"># Resets the model parameters (slice vectors and frequencies) and updates the model settings.</span>
</span><span id="FSWEmbedding-598"><a href="#FSWEmbedding-598"><span class="linenos"> 598</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FSWEmbedding-599"><a href="#FSWEmbedding-599"><span class="linenos"> 599</span></a>                         <span class="n">frequency_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">FrequencyInitMethod</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-600"><a href="#FSWEmbedding-600"><span class="linenos"> 600</span></a>                         <span class="n">minimize_slice_coherence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-601"><a href="#FSWEmbedding-601"><span class="linenos"> 601</span></a>                         <span class="n">report</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-602"><a href="#FSWEmbedding-602"><span class="linenos"> 602</span></a>                         <span class="n">report_on_coherence_minimization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding-603"><a href="#FSWEmbedding-603"><span class="linenos"> 603</span></a>
</span><span id="FSWEmbedding-604"><a href="#FSWEmbedding-604"><span class="linenos"> 604</span></a>        <span class="c1"># Apply user updates for these parameters</span>
</span><span id="FSWEmbedding-605"><a href="#FSWEmbedding-605"><span class="linenos"> 605</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span><span class="p">)</span>
</span><span id="FSWEmbedding-606"><a href="#FSWEmbedding-606"><span class="linenos"> 606</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">minimize_slice_coherence</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span><span class="p">)</span>
</span><span id="FSWEmbedding-607"><a href="#FSWEmbedding-607"><span class="linenos"> 607</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">)</span>
</span><span id="FSWEmbedding-608"><a href="#FSWEmbedding-608"><span class="linenos"> 608</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">report_on_coherence_minimization</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span><span class="p">)</span>
</span><span id="FSWEmbedding-609"><a href="#FSWEmbedding-609"><span class="linenos"> 609</span></a>
</span><span id="FSWEmbedding-610"><a href="#FSWEmbedding-610"><span class="linenos"> 610</span></a>        <span class="c1"># To make sure we don&#39;t use these values inside the function; if any of then is None, we must use its self. counterpart.</span>
</span><span id="FSWEmbedding-611"><a href="#FSWEmbedding-611"><span class="linenos"> 611</span></a>        <span class="k">del</span> <span class="n">minimize_slice_coherence</span><span class="p">,</span> <span class="n">frequency_init</span><span class="p">,</span> <span class="n">report</span><span class="p">,</span> <span class="n">report_on_coherence_minimization</span>
</span><span id="FSWEmbedding-612"><a href="#FSWEmbedding-612"><span class="linenos"> 612</span></a>
</span><span id="FSWEmbedding-613"><a href="#FSWEmbedding-613"><span class="linenos"> 613</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">)</span>
</span><span id="FSWEmbedding-614"><a href="#FSWEmbedding-614"><span class="linenos"> 614</span></a>
</span><span id="FSWEmbedding-615"><a href="#FSWEmbedding-615"><span class="linenos"> 615</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_device_new&#39;</span><span class="p">):</span>
</span><span id="FSWEmbedding-616"><a href="#FSWEmbedding-616"><span class="linenos"> 616</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">,</span> <span class="s1">&#39;Generating embedding parameters:&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-617"><a href="#FSWEmbedding-617"><span class="linenos"> 617</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-618"><a href="#FSWEmbedding-618"><span class="linenos"> 618</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">,</span> <span class="s1">&#39;Resetting embedding parameters:&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-619"><a href="#FSWEmbedding-619"><span class="linenos"> 619</span></a>
</span><span id="FSWEmbedding-620"><a href="#FSWEmbedding-620"><span class="linenos"> 620</span></a>
</span><span id="FSWEmbedding-621"><a href="#FSWEmbedding-621"><span class="linenos"> 621</span></a>        <span class="c1"># If we&#39;re running for the first time, get the device and dtype that were set in the __init__ method;</span>
</span><span id="FSWEmbedding-622"><a href="#FSWEmbedding-622"><span class="linenos"> 622</span></a>        <span class="c1"># otherwise use the current device and dtype.</span>
</span><span id="FSWEmbedding-623"><a href="#FSWEmbedding-623"><span class="linenos"> 623</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_device_new&#39;</span><span class="p">):</span>
</span><span id="FSWEmbedding-624"><a href="#FSWEmbedding-624"><span class="linenos"> 624</span></a>            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_new</span>
</span><span id="FSWEmbedding-625"><a href="#FSWEmbedding-625"><span class="linenos"> 625</span></a>            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_device_new&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-626"><a href="#FSWEmbedding-626"><span class="linenos"> 626</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-627"><a href="#FSWEmbedding-627"><span class="linenos"> 627</span></a>            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
</span><span id="FSWEmbedding-628"><a href="#FSWEmbedding-628"><span class="linenos"> 628</span></a>
</span><span id="FSWEmbedding-629"><a href="#FSWEmbedding-629"><span class="linenos"> 629</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_dtype_new&#39;</span><span class="p">):</span>
</span><span id="FSWEmbedding-630"><a href="#FSWEmbedding-630"><span class="linenos"> 630</span></a>            <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_new</span>
</span><span id="FSWEmbedding-631"><a href="#FSWEmbedding-631"><span class="linenos"> 631</span></a>            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_dtype_new&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-632"><a href="#FSWEmbedding-632"><span class="linenos"> 632</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-633"><a href="#FSWEmbedding-633"><span class="linenos"> 633</span></a>            <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="FSWEmbedding-634"><a href="#FSWEmbedding-634"><span class="linenos"> 634</span></a>
</span><span id="FSWEmbedding-635"><a href="#FSWEmbedding-635"><span class="linenos"> 635</span></a>
</span><span id="FSWEmbedding-636"><a href="#FSWEmbedding-636"><span class="linenos"> 636</span></a>        <span class="n">total_mass_encoding_dim</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span> <span class="k">else</span> <span class="mi">0</span>
</span><span id="FSWEmbedding-637"><a href="#FSWEmbedding-637"><span class="linenos"> 637</span></a>
</span><span id="FSWEmbedding-638"><a href="#FSWEmbedding-638"><span class="linenos"> 638</span></a>        <span class="c1"># Generate slice vectors and frequencies</span>
</span><span id="FSWEmbedding-639"><a href="#FSWEmbedding-639"><span class="linenos"> 639</span></a>        <span class="c1"># We always generate (and optimize) them in float64 and then convert to the desired dtype.</span>
</span><span id="FSWEmbedding-640"><a href="#FSWEmbedding-640"><span class="linenos"> 640</span></a>        <span class="n">slice_vectors</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_generate_embedding_parameters</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">,</span>
</span><span id="FSWEmbedding-641"><a href="#FSWEmbedding-641"><span class="linenos"> 641</span></a>                                                                                       <span class="n">num_slices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">,</span>
</span><span id="FSWEmbedding-642"><a href="#FSWEmbedding-642"><span class="linenos"> 642</span></a>                                                                                       <span class="n">cartesian_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">,</span>
</span><span id="FSWEmbedding-643"><a href="#FSWEmbedding-643"><span class="linenos"> 643</span></a>                                                                                       <span class="n">flatten_cartesian_axes</span> <span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span><span class="p">,</span>
</span><span id="FSWEmbedding-644"><a href="#FSWEmbedding-644"><span class="linenos"> 644</span></a>                                                                                       <span class="n">total_mass_encoding_dim</span><span class="o">=</span><span class="n">total_mass_encoding_dim</span><span class="p">,</span>
</span><span id="FSWEmbedding-645"><a href="#FSWEmbedding-645"><span class="linenos"> 645</span></a>                                                                                       <span class="n">frequency_init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span><span class="p">,</span>
</span><span id="FSWEmbedding-646"><a href="#FSWEmbedding-646"><span class="linenos"> 646</span></a>                                                                                       <span class="n">minimize_slice_coherence</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span><span class="p">,</span>
</span><span id="FSWEmbedding-647"><a href="#FSWEmbedding-647"><span class="linenos"> 647</span></a>                                                                                       <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
</span><span id="FSWEmbedding-648"><a href="#FSWEmbedding-648"><span class="linenos"> 648</span></a>                                                                                       <span class="n">report</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">,</span>
</span><span id="FSWEmbedding-649"><a href="#FSWEmbedding-649"><span class="linenos"> 649</span></a>                                                                                       <span class="n">report_on_coherence_minimization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span><span class="p">)</span>
</span><span id="FSWEmbedding-650"><a href="#FSWEmbedding-650"><span class="linenos"> 650</span></a>
</span><span id="FSWEmbedding-651"><a href="#FSWEmbedding-651"><span class="linenos"> 651</span></a>        <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">slice_vectors</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-652"><a href="#FSWEmbedding-652"><span class="linenos"> 652</span></a>        <span class="n">frequencies</span> <span class="o">=</span> <span class="n">frequencies</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-653"><a href="#FSWEmbedding-653"><span class="linenos"> 653</span></a>
</span><span id="FSWEmbedding-654"><a href="#FSWEmbedding-654"><span class="linenos"> 654</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">)</span>
</span><span id="FSWEmbedding-655"><a href="#FSWEmbedding-655"><span class="linenos"> 655</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-656"><a href="#FSWEmbedding-656"><span class="linenos"> 656</span></a>
</span><span id="FSWEmbedding-657"><a href="#FSWEmbedding-657"><span class="linenos"> 657</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding-658"><a href="#FSWEmbedding-658"><span class="linenos"> 658</span></a>            <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-659"><a href="#FSWEmbedding-659"><span class="linenos"> 659</span></a>
</span><span id="FSWEmbedding-660"><a href="#FSWEmbedding-660"><span class="linenos"> 660</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding-661"><a href="#FSWEmbedding-661"><span class="linenos"> 661</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">))</span>
</span><span id="FSWEmbedding-662"><a href="#FSWEmbedding-662"><span class="linenos"> 662</span></a>
</span><span id="FSWEmbedding-663"><a href="#FSWEmbedding-663"><span class="linenos"> 663</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">)</span>
</span><span id="FSWEmbedding-664"><a href="#FSWEmbedding-664"><span class="linenos"> 664</span></a>
</span><span id="FSWEmbedding-665"><a href="#FSWEmbedding-665"><span class="linenos"> 665</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-666"><a href="#FSWEmbedding-666"><span class="linenos"> 666</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding-667"><a href="#FSWEmbedding-667"><span class="linenos"> 667</span></a>
</span><span id="FSWEmbedding-668"><a href="#FSWEmbedding-668"><span class="linenos"> 668</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="FSWEmbedding-669"><a href="#FSWEmbedding-669"><span class="linenos"> 669</span></a>
</span><span id="FSWEmbedding-670"><a href="#FSWEmbedding-670"><span class="linenos"> 670</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="FSWEmbedding-671"><a href="#FSWEmbedding-671"><span class="linenos"> 671</span></a>
</span><span id="FSWEmbedding-672"><a href="#FSWEmbedding-672"><span class="linenos"> 672</span></a>
</span><span id="FSWEmbedding-673"><a href="#FSWEmbedding-673"><span class="linenos"> 673</span></a>
</span><span id="FSWEmbedding-674"><a href="#FSWEmbedding-674"><span class="linenos"> 674</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FSWEmbedding-675"><a href="#FSWEmbedding-675"><span class="linenos"> 675</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Moves the module to the specified device or dtype.</span>
</span><span id="FSWEmbedding-676"><a href="#FSWEmbedding-676"><span class="linenos"> 676</span></a>
</span><span id="FSWEmbedding-677"><a href="#FSWEmbedding-677"><span class="linenos"> 677</span></a><span class="sd">        Example:</span>
</span><span id="FSWEmbedding-678"><a href="#FSWEmbedding-678"><span class="linenos"> 678</span></a>
</span><span id="FSWEmbedding-679"><a href="#FSWEmbedding-679"><span class="linenos"> 679</span></a><span class="sd">            module.to(torch.float32)</span>
</span><span id="FSWEmbedding-680"><a href="#FSWEmbedding-680"><span class="linenos"> 680</span></a><span class="sd">            module.to(device=&#39;cuda&#39;)</span>
</span><span id="FSWEmbedding-681"><a href="#FSWEmbedding-681"><span class="linenos"> 681</span></a>
</span><span id="FSWEmbedding-682"><a href="#FSWEmbedding-682"><span class="linenos"> 682</span></a><span class="sd">        See also: torch.nn.Module.to()</span>
</span><span id="FSWEmbedding-683"><a href="#FSWEmbedding-683"><span class="linenos"> 683</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-684"><a href="#FSWEmbedding-684"><span class="linenos"> 684</span></a>        <span class="k">if</span> <span class="s1">&#39;dtype&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
</span><span id="FSWEmbedding-685"><a href="#FSWEmbedding-685"><span class="linenos"> 685</span></a>            <span class="n">arg</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;dtype&#39;</span><span class="p">]</span>
</span><span id="FSWEmbedding-686"><a href="#FSWEmbedding-686"><span class="linenos"> 686</span></a>
</span><span id="FSWEmbedding-687"><a href="#FSWEmbedding-687"><span class="linenos"> 687</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="s1">&#39;invalid input type </span><span class="si">%s</span><span class="s1"> at argument &#39;&#39;dtype&#39;&#39;&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
</span><span id="FSWEmbedding-688"><a href="#FSWEmbedding-688"><span class="linenos"> 688</span></a>            <span class="k">assert</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_floating_point</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_complex</span><span class="p">,</span> <span class="s1">&#39;dtype must be real floating-point; instead got dtype=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">arg</span>
</span><span id="FSWEmbedding-689"><a href="#FSWEmbedding-689"><span class="linenos"> 689</span></a>
</span><span id="FSWEmbedding-690"><a href="#FSWEmbedding-690"><span class="linenos"> 690</span></a>        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
</span><span id="FSWEmbedding-691"><a href="#FSWEmbedding-691"><span class="linenos"> 691</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
</span><span id="FSWEmbedding-692"><a href="#FSWEmbedding-692"><span class="linenos"> 692</span></a>                <span class="k">assert</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_floating_point</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_complex</span><span class="p">,</span> <span class="s1">&#39;dtype must be real floating-point; instead got dtype=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">arg</span>
</span><span id="FSWEmbedding-693"><a href="#FSWEmbedding-693"><span class="linenos"> 693</span></a>
</span><span id="FSWEmbedding-694"><a href="#FSWEmbedding-694"><span class="linenos"> 694</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FSWEmbedding-695"><a href="#FSWEmbedding-695"><span class="linenos"> 695</span></a>
</span><span id="FSWEmbedding-696"><a href="#FSWEmbedding-696"><span class="linenos"> 696</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="FSWEmbedding-697"><a href="#FSWEmbedding-697"><span class="linenos"> 697</span></a>
</span><span id="FSWEmbedding-698"><a href="#FSWEmbedding-698"><span class="linenos"> 698</span></a>
</span><span id="FSWEmbedding-699"><a href="#FSWEmbedding-699"><span class="linenos"> 699</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-700"><a href="#FSWEmbedding-700"><span class="linenos"> 700</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">num_slices</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding-701"><a href="#FSWEmbedding-701"><span class="linenos"> 701</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of slices used in the embedding.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-702"><a href="#FSWEmbedding-702"><span class="linenos"> 702</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span>
</span><span id="FSWEmbedding-703"><a href="#FSWEmbedding-703"><span class="linenos"> 703</span></a>
</span><span id="FSWEmbedding-704"><a href="#FSWEmbedding-704"><span class="linenos"> 704</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-705"><a href="#FSWEmbedding-705"><span class="linenos"> 705</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">num_frequencies</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding-706"><a href="#FSWEmbedding-706"><span class="linenos"> 706</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of frequencies used in the embedding. In Cartesian mode, this is the number of frequencies per slice.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-707"><a href="#FSWEmbedding-707"><span class="linenos"> 707</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span>
</span><span id="FSWEmbedding-708"><a href="#FSWEmbedding-708"><span class="linenos"> 708</span></a>
</span><span id="FSWEmbedding-709"><a href="#FSWEmbedding-709"><span class="linenos"> 709</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-710"><a href="#FSWEmbedding-710"><span class="linenos"> 710</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">cartesian_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding-711"><a href="#FSWEmbedding-711"><span class="linenos"> 711</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;If True, the embedding is computed for each (slice, frequency) pair in the Cartesian product of slices</span>
</span><span id="FSWEmbedding-712"><a href="#FSWEmbedding-712"><span class="linenos"> 712</span></a><span class="sd">        and frequencies.</span>
</span><span id="FSWEmbedding-713"><a href="#FSWEmbedding-713"><span class="linenos"> 713</span></a><span class="sd">        In Cartesian mode, the embeding dimension is `d_out` = `num_slices √ó num_frequencies`.</span>
</span><span id="FSWEmbedding-714"><a href="#FSWEmbedding-714"><span class="linenos"> 714</span></a><span class="sd">        Cartesian mode is activated by providing `num_slices` and `num_frequencies` to `FSWEmbedding.__init__`bool</span>
</span><span id="FSWEmbedding-715"><a href="#FSWEmbedding-715"><span class="linenos"> 715</span></a><span class="sd">        See also: `flatten_cartesian_axes`&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-716"><a href="#FSWEmbedding-716"><span class="linenos"> 716</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span>
</span><span id="FSWEmbedding-717"><a href="#FSWEmbedding-717"><span class="linenos"> 717</span></a>
</span><span id="FSWEmbedding-718"><a href="#FSWEmbedding-718"><span class="linenos"> 718</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-719"><a href="#FSWEmbedding-719"><span class="linenos"> 719</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">flatten_cartesian_axes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding-720"><a href="#FSWEmbedding-720"><span class="linenos"> 720</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;In Cartesian mode, tells Whether the slice and frequency axes are flattened into a single dimension.</span>
</span><span id="FSWEmbedding-721"><a href="#FSWEmbedding-721"><span class="linenos"> 721</span></a><span class="sd">        If True, each input multiset/distribution corresponds to a two-dimensional output, with the shape (`num_slices`, `num_frequencies`).</span>
</span><span id="FSWEmbedding-722"><a href="#FSWEmbedding-722"><span class="linenos"> 722</span></a><span class="sd">        If False, the otput is shaped `num_slices` √ó `num_frequencies`.</span>
</span><span id="FSWEmbedding-723"><a href="#FSWEmbedding-723"><span class="linenos"> 723</span></a><span class="sd">        This setting is only relevant if `cartesian_mode` is True.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-724"><a href="#FSWEmbedding-724"><span class="linenos"> 724</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>
</span><span id="FSWEmbedding-725"><a href="#FSWEmbedding-725"><span class="linenos"> 725</span></a>
</span><span id="FSWEmbedding-726"><a href="#FSWEmbedding-726"><span class="linenos"> 726</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-727"><a href="#FSWEmbedding-727"><span class="linenos"> 727</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">learnable_slices</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding-728"><a href="#FSWEmbedding-728"><span class="linenos"> 728</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether slice directions are learnable parameters.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-729"><a href="#FSWEmbedding-729"><span class="linenos"> 729</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span>
</span><span id="FSWEmbedding-730"><a href="#FSWEmbedding-730"><span class="linenos"> 730</span></a>
</span><span id="FSWEmbedding-731"><a href="#FSWEmbedding-731"><span class="linenos"> 731</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-732"><a href="#FSWEmbedding-732"><span class="linenos"> 732</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">learnable_frequencies</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding-733"><a href="#FSWEmbedding-733"><span class="linenos"> 733</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether frequency values are learnable parameters.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-734"><a href="#FSWEmbedding-734"><span class="linenos"> 734</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span>
</span><span id="FSWEmbedding-735"><a href="#FSWEmbedding-735"><span class="linenos"> 735</span></a>
</span><span id="FSWEmbedding-736"><a href="#FSWEmbedding-736"><span class="linenos"> 736</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-737"><a href="#FSWEmbedding-737"><span class="linenos"> 737</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">enable_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding-738"><a href="#FSWEmbedding-738"><span class="linenos"> 738</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether a learnable bias vector is added to the output embedding.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-739"><a href="#FSWEmbedding-739"><span class="linenos"> 739</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span>
</span><span id="FSWEmbedding-740"><a href="#FSWEmbedding-740"><span class="linenos"> 740</span></a>
</span><span id="FSWEmbedding-741"><a href="#FSWEmbedding-741"><span class="linenos"> 741</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-742"><a href="#FSWEmbedding-742"><span class="linenos"> 742</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">encode_total_mass</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding-743"><a href="#FSWEmbedding-743"><span class="linenos"> 743</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether the total mass of the input measure is encoded into the embedding.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-744"><a href="#FSWEmbedding-744"><span class="linenos"> 744</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span>
</span><span id="FSWEmbedding-745"><a href="#FSWEmbedding-745"><span class="linenos"> 745</span></a>
</span><span id="FSWEmbedding-746"><a href="#FSWEmbedding-746"><span class="linenos"> 746</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-747"><a href="#FSWEmbedding-747"><span class="linenos"> 747</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_encoding_transformation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TotalMassEncodingTransformation</span><span class="p">:</span>
</span><span id="FSWEmbedding-748"><a href="#FSWEmbedding-748"><span class="linenos"> 748</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Function applied to the total mass before it is stored.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-749"><a href="#FSWEmbedding-749"><span class="linenos"> 749</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span>
</span><span id="FSWEmbedding-750"><a href="#FSWEmbedding-750"><span class="linenos"> 750</span></a>
</span><span id="FSWEmbedding-751"><a href="#FSWEmbedding-751"><span class="linenos"> 751</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-752"><a href="#FSWEmbedding-752"><span class="linenos"> 752</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_encoding_method</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TotalMassEncodingMethod</span><span class="p">:</span>
</span><span id="FSWEmbedding-753"><a href="#FSWEmbedding-753"><span class="linenos"> 753</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Strategy used to incorporate total mass into the final embedding vector.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-754"><a href="#FSWEmbedding-754"><span class="linenos"> 754</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span>
</span><span id="FSWEmbedding-755"><a href="#FSWEmbedding-755"><span class="linenos"> 755</span></a>
</span><span id="FSWEmbedding-756"><a href="#FSWEmbedding-756"><span class="linenos"> 756</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-757"><a href="#FSWEmbedding-757"><span class="linenos"> 757</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_encoding_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="FSWEmbedding-758"><a href="#FSWEmbedding-758"><span class="linenos"> 758</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;The encoded total mass is scaled by this factor.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-759"><a href="#FSWEmbedding-759"><span class="linenos"> 759</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_scale</span>
</span><span id="FSWEmbedding-760"><a href="#FSWEmbedding-760"><span class="linenos"> 760</span></a>
</span><span id="FSWEmbedding-761"><a href="#FSWEmbedding-761"><span class="linenos"> 761</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-762"><a href="#FSWEmbedding-762"><span class="linenos"> 762</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_padding_thresh</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="FSWEmbedding-763"><a href="#FSWEmbedding-763"><span class="linenos"> 763</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Minimum total mass threshold; inputs below this value are padded to reach it.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-764"><a href="#FSWEmbedding-764"><span class="linenos"> 764</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span>
</span><span id="FSWEmbedding-765"><a href="#FSWEmbedding-765"><span class="linenos"> 765</span></a>
</span><span id="FSWEmbedding-766"><a href="#FSWEmbedding-766"><span class="linenos"> 766</span></a>
</span><span id="FSWEmbedding-767"><a href="#FSWEmbedding-767"><span class="linenos"> 767</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-768"><a href="#FSWEmbedding-768"><span class="linenos"> 768</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">d_in</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding-769"><a href="#FSWEmbedding-769"><span class="linenos"> 769</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;int: Ambient dimension of the input elements.</span>
</span><span id="FSWEmbedding-770"><a href="#FSWEmbedding-770"><span class="linenos"> 770</span></a>
</span><span id="FSWEmbedding-771"><a href="#FSWEmbedding-771"><span class="linenos"> 771</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding-772"><a href="#FSWEmbedding-772"><span class="linenos"> 772</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding-773"><a href="#FSWEmbedding-773"><span class="linenos"> 773</span></a><span class="sd">        int</span>
</span><span id="FSWEmbedding-774"><a href="#FSWEmbedding-774"><span class="linenos"> 774</span></a><span class="sd">            The input dimensionality of the multiset elements (i.e., the last dimension of the input tensors).</span>
</span><span id="FSWEmbedding-775"><a href="#FSWEmbedding-775"><span class="linenos"> 775</span></a>
</span><span id="FSWEmbedding-776"><a href="#FSWEmbedding-776"><span class="linenos"> 776</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding-777"><a href="#FSWEmbedding-777"><span class="linenos"> 777</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding-778"><a href="#FSWEmbedding-778"><span class="linenos"> 778</span></a><span class="sd">        This value is set at initialization and determines the expected feature dimension of input points.</span>
</span><span id="FSWEmbedding-779"><a href="#FSWEmbedding-779"><span class="linenos"> 779</span></a>
</span><span id="FSWEmbedding-780"><a href="#FSWEmbedding-780"><span class="linenos"> 780</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding-781"><a href="#FSWEmbedding-781"><span class="linenos"> 781</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding-782"><a href="#FSWEmbedding-782"><span class="linenos"> 782</span></a><span class="sd">        __init__ : The `d_in` argument specifies this value at initialization.</span>
</span><span id="FSWEmbedding-783"><a href="#FSWEmbedding-783"><span class="linenos"> 783</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-784"><a href="#FSWEmbedding-784"><span class="linenos"> 784</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span>
</span><span id="FSWEmbedding-785"><a href="#FSWEmbedding-785"><span class="linenos"> 785</span></a>
</span><span id="FSWEmbedding-786"><a href="#FSWEmbedding-786"><span class="linenos"> 786</span></a>
</span><span id="FSWEmbedding-787"><a href="#FSWEmbedding-787"><span class="linenos"> 787</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-788"><a href="#FSWEmbedding-788"><span class="linenos"> 788</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">d_out</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding-789"><a href="#FSWEmbedding-789"><span class="linenos"> 789</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;int: Dimensionality of the embedding output.</span>
</span><span id="FSWEmbedding-790"><a href="#FSWEmbedding-790"><span class="linenos"> 790</span></a>
</span><span id="FSWEmbedding-791"><a href="#FSWEmbedding-791"><span class="linenos"> 791</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding-792"><a href="#FSWEmbedding-792"><span class="linenos"> 792</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding-793"><a href="#FSWEmbedding-793"><span class="linenos"> 793</span></a><span class="sd">        int</span>
</span><span id="FSWEmbedding-794"><a href="#FSWEmbedding-794"><span class="linenos"> 794</span></a><span class="sd">            The dimension of the vector produced by the embedding for each multiset or distribution.</span>
</span><span id="FSWEmbedding-795"><a href="#FSWEmbedding-795"><span class="linenos"> 795</span></a>
</span><span id="FSWEmbedding-796"><a href="#FSWEmbedding-796"><span class="linenos"> 796</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding-797"><a href="#FSWEmbedding-797"><span class="linenos"> 797</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding-798"><a href="#FSWEmbedding-798"><span class="linenos"> 798</span></a><span class="sd">        This value is set at initialization and governs the size of the embedding output.</span>
</span><span id="FSWEmbedding-799"><a href="#FSWEmbedding-799"><span class="linenos"> 799</span></a>
</span><span id="FSWEmbedding-800"><a href="#FSWEmbedding-800"><span class="linenos"> 800</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding-801"><a href="#FSWEmbedding-801"><span class="linenos"> 801</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding-802"><a href="#FSWEmbedding-802"><span class="linenos"> 802</span></a><span class="sd">        __init__ : The `d_out` argument specifies this value at initialization.</span>
</span><span id="FSWEmbedding-803"><a href="#FSWEmbedding-803"><span class="linenos"> 803</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-804"><a href="#FSWEmbedding-804"><span class="linenos"> 804</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span>
</span><span id="FSWEmbedding-805"><a href="#FSWEmbedding-805"><span class="linenos"> 805</span></a>
</span><span id="FSWEmbedding-806"><a href="#FSWEmbedding-806"><span class="linenos"> 806</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-807"><a href="#FSWEmbedding-807"><span class="linenos"> 807</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FSWEmbedding-808"><a href="#FSWEmbedding-808"><span class="linenos"> 808</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;torch.device: The device on which the module&#39;s parameters and buffers are stored.</span>
</span><span id="FSWEmbedding-809"><a href="#FSWEmbedding-809"><span class="linenos"> 809</span></a>
</span><span id="FSWEmbedding-810"><a href="#FSWEmbedding-810"><span class="linenos"> 810</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding-811"><a href="#FSWEmbedding-811"><span class="linenos"> 811</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding-812"><a href="#FSWEmbedding-812"><span class="linenos"> 812</span></a><span class="sd">        torch.device</span>
</span><span id="FSWEmbedding-813"><a href="#FSWEmbedding-813"><span class="linenos"> 813</span></a><span class="sd">            The PyTorch device (`&#39;cpu&#39;`, `&#39;cuda&#39;`, etc.) where the embedding computations will take place.</span>
</span><span id="FSWEmbedding-814"><a href="#FSWEmbedding-814"><span class="linenos"> 814</span></a>
</span><span id="FSWEmbedding-815"><a href="#FSWEmbedding-815"><span class="linenos"> 815</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding-816"><a href="#FSWEmbedding-816"><span class="linenos"> 816</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding-817"><a href="#FSWEmbedding-817"><span class="linenos"> 817</span></a><span class="sd">        This behaves like the `device` property in standard PyTorch modules.</span>
</span><span id="FSWEmbedding-818"><a href="#FSWEmbedding-818"><span class="linenos"> 818</span></a>
</span><span id="FSWEmbedding-819"><a href="#FSWEmbedding-819"><span class="linenos"> 819</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding-820"><a href="#FSWEmbedding-820"><span class="linenos"> 820</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding-821"><a href="#FSWEmbedding-821"><span class="linenos"> 821</span></a><span class="sd">        __init__ : The `device` can be specified at initialization.</span>
</span><span id="FSWEmbedding-822"><a href="#FSWEmbedding-822"><span class="linenos"> 822</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-823"><a href="#FSWEmbedding-823"><span class="linenos"> 823</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">device</span>
</span><span id="FSWEmbedding-824"><a href="#FSWEmbedding-824"><span class="linenos"> 824</span></a>
</span><span id="FSWEmbedding-825"><a href="#FSWEmbedding-825"><span class="linenos"> 825</span></a>
</span><span id="FSWEmbedding-826"><a href="#FSWEmbedding-826"><span class="linenos"> 826</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding-827"><a href="#FSWEmbedding-827"><span class="linenos"> 827</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FSWEmbedding-828"><a href="#FSWEmbedding-828"><span class="linenos"> 828</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;torch.dtype: The default data type used by the module.</span>
</span><span id="FSWEmbedding-829"><a href="#FSWEmbedding-829"><span class="linenos"> 829</span></a>
</span><span id="FSWEmbedding-830"><a href="#FSWEmbedding-830"><span class="linenos"> 830</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding-831"><a href="#FSWEmbedding-831"><span class="linenos"> 831</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding-832"><a href="#FSWEmbedding-832"><span class="linenos"> 832</span></a><span class="sd">        torch.dtype</span>
</span><span id="FSWEmbedding-833"><a href="#FSWEmbedding-833"><span class="linenos"> 833</span></a><span class="sd">            The data type (`torch.float32`, `torch.float64`, etc.) of the module‚Äôs parameters and buffers.</span>
</span><span id="FSWEmbedding-834"><a href="#FSWEmbedding-834"><span class="linenos"> 834</span></a>
</span><span id="FSWEmbedding-835"><a href="#FSWEmbedding-835"><span class="linenos"> 835</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding-836"><a href="#FSWEmbedding-836"><span class="linenos"> 836</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding-837"><a href="#FSWEmbedding-837"><span class="linenos"> 837</span></a><span class="sd">        This behaves like the `dtype` property in standard PyTorch modules.</span>
</span><span id="FSWEmbedding-838"><a href="#FSWEmbedding-838"><span class="linenos"> 838</span></a>
</span><span id="FSWEmbedding-839"><a href="#FSWEmbedding-839"><span class="linenos"> 839</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding-840"><a href="#FSWEmbedding-840"><span class="linenos"> 840</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding-841"><a href="#FSWEmbedding-841"><span class="linenos"> 841</span></a><span class="sd">        __init__ : The `dtype` can be specified at initialization.</span>
</span><span id="FSWEmbedding-842"><a href="#FSWEmbedding-842"><span class="linenos"> 842</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-843"><a href="#FSWEmbedding-843"><span class="linenos"> 843</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="FSWEmbedding-844"><a href="#FSWEmbedding-844"><span class="linenos"> 844</span></a>
</span><span id="FSWEmbedding-845"><a href="#FSWEmbedding-845"><span class="linenos"> 845</span></a>
</span><span id="FSWEmbedding-846"><a href="#FSWEmbedding-846"><span class="linenos"> 846</span></a>    <span class="nd">@staticmethod</span>
</span><span id="FSWEmbedding-847"><a href="#FSWEmbedding-847"><span class="linenos"> 847</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_embedding_parameters</span><span class="p">(</span><span class="n">d_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="FSWEmbedding-848"><a href="#FSWEmbedding-848"><span class="linenos"> 848</span></a>                                       <span class="n">num_slices</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="FSWEmbedding-849"><a href="#FSWEmbedding-849"><span class="linenos"> 849</span></a>                                       <span class="n">num_frequencies</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="FSWEmbedding-850"><a href="#FSWEmbedding-850"><span class="linenos"> 850</span></a>                                       <span class="n">cartesian_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="FSWEmbedding-851"><a href="#FSWEmbedding-851"><span class="linenos"> 851</span></a>                                       <span class="n">flatten_cartesian_axes</span> <span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="FSWEmbedding-852"><a href="#FSWEmbedding-852"><span class="linenos"> 852</span></a>                                       <span class="n">total_mass_encoding_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="FSWEmbedding-853"><a href="#FSWEmbedding-853"><span class="linenos"> 853</span></a>                                       <span class="n">frequency_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">FrequencyInitMethod</span><span class="p">,</span>
</span><span id="FSWEmbedding-854"><a href="#FSWEmbedding-854"><span class="linenos"> 854</span></a>                                       <span class="n">minimize_slice_coherence</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="FSWEmbedding-855"><a href="#FSWEmbedding-855"><span class="linenos"> 855</span></a>                                       <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-856"><a href="#FSWEmbedding-856"><span class="linenos"> 856</span></a>                                       <span class="n">report</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="FSWEmbedding-857"><a href="#FSWEmbedding-857"><span class="linenos"> 857</span></a>                                       <span class="n">report_on_coherence_minimization</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
</span><span id="FSWEmbedding-858"><a href="#FSWEmbedding-858"><span class="linenos"> 858</span></a>        <span class="n">dtype_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>
</span><span id="FSWEmbedding-859"><a href="#FSWEmbedding-859"><span class="linenos"> 859</span></a>
</span><span id="FSWEmbedding-860"><a href="#FSWEmbedding-860"><span class="linenos"> 860</span></a>        <span class="c1"># Axis number for the ambient space R^d_in</span>
</span><span id="FSWEmbedding-861"><a href="#FSWEmbedding-861"><span class="linenos"> 861</span></a>        <span class="n">ambspace_axis</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="FSWEmbedding-862"><a href="#FSWEmbedding-862"><span class="linenos"> 862</span></a>
</span><span id="FSWEmbedding-863"><a href="#FSWEmbedding-863"><span class="linenos"> 863</span></a>        <span class="c1">### A. Generate slice vectors</span>
</span><span id="FSWEmbedding-864"><a href="#FSWEmbedding-864"><span class="linenos"> 864</span></a>
</span><span id="FSWEmbedding-865"><a href="#FSWEmbedding-865"><span class="linenos"> 865</span></a>        <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">d_in</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-866"><a href="#FSWEmbedding-866"><span class="linenos"> 866</span></a>        <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">ambspace_axis</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="FSWEmbedding-867"><a href="#FSWEmbedding-867"><span class="linenos"> 867</span></a>
</span><span id="FSWEmbedding-868"><a href="#FSWEmbedding-868"><span class="linenos"> 868</span></a>        <span class="k">if</span> <span class="n">minimize_slice_coherence</span><span class="p">:</span>
</span><span id="FSWEmbedding-869"><a href="#FSWEmbedding-869"><span class="linenos"> 869</span></a>            <span class="k">if</span> <span class="p">(</span><span class="n">num_slices</span> <span class="o">&gt;</span> <span class="n">d_in</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="FSWEmbedding-870"><a href="#FSWEmbedding-870"><span class="linenos"> 870</span></a>                <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">minimize_mutual_coherence</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="n">report</span><span class="o">=</span><span class="n">report_on_coherence_minimization</span><span class="p">)</span>
</span><span id="FSWEmbedding-871"><a href="#FSWEmbedding-871"><span class="linenos"> 871</span></a>                <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Generated </span><span class="si">%d</span><span class="s1"> slice vectors in R^</span><span class="si">%d</span><span class="s1"> with minimized mutual coherence&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">d_in</span><span class="p">))</span>
</span><span id="FSWEmbedding-872"><a href="#FSWEmbedding-872"><span class="linenos"> 872</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-873"><a href="#FSWEmbedding-873"><span class="linenos"> 873</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;num_slices: &#39;</span><span class="p">,</span> <span class="n">num_slices</span><span class="p">,</span> <span class="s1">&#39;d_in: &#39;</span><span class="p">,</span> <span class="n">d_in</span><span class="p">)</span>
</span><span id="FSWEmbedding-874"><a href="#FSWEmbedding-874"><span class="linenos"> 874</span></a>                <span class="c1"># Here we need to compute a set of num_slices orthogonal vectors in R^d_in.</span>
</span><span id="FSWEmbedding-875"><a href="#FSWEmbedding-875"><span class="linenos"> 875</span></a>                <span class="c1"># Below are two methods to do so: SVD and QR decomposition</span>
</span><span id="FSWEmbedding-876"><a href="#FSWEmbedding-876"><span class="linenos"> 876</span></a>                <span class="c1"># In some cases with little available memory, SVD seems more resilient, whereas QR sometimes crashes.</span>
</span><span id="FSWEmbedding-877"><a href="#FSWEmbedding-877"><span class="linenos"> 877</span></a>                <span class="n">use_svd</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="FSWEmbedding-878"><a href="#FSWEmbedding-878"><span class="linenos"> 878</span></a>
</span><span id="FSWEmbedding-879"><a href="#FSWEmbedding-879"><span class="linenos"> 879</span></a>                <span class="k">if</span> <span class="n">use_svd</span><span class="p">:</span>
</span><span id="FSWEmbedding-880"><a href="#FSWEmbedding-880"><span class="linenos"> 880</span></a>                    <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="FSWEmbedding-881"><a href="#FSWEmbedding-881"><span class="linenos"> 881</span></a>                    <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">Vh</span>
</span><span id="FSWEmbedding-882"><a href="#FSWEmbedding-882"><span class="linenos"> 882</span></a>                    <span class="k">del</span> <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vh</span>
</span><span id="FSWEmbedding-883"><a href="#FSWEmbedding-883"><span class="linenos"> 883</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-884"><a href="#FSWEmbedding-884"><span class="linenos"> 884</span></a>                    <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">slice_vectors</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-885"><a href="#FSWEmbedding-885"><span class="linenos"> 885</span></a>                    <span class="n">slice_vectors</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;reduced&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-886"><a href="#FSWEmbedding-886"><span class="linenos"> 886</span></a>                    <span class="k">del</span> <span class="n">R</span>
</span><span id="FSWEmbedding-887"><a href="#FSWEmbedding-887"><span class="linenos"> 887</span></a>                    <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">slice_vectors</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-888"><a href="#FSWEmbedding-888"><span class="linenos"> 888</span></a>                <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Generated </span><span class="si">%d</span><span class="s1"> perpendicular slice vectors in R^</span><span class="si">%d</span><span class="s1"> using QR decomposition&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">d_in</span><span class="p">))</span>
</span><span id="FSWEmbedding-889"><a href="#FSWEmbedding-889"><span class="linenos"> 889</span></a>
</span><span id="FSWEmbedding-890"><a href="#FSWEmbedding-890"><span class="linenos"> 890</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-891"><a href="#FSWEmbedding-891"><span class="linenos"> 891</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Generated </span><span class="si">%d</span><span class="s1"> random slice vectors&#39;</span> <span class="o">%</span> <span class="n">num_slices</span><span class="p">)</span>
</span><span id="FSWEmbedding-892"><a href="#FSWEmbedding-892"><span class="linenos"> 892</span></a>
</span><span id="FSWEmbedding-893"><a href="#FSWEmbedding-893"><span class="linenos"> 893</span></a>        <span class="c1"># Detect nans, infs and zero vectors in slice_vectors</span>
</span><span id="FSWEmbedding-894"><a href="#FSWEmbedding-894"><span class="linenos"> 894</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;Found infs in slice_vectors&quot;</span>
</span><span id="FSWEmbedding-895"><a href="#FSWEmbedding-895"><span class="linenos"> 895</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;Found nans in slice_vectors&quot;</span>
</span><span id="FSWEmbedding-896"><a href="#FSWEmbedding-896"><span class="linenos"> 896</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span><span class="n">slice_vectors</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Found zero vectors in slice_vectors&#39;</span>
</span><span id="FSWEmbedding-897"><a href="#FSWEmbedding-897"><span class="linenos"> 897</span></a>
</span><span id="FSWEmbedding-898"><a href="#FSWEmbedding-898"><span class="linenos"> 898</span></a>
</span><span id="FSWEmbedding-899"><a href="#FSWEmbedding-899"><span class="linenos"> 899</span></a>
</span><span id="FSWEmbedding-900"><a href="#FSWEmbedding-900"><span class="linenos"> 900</span></a>        <span class="c1">### B. Generate frequencies</span>
</span><span id="FSWEmbedding-901"><a href="#FSWEmbedding-901"><span class="linenos"> 901</span></a>        <span class="n">freqs_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_frequencies</span><span class="p">,)</span> <span class="c1"># Note: Changing this to (self.num_frequencies, 1) yields incorrect results in self.forward()</span>
</span><span id="FSWEmbedding-902"><a href="#FSWEmbedding-902"><span class="linenos"> 902</span></a>
</span><span id="FSWEmbedding-903"><a href="#FSWEmbedding-903"><span class="linenos"> 903</span></a>        <span class="k">if</span> <span class="n">num_frequencies</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-904"><a href="#FSWEmbedding-904"><span class="linenos"> 904</span></a>            <span class="n">frequencies</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">freqs_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-905"><a href="#FSWEmbedding-905"><span class="linenos"> 905</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Initialized 0 frequencies&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-906"><a href="#FSWEmbedding-906"><span class="linenos"> 906</span></a>
</span><span id="FSWEmbedding-907"><a href="#FSWEmbedding-907"><span class="linenos"> 907</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Real</span><span class="p">):</span>
</span><span id="FSWEmbedding-908"><a href="#FSWEmbedding-908"><span class="linenos"> 908</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">),</span> <span class="s1">&#39;frequency_init cannot be infinite&#39;</span>
</span><span id="FSWEmbedding-909"><a href="#FSWEmbedding-909"><span class="linenos"> 909</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">),</span> <span class="s1">&#39;frequency_init cannot be NaN&#39;</span>
</span><span id="FSWEmbedding-910"><a href="#FSWEmbedding-910"><span class="linenos"> 910</span></a>            <span class="n">frequencies</span> <span class="o">=</span> <span class="n">frequency_init</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">freqs_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-911"><a href="#FSWEmbedding-911"><span class="linenos"> 911</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Initialized </span><span class="si">%d</span><span class="s1"> frequencies to </span><span class="si">%g</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_frequencies</span><span class="p">,</span> <span class="n">frequency_init</span><span class="p">))</span>
</span><span id="FSWEmbedding-912"><a href="#FSWEmbedding-912"><span class="linenos"> 912</span></a>
</span><span id="FSWEmbedding-913"><a href="#FSWEmbedding-913"><span class="linenos"> 913</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
</span><span id="FSWEmbedding-914"><a href="#FSWEmbedding-914"><span class="linenos"> 914</span></a>            <span class="c1"># Here frequency_init should have been type-enforced to be a tuple of two real numbers.</span>
</span><span id="FSWEmbedding-915"><a href="#FSWEmbedding-915"><span class="linenos"> 915</span></a>            <span class="c1"># However, it does not prevent the tuple from containing more numbers.</span>
</span><span id="FSWEmbedding-916"><a href="#FSWEmbedding-916"><span class="linenos"> 916</span></a>            <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">)</span><span class="o">==</span><span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;When frequency_init is a tuple, it must be of length 2&#39;</span>
</span><span id="FSWEmbedding-917"><a href="#FSWEmbedding-917"><span class="linenos"> 917</span></a>
</span><span id="FSWEmbedding-918"><a href="#FSWEmbedding-918"><span class="linenos"> 918</span></a>            <span class="n">a</span> <span class="o">=</span> <span class="n">frequency_init</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FSWEmbedding-919"><a href="#FSWEmbedding-919"><span class="linenos"> 919</span></a>            <span class="n">b</span> <span class="o">=</span> <span class="n">frequency_init</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="FSWEmbedding-920"><a href="#FSWEmbedding-920"><span class="linenos"> 920</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="s1">&#39;Received infinite value in frequency_init tuple&#39;</span>
</span><span id="FSWEmbedding-921"><a href="#FSWEmbedding-921"><span class="linenos"> 921</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="s1">&#39;Received NaN value in frequency_init tuple&#39;</span>
</span><span id="FSWEmbedding-922"><a href="#FSWEmbedding-922"><span class="linenos"> 922</span></a>            <span class="k">assert</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">b</span><span class="p">,</span> <span class="s1">&#39;When frequency_init is a tuple, it is required to satisfy frequency_init[0] &lt;= frequency_init[1]&#39;</span>
</span><span id="FSWEmbedding-923"><a href="#FSWEmbedding-923"><span class="linenos"> 923</span></a>
</span><span id="FSWEmbedding-924"><a href="#FSWEmbedding-924"><span class="linenos"> 924</span></a>            <span class="k">if</span> <span class="n">num_frequencies</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FSWEmbedding-925"><a href="#FSWEmbedding-925"><span class="linenos"> 925</span></a>                <span class="n">frequencies</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">freqs_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-926"><a href="#FSWEmbedding-926"><span class="linenos"> 926</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-927"><a href="#FSWEmbedding-927"><span class="linenos"> 927</span></a>                <span class="n">frequencies</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="p">(</span><span class="n">b</span><span class="o">-</span><span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_frequencies</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">num_frequencies</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-928"><a href="#FSWEmbedding-928"><span class="linenos"> 928</span></a>
</span><span id="FSWEmbedding-929"><a href="#FSWEmbedding-929"><span class="linenos"> 929</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Initialized </span><span class="si">%d</span><span class="s1"> equispaced frequencies in the interval [</span><span class="si">%d</span><span class="s1">, </span><span class="si">%d</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_frequencies</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span>
</span><span id="FSWEmbedding-930"><a href="#FSWEmbedding-930"><span class="linenos"> 930</span></a>
</span><span id="FSWEmbedding-931"><a href="#FSWEmbedding-931"><span class="linenos"> 931</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-932"><a href="#FSWEmbedding-932"><span class="linenos"> 932</span></a>            <span class="n">frequency_init</span> <span class="o">=</span> <span class="n">FrequencyInitMethod</span><span class="o">.</span><span class="n">resolve</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">)</span>
</span><span id="FSWEmbedding-933"><a href="#FSWEmbedding-933"><span class="linenos"> 933</span></a>
</span><span id="FSWEmbedding-934"><a href="#FSWEmbedding-934"><span class="linenos"> 934</span></a>            <span class="k">if</span> <span class="n">frequency_init</span> <span class="o">==</span> <span class="n">FrequencyInitMethod</span><span class="o">.</span><span class="n">RANDOM</span><span class="p">:</span>
</span><span id="FSWEmbedding-935"><a href="#FSWEmbedding-935"><span class="linenos"> 935</span></a>                <span class="n">frequencies</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">freqs_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-936"><a href="#FSWEmbedding-936"><span class="linenos"> 936</span></a>                <span class="n">frequencies</span><span class="p">,</span> <span class="n">junk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="FSWEmbedding-937"><a href="#FSWEmbedding-937"><span class="linenos"> 937</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="n">frequencies</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s2">&quot;Unexpected behavior of torch.rand(): Returned a value of 1, whereas values are supposed to be in [0,1)&quot;</span>
</span><span id="FSWEmbedding-938"><a href="#FSWEmbedding-938"><span class="linenos"> 938</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="n">frequencies</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s2">&quot;Unexpected behavior of torch.rand(): Returned a value &gt; 1, whereas values are supposed to be in [0,1)&quot;</span>
</span><span id="FSWEmbedding-939"><a href="#FSWEmbedding-939"><span class="linenos"> 939</span></a>                <span class="n">frequencies</span> <span class="o">=</span> <span class="n">frequencies</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-940"><a href="#FSWEmbedding-940"><span class="linenos"> 940</span></a>
</span><span id="FSWEmbedding-941"><a href="#FSWEmbedding-941"><span class="linenos"> 941</span></a>                <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Initialized </span><span class="si">%d</span><span class="s1"> random frequencies i.i.d. with density f(x) = 1/(1+x)^2, x</span><span class="se">\u2265</span><span class="s1">0&#39;</span> <span class="o">%</span> <span class="n">num_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-942"><a href="#FSWEmbedding-942"><span class="linenos"> 942</span></a>
</span><span id="FSWEmbedding-943"><a href="#FSWEmbedding-943"><span class="linenos"> 943</span></a>            <span class="k">elif</span> <span class="n">frequency_init</span> <span class="o">==</span> <span class="n">FrequencyInitMethod</span><span class="o">.</span><span class="n">EVEN</span><span class="p">:</span>
</span><span id="FSWEmbedding-944"><a href="#FSWEmbedding-944"><span class="linenos"> 944</span></a>                <span class="n">frequencies</span> <span class="o">=</span> <span class="p">(</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_frequencies</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">freqs_shape</span><span class="p">)</span> <span class="p">)</span> <span class="o">/</span> <span class="n">num_frequencies</span>
</span><span id="FSWEmbedding-945"><a href="#FSWEmbedding-945"><span class="linenos"> 945</span></a>                <span class="n">frequencies</span> <span class="o">=</span> <span class="n">frequencies</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-946"><a href="#FSWEmbedding-946"><span class="linenos"> 946</span></a>                <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;- Initialized </span><span class="si">%d</span><span class="s1"> frequencies spread evenly in [</span><span class="si">%g</span><span class="s1">, </span><span class="si">%g</span><span class="s1">] according to probability density&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_frequencies</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">frequencies</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</span><span id="FSWEmbedding-947"><a href="#FSWEmbedding-947"><span class="linenos"> 947</span></a>
</span><span id="FSWEmbedding-948"><a href="#FSWEmbedding-948"><span class="linenos"> 948</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-949"><a href="#FSWEmbedding-949"><span class="linenos"> 949</span></a>                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Invalid value for argument frequency_init; expected number, tuple (a,b) of numbers denoting an interval, </span><span class="se">\&#39;</span><span class="s1">random</span><span class="se">\&#39;</span><span class="s1"> or </span><span class="se">\&#39;</span><span class="s1">spread</span><span class="se">\&#39;</span><span class="s1">&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding-950"><a href="#FSWEmbedding-950"><span class="linenos"> 950</span></a>
</span><span id="FSWEmbedding-951"><a href="#FSWEmbedding-951"><span class="linenos"> 951</span></a>        <span class="c1"># Detect nan and inf entries in frequencies</span>
</span><span id="FSWEmbedding-952"><a href="#FSWEmbedding-952"><span class="linenos"> 952</span></a>        <span class="k">if</span> <span class="n">num_frequencies</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-953"><a href="#FSWEmbedding-953"><span class="linenos"> 953</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">frequencies</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;Found infs in frequencies&quot;</span>
</span><span id="FSWEmbedding-954"><a href="#FSWEmbedding-954"><span class="linenos"> 954</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">frequencies</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;Found nans in frequencies&quot;</span>
</span><span id="FSWEmbedding-955"><a href="#FSWEmbedding-955"><span class="linenos"> 955</span></a>
</span><span id="FSWEmbedding-956"><a href="#FSWEmbedding-956"><span class="linenos"> 956</span></a>        <span class="c1"># C. Generate bias vector. Always initialized to zero.</span>
</span><span id="FSWEmbedding-957"><a href="#FSWEmbedding-957"><span class="linenos"> 957</span></a>        <span class="k">if</span> <span class="n">cartesian_mode</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding-958"><a href="#FSWEmbedding-958"><span class="linenos"> 958</span></a>            <span class="n">bias_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-959"><a href="#FSWEmbedding-959"><span class="linenos"> 959</span></a>        <span class="k">elif</span> <span class="n">cartesian_mode</span> <span class="ow">and</span> <span class="n">flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding-960"><a href="#FSWEmbedding-960"><span class="linenos"> 960</span></a>            <span class="n">bias_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_slices</span><span class="o">*</span><span class="n">num_frequencies</span> <span class="o">+</span> <span class="n">total_mass_encoding_dim</span><span class="p">,)</span>
</span><span id="FSWEmbedding-961"><a href="#FSWEmbedding-961"><span class="linenos"> 961</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-962"><a href="#FSWEmbedding-962"><span class="linenos"> 962</span></a>            <span class="n">bias_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_slices</span> <span class="o">+</span> <span class="n">total_mass_encoding_dim</span><span class="p">,)</span>
</span><span id="FSWEmbedding-963"><a href="#FSWEmbedding-963"><span class="linenos"> 963</span></a>
</span><span id="FSWEmbedding-964"><a href="#FSWEmbedding-964"><span class="linenos"> 964</span></a>        <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">bias_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype_init</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-965"><a href="#FSWEmbedding-965"><span class="linenos"> 965</span></a>
</span><span id="FSWEmbedding-966"><a href="#FSWEmbedding-966"><span class="linenos"> 966</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span><span id="FSWEmbedding-967"><a href="#FSWEmbedding-967"><span class="linenos"> 967</span></a>
</span><span id="FSWEmbedding-968"><a href="#FSWEmbedding-968"><span class="linenos"> 968</span></a>        <span class="k">return</span> <span class="n">slice_vectors</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">,</span> <span class="n">bias</span>
</span><span id="FSWEmbedding-969"><a href="#FSWEmbedding-969"><span class="linenos"> 969</span></a>
</span><span id="FSWEmbedding-970"><a href="#FSWEmbedding-970"><span class="linenos"> 970</span></a>
</span><span id="FSWEmbedding-971"><a href="#FSWEmbedding-971"><span class="linenos"> 971</span></a>
</span><span id="FSWEmbedding-972"><a href="#FSWEmbedding-972"><span class="linenos"> 972</span></a>    <span class="c1"># Spreads the frequencies on an interval centered at &#39;center&#39; with the given radius, in an equispaced manner.</span>
</span><span id="FSWEmbedding-973"><a href="#FSWEmbedding-973"><span class="linenos"> 973</span></a>    <span class="c1"># This might be useful when using the embedding for graph message passing with learnable_slices=True, as the magnitude of the</span>
</span><span id="FSWEmbedding-974"><a href="#FSWEmbedding-974"><span class="linenos"> 974</span></a>    <span class="c1"># slice vectors already determines the effective frequency, and having a very high max-frequency-to-low-frequency ratio</span>
</span><span id="FSWEmbedding-975"><a href="#FSWEmbedding-975"><span class="linenos"> 975</span></a>    <span class="c1"># may impede the optimization due to ill conditioning.</span>
</span><span id="FSWEmbedding-976"><a href="#FSWEmbedding-976"><span class="linenos"> 976</span></a>
</span><span id="FSWEmbedding-977"><a href="#FSWEmbedding-977"><span class="linenos"> 977</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_spread_freqs_at_interval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">center</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">,</span> <span class="n">radius</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">):</span>
</span><span id="FSWEmbedding-978"><a href="#FSWEmbedding-978"><span class="linenos"> 978</span></a>        <span class="k">assert</span> <span class="n">radius</span> <span class="o">&gt;=</span> <span class="mi">0</span>
</span><span id="FSWEmbedding-979"><a href="#FSWEmbedding-979"><span class="linenos"> 979</span></a>
</span><span id="FSWEmbedding-980"><a href="#FSWEmbedding-980"><span class="linenos"> 980</span></a>        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">radius</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="FSWEmbedding-981"><a href="#FSWEmbedding-981"><span class="linenos"> 981</span></a>            <span class="n">freqs_new</span> <span class="o">=</span> <span class="n">center</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-982"><a href="#FSWEmbedding-982"><span class="linenos"> 982</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-983"><a href="#FSWEmbedding-983"><span class="linenos"> 983</span></a>            <span class="n">spread</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="FSWEmbedding-984"><a href="#FSWEmbedding-984"><span class="linenos"> 984</span></a>            <span class="n">spread</span> <span class="o">=</span> <span class="n">spread</span> <span class="o">*</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-985"><a href="#FSWEmbedding-985"><span class="linenos"> 985</span></a>            <span class="n">freqs_new</span> <span class="o">=</span> <span class="n">center</span> <span class="o">+</span> <span class="n">radius</span> <span class="o">*</span> <span class="n">spread</span>
</span><span id="FSWEmbedding-986"><a href="#FSWEmbedding-986"><span class="linenos"> 986</span></a>
</span><span id="FSWEmbedding-987"><a href="#FSWEmbedding-987"><span class="linenos"> 987</span></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</span><span id="FSWEmbedding-988"><a href="#FSWEmbedding-988"><span class="linenos"> 988</span></a>        <span class="n">state_dict</span><span class="p">[</span><span class="s1">&#39;frequencies&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">freqs_new</span>
</span><span id="FSWEmbedding-989"><a href="#FSWEmbedding-989"><span class="linenos"> 989</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span><span id="FSWEmbedding-990"><a href="#FSWEmbedding-990"><span class="linenos"> 990</span></a>
</span><span id="FSWEmbedding-991"><a href="#FSWEmbedding-991"><span class="linenos"> 991</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span><span id="FSWEmbedding-992"><a href="#FSWEmbedding-992"><span class="linenos"> 992</span></a>
</span><span id="FSWEmbedding-993"><a href="#FSWEmbedding-993"><span class="linenos"> 993</span></a>
</span><span id="FSWEmbedding-994"><a href="#FSWEmbedding-994"><span class="linenos"> 994</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FSWEmbedding-995"><a href="#FSWEmbedding-995"><span class="linenos"> 995</span></a>                <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="FSWEmbedding-996"><a href="#FSWEmbedding-996"><span class="linenos"> 996</span></a>                <span class="n">W</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;unit&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="s1">&#39;unit&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding-997"><a href="#FSWEmbedding-997"><span class="linenos"> 997</span></a>                <span class="n">X_edge</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding-998"><a href="#FSWEmbedding-998"><span class="linenos"> 998</span></a>                <span class="n">graph_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-999"><a href="#FSWEmbedding-999"><span class="linenos"> 999</span></a>                <span class="n">max_parallel_slices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding-1000"><a href="#FSWEmbedding-1000"><span class="linenos">1000</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-1001"><a href="#FSWEmbedding-1001"><span class="linenos">1001</span></a><span class="sd">        Compute the FSW embedding of an input multiset, measure, or graph.</span>
</span><span id="FSWEmbedding-1002"><a href="#FSWEmbedding-1002"><span class="linenos">1002</span></a>
</span><span id="FSWEmbedding-1003"><a href="#FSWEmbedding-1003"><span class="linenos">1003</span></a><span class="sd">        This method maps input sets of vectors (optionally weighted) to vectors in ‚Ñù^{d_out}</span>
</span><span id="FSWEmbedding-1004"><a href="#FSWEmbedding-1004"><span class="linenos">1004</span></a><span class="sd">        using the Fourier Sliced-Wasserstein (FSW) embedding. It supports batched inputs and</span>
</span><span id="FSWEmbedding-1005"><a href="#FSWEmbedding-1005"><span class="linenos">1005</span></a><span class="sd">        graph-based neighbor aggregation, with possibly sparse weight/adjacency matrices.</span>
</span><span id="FSWEmbedding-1006"><a href="#FSWEmbedding-1006"><span class="linenos">1006</span></a>
</span><span id="FSWEmbedding-1007"><a href="#FSWEmbedding-1007"><span class="linenos">1007</span></a><span class="sd">        Parameters</span>
</span><span id="FSWEmbedding-1008"><a href="#FSWEmbedding-1008"><span class="linenos">1008</span></a><span class="sd">        ----------</span>
</span><span id="FSWEmbedding-1009"><a href="#FSWEmbedding-1009"><span class="linenos">1009</span></a><span class="sd">        X : torch.Tensor</span>
</span><span id="FSWEmbedding-1010"><a href="#FSWEmbedding-1010"><span class="linenos">1010</span></a><span class="sd">            Input tensor of shape `(n, d_in)` or `(..., n, d_in)` for batched input.</span>
</span><span id="FSWEmbedding-1011"><a href="#FSWEmbedding-1011"><span class="linenos">1011</span></a><span class="sd">        W : torch.Tensor or {&#39;unit&#39;, &#39;uniform&#39;}, default=&#39;unit&#39;</span>
</span><span id="FSWEmbedding-1012"><a href="#FSWEmbedding-1012"><span class="linenos">1012</span></a><span class="sd">            Weights tensor of shape `(n,)` or `(..., n)` corresponding to point importance.</span>
</span><span id="FSWEmbedding-1013"><a href="#FSWEmbedding-1013"><span class="linenos">1013</span></a><span class="sd">            If set to `&#39;unit&#39;` or `&#39;uniform&#39;`, uniform weights of `1/n` are assumed.</span>
</span><span id="FSWEmbedding-1014"><a href="#FSWEmbedding-1014"><span class="linenos">1014</span></a><span class="sd">        X_edge : torch.Tensor, optional</span>
</span><span id="FSWEmbedding-1015"><a href="#FSWEmbedding-1015"><span class="linenos">1015</span></a><span class="sd">            Optional edge feature tensor. Required if `d_edge &gt; 0` was set at initialization.</span>
</span><span id="FSWEmbedding-1016"><a href="#FSWEmbedding-1016"><span class="linenos">1016</span></a><span class="sd">        graph_mode : bool, default=False</span>
</span><span id="FSWEmbedding-1017"><a href="#FSWEmbedding-1017"><span class="linenos">1017</span></a><span class="sd">            If True, interprets `W` as an adjacency matrix and computes a neighbor-aggregated</span>
</span><span id="FSWEmbedding-1018"><a href="#FSWEmbedding-1018"><span class="linenos">1018</span></a><span class="sd">            embedding.</span>
</span><span id="FSWEmbedding-1019"><a href="#FSWEmbedding-1019"><span class="linenos">1019</span></a><span class="sd">        max_parallel_slices : int, optional</span>
</span><span id="FSWEmbedding-1020"><a href="#FSWEmbedding-1020"><span class="linenos">1020</span></a><span class="sd">            Limits the number of slices processed in parallel. Reduces memory usage by computing</span>
</span><span id="FSWEmbedding-1021"><a href="#FSWEmbedding-1021"><span class="linenos">1021</span></a><span class="sd">            the embedding in smaller blocks without changing the result.</span>
</span><span id="FSWEmbedding-1022"><a href="#FSWEmbedding-1022"><span class="linenos">1022</span></a>
</span><span id="FSWEmbedding-1023"><a href="#FSWEmbedding-1023"><span class="linenos">1023</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding-1024"><a href="#FSWEmbedding-1024"><span class="linenos">1024</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding-1025"><a href="#FSWEmbedding-1025"><span class="linenos">1025</span></a><span class="sd">        torch.Tensor</span>
</span><span id="FSWEmbedding-1026"><a href="#FSWEmbedding-1026"><span class="linenos">1026</span></a><span class="sd">            The embedding tensor. Shape depends on the mode:</span>
</span><span id="FSWEmbedding-1027"><a href="#FSWEmbedding-1027"><span class="linenos">1027</span></a><span class="sd">            - `(d_out,)` or `(..., d_out)` in standard mode.</span>
</span><span id="FSWEmbedding-1028"><a href="#FSWEmbedding-1028"><span class="linenos">1028</span></a><span class="sd">            - `(..., num_slices, num_frequencies)` in Cartesian mode if `flatten_cartesian_axes=False`.</span>
</span><span id="FSWEmbedding-1029"><a href="#FSWEmbedding-1029"><span class="linenos">1029</span></a><span class="sd">            - `(..., num_slices * num_frequencies)` in Cartesian mode if `flatten_cartesian_axes=True`.</span>
</span><span id="FSWEmbedding-1030"><a href="#FSWEmbedding-1030"><span class="linenos">1030</span></a>
</span><span id="FSWEmbedding-1031"><a href="#FSWEmbedding-1031"><span class="linenos">1031</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding-1032"><a href="#FSWEmbedding-1032"><span class="linenos">1032</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding-1033"><a href="#FSWEmbedding-1033"><span class="linenos">1033</span></a><span class="sd">        Multisets and distributions:</span>
</span><span id="FSWEmbedding-1034"><a href="#FSWEmbedding-1034"><span class="linenos">1034</span></a><span class="sd">            If `X` is `(n, d_in)` and `W` is `(n,)`, the pair represents a weighted point cloud.</span>
</span><span id="FSWEmbedding-1035"><a href="#FSWEmbedding-1035"><span class="linenos">1035</span></a><span class="sd">            Weights must be non-negative with positive total mass.</span>
</span><span id="FSWEmbedding-1036"><a href="#FSWEmbedding-1036"><span class="linenos">1036</span></a><span class="sd">            If `W` is `&#39;unit&#39;` or `&#39;uniform&#39;`, uniform weights are used internally.</span>
</span><span id="FSWEmbedding-1037"><a href="#FSWEmbedding-1037"><span class="linenos">1037</span></a>
</span><span id="FSWEmbedding-1038"><a href="#FSWEmbedding-1038"><span class="linenos">1038</span></a><span class="sd">        Batching:</span>
</span><span id="FSWEmbedding-1039"><a href="#FSWEmbedding-1039"><span class="linenos">1039</span></a><span class="sd">            Input tensors may include leading batch dimensions. For `X` of shape `(..., n, d_in)`</span>
</span><span id="FSWEmbedding-1040"><a href="#FSWEmbedding-1040"><span class="linenos">1040</span></a><span class="sd">            and `W` of shape `(..., n)`, the output shape is `(..., d_out)`.</span>
</span><span id="FSWEmbedding-1041"><a href="#FSWEmbedding-1041"><span class="linenos">1041</span></a>
</span><span id="FSWEmbedding-1042"><a href="#FSWEmbedding-1042"><span class="linenos">1042</span></a><span class="sd">        Graph mode:</span>
</span><span id="FSWEmbedding-1043"><a href="#FSWEmbedding-1043"><span class="linenos">1043</span></a><span class="sd">            When `graph_mode=True`, `W` must be of shape `(..., n_recipients, n)` and `X` of</span>
</span><span id="FSWEmbedding-1044"><a href="#FSWEmbedding-1044"><span class="linenos">1044</span></a><span class="sd">            shape `(..., n, d_in)` or broadcastable to that. The output will be</span>
</span><span id="FSWEmbedding-1045"><a href="#FSWEmbedding-1045"><span class="linenos">1045</span></a><span class="sd">            `(..., n_recipients, d_out)`, where each vector represents a weighted embedding of</span>
</span><span id="FSWEmbedding-1046"><a href="#FSWEmbedding-1046"><span class="linenos">1046</span></a><span class="sd">            neighboring nodes. This avoids expanding `X` across `n_recipients` explicitly.</span>
</span><span id="FSWEmbedding-1047"><a href="#FSWEmbedding-1047"><span class="linenos">1047</span></a>
</span><span id="FSWEmbedding-1048"><a href="#FSWEmbedding-1048"><span class="linenos">1048</span></a><span class="sd">        Cartesian mode:</span>
</span><span id="FSWEmbedding-1049"><a href="#FSWEmbedding-1049"><span class="linenos">1049</span></a><span class="sd">            If `d_out` is not specified but `num_slices` and `num_frequencies` are, the embedding</span>
</span><span id="FSWEmbedding-1050"><a href="#FSWEmbedding-1050"><span class="linenos">1050</span></a><span class="sd">            is computed over a Cartesian product. The output shape is:</span>
</span><span id="FSWEmbedding-1051"><a href="#FSWEmbedding-1051"><span class="linenos">1051</span></a><span class="sd">                - `(..., num_slices, num_frequencies)` if `flatten_cartesian_axes=False`</span>
</span><span id="FSWEmbedding-1052"><a href="#FSWEmbedding-1052"><span class="linenos">1052</span></a><span class="sd">                - `(..., num_slices * num_frequencies)` if `flatten_cartesian_axes=True`</span>
</span><span id="FSWEmbedding-1053"><a href="#FSWEmbedding-1053"><span class="linenos">1053</span></a>
</span><span id="FSWEmbedding-1054"><a href="#FSWEmbedding-1054"><span class="linenos">1054</span></a><span class="sd">        Slice serialization:</span>
</span><span id="FSWEmbedding-1055"><a href="#FSWEmbedding-1055"><span class="linenos">1055</span></a><span class="sd">            If `max_parallel_slices=t` is set, the computation is performed in blocks of size `t`,</span>
</span><span id="FSWEmbedding-1056"><a href="#FSWEmbedding-1056"><span class="linenos">1056</span></a><span class="sd">            reducing memory complexity by a factor of `num_slices / t`. The output remains unchanged.</span>
</span><span id="FSWEmbedding-1057"><a href="#FSWEmbedding-1057"><span class="linenos">1057</span></a>
</span><span id="FSWEmbedding-1058"><a href="#FSWEmbedding-1058"><span class="linenos">1058</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding-1059"><a href="#FSWEmbedding-1059"><span class="linenos">1059</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding-1060"><a href="#FSWEmbedding-1060"><span class="linenos">1060</span></a><span class="sd">        FSWEmbedding.__init__ : Constructor for model configuration options.</span>
</span><span id="FSWEmbedding-1061"><a href="#FSWEmbedding-1061"><span class="linenos">1061</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding-1062"><a href="#FSWEmbedding-1062"><span class="linenos">1062</span></a>
</span><span id="FSWEmbedding-1063"><a href="#FSWEmbedding-1063"><span class="linenos">1063</span></a>
</span><span id="FSWEmbedding-1064"><a href="#FSWEmbedding-1064"><span class="linenos">1064</span></a>        <span class="c1"># Verify slices and frequencies at each forward pass if they are learnable</span>
</span><span id="FSWEmbedding-1065"><a href="#FSWEmbedding-1065"><span class="linenos">1065</span></a>        <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">:</span>
</span><span id="FSWEmbedding-1066"><a href="#FSWEmbedding-1066"><span class="linenos">1066</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Slice vectors contain NaNs&#39;</span>
</span><span id="FSWEmbedding-1067"><a href="#FSWEmbedding-1067"><span class="linenos">1067</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Slice vectors contain infs&#39;</span>
</span><span id="FSWEmbedding-1068"><a href="#FSWEmbedding-1068"><span class="linenos">1068</span></a>            <span class="c1"># Note: We allow them to contain zero vectors when they are learnable, in case i.e. when sparsity is desired</span>
</span><span id="FSWEmbedding-1069"><a href="#FSWEmbedding-1069"><span class="linenos">1069</span></a>            <span class="c1"># assert not (self.slice_vectors == 0).all(dim=1).any(), &#39;Slice vectors contain a zero vector&#39;</span>
</span><span id="FSWEmbedding-1070"><a href="#FSWEmbedding-1070"><span class="linenos">1070</span></a>
</span><span id="FSWEmbedding-1071"><a href="#FSWEmbedding-1071"><span class="linenos">1071</span></a>        <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">:</span>
</span><span id="FSWEmbedding-1072"><a href="#FSWEmbedding-1072"><span class="linenos">1072</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Frequencies contain NaNs&#39;</span>
</span><span id="FSWEmbedding-1073"><a href="#FSWEmbedding-1073"><span class="linenos">1073</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Frequencies contain infs&#39;</span>
</span><span id="FSWEmbedding-1074"><a href="#FSWEmbedding-1074"><span class="linenos">1074</span></a>
</span><span id="FSWEmbedding-1075"><a href="#FSWEmbedding-1075"><span class="linenos">1075</span></a>        <span class="c1">### A. Verify input types and content</span>
</span><span id="FSWEmbedding-1076"><a href="#FSWEmbedding-1076"><span class="linenos">1076</span></a>
</span><span id="FSWEmbedding-1077"><a href="#FSWEmbedding-1077"><span class="linenos">1077</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;total_mass_padding_thresh must be positive&#39;</span>
</span><span id="FSWEmbedding-1078"><a href="#FSWEmbedding-1078"><span class="linenos">1078</span></a>
</span><span id="FSWEmbedding-1079"><a href="#FSWEmbedding-1079"><span class="linenos">1079</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-1080"><a href="#FSWEmbedding-1080"><span class="linenos">1080</span></a>            <span class="k">assert</span> <span class="n">graph_mode</span><span class="p">,</span> <span class="s1">&#39;d_edge &gt; 0 (given at initialization) necessitates graph_mode=True on forward call&#39;</span>
</span><span id="FSWEmbedding-1081"><a href="#FSWEmbedding-1081"><span class="linenos">1081</span></a>            <span class="k">assert</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;X_edge must be provided since d_edge &gt; 0&#39;</span>
</span><span id="FSWEmbedding-1082"><a href="#FSWEmbedding-1082"><span class="linenos">1082</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1083"><a href="#FSWEmbedding-1083"><span class="linenos">1083</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;X_edge should be None or empty since d_edge == 0&#39;</span>
</span><span id="FSWEmbedding-1084"><a href="#FSWEmbedding-1084"><span class="linenos">1084</span></a>            <span class="n">X_edge</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding-1085"><a href="#FSWEmbedding-1085"><span class="linenos">1085</span></a>
</span><span id="FSWEmbedding-1086"><a href="#FSWEmbedding-1086"><span class="linenos">1086</span></a>        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s1">&#39;X must be a pytorch tensor. Instead got type </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</span><span id="FSWEmbedding-1087"><a href="#FSWEmbedding-1087"><span class="linenos">1087</span></a>        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">)</span> <span class="ow">or</span> <span class="n">W</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;unit&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">},</span> <span class="s1">&#39;W must be a pytorch tensor, </span><span class="se">\&#39;</span><span class="s1">unit</span><span class="se">\&#39;</span><span class="s1"> or </span><span class="se">\&#39;</span><span class="s1">uniform</span><span class="se">\&#39;</span><span class="s1">&#39;</span>
</span><span id="FSWEmbedding-1088"><a href="#FSWEmbedding-1088"><span class="linenos">1088</span></a>        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;X has the wrong dtype. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1089"><a href="#FSWEmbedding-1089"><span class="linenos">1089</span></a>        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;X is on the wrong device. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1090"><a href="#FSWEmbedding-1090"><span class="linenos">1090</span></a>
</span><span id="FSWEmbedding-1091"><a href="#FSWEmbedding-1091"><span class="linenos">1091</span></a>        <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1092"><a href="#FSWEmbedding-1092"><span class="linenos">1092</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;The entries of X cannot contain NaNs&quot;</span>
</span><span id="FSWEmbedding-1093"><a href="#FSWEmbedding-1093"><span class="linenos">1093</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;All entries of X must be finite&quot;</span>
</span><span id="FSWEmbedding-1094"><a href="#FSWEmbedding-1094"><span class="linenos">1094</span></a>
</span><span id="FSWEmbedding-1095"><a href="#FSWEmbedding-1095"><span class="linenos">1095</span></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
</span><span id="FSWEmbedding-1096"><a href="#FSWEmbedding-1096"><span class="linenos">1096</span></a>            <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;W has the wrong dtype. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1097"><a href="#FSWEmbedding-1097"><span class="linenos">1097</span></a>            <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;W is on the wrong device. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1098"><a href="#FSWEmbedding-1098"><span class="linenos">1098</span></a>
</span><span id="FSWEmbedding-1099"><a href="#FSWEmbedding-1099"><span class="linenos">1099</span></a>            <span class="c1"># Check if W is sparse. If so, ensure that W is of the correct layout.</span>
</span><span id="FSWEmbedding-1100"><a href="#FSWEmbedding-1100"><span class="linenos">1100</span></a>            <span class="c1"># Note: Strangely enough, sparse tensors of layouts other than COO (e.g. CSR) may have is_sparse=False.</span>
</span><span id="FSWEmbedding-1101"><a href="#FSWEmbedding-1101"><span class="linenos">1101</span></a>            <span class="c1">#       This may lead us to mistakenly treat a, e.g. W that is sparse CSR as dense.</span>
</span><span id="FSWEmbedding-1102"><a href="#FSWEmbedding-1102"><span class="linenos">1102</span></a>            <span class="c1">#       Currently there is no is_dense() function in torch, so reading the layout string directly is the second best.</span>
</span><span id="FSWEmbedding-1103"><a href="#FSWEmbedding-1103"><span class="linenos">1103</span></a>            <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span> <span class="ow">or</span> <span class="n">W</span><span class="o">.</span><span class="n">layout</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">:</span>
</span><span id="FSWEmbedding-1104"><a href="#FSWEmbedding-1104"><span class="linenos">1104</span></a>                <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">layout</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;Sparse W has an unsupported sparsity layout &#39;</span><span class="si">%s</span><span class="s2">&#39;. Only the COO layout (torch.sparse_coo) is currently supported.&quot;</span> <span class="o">%</span> <span class="n">W</span><span class="o">.</span><span class="n">layout</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1105"><a href="#FSWEmbedding-1105"><span class="linenos">1105</span></a>
</span><span id="FSWEmbedding-1106"><a href="#FSWEmbedding-1106"><span class="linenos">1106</span></a>                <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">is_coalesced</span><span class="p">(),</span> <span class="s1">&#39;Sparse W must be coalesced&#39;</span>
</span><span id="FSWEmbedding-1107"><a href="#FSWEmbedding-1107"><span class="linenos">1107</span></a>                <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;W.dense_dim() must be zero&#39;</span>
</span><span id="FSWEmbedding-1108"><a href="#FSWEmbedding-1108"><span class="linenos">1108</span></a>
</span><span id="FSWEmbedding-1109"><a href="#FSWEmbedding-1109"><span class="linenos">1109</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1110"><a href="#FSWEmbedding-1110"><span class="linenos">1110</span></a>                    <span class="n">W_vals</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span><span id="FSWEmbedding-1111"><a href="#FSWEmbedding-1111"><span class="linenos">1111</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1112"><a href="#FSWEmbedding-1112"><span class="linenos">1112</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1113"><a href="#FSWEmbedding-1113"><span class="linenos">1113</span></a>                    <span class="n">W_vals</span> <span class="o">=</span> <span class="n">W</span>
</span><span id="FSWEmbedding-1114"><a href="#FSWEmbedding-1114"><span class="linenos">1114</span></a>
</span><span id="FSWEmbedding-1115"><a href="#FSWEmbedding-1115"><span class="linenos">1115</span></a>            <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1116"><a href="#FSWEmbedding-1116"><span class="linenos">1116</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W_vals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding-1117"><a href="#FSWEmbedding-1117"><span class="linenos">1117</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">W_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;W cannot contain NaNs&quot;</span>
</span><span id="FSWEmbedding-1118"><a href="#FSWEmbedding-1118"><span class="linenos">1118</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">W_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;All entries of W must be finite&quot;</span>
</span><span id="FSWEmbedding-1119"><a href="#FSWEmbedding-1119"><span class="linenos">1119</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="n">W_vals</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s2">&quot;All entries of W must be nonnegative&quot;</span>
</span><span id="FSWEmbedding-1120"><a href="#FSWEmbedding-1120"><span class="linenos">1120</span></a>                <span class="k">del</span> <span class="n">W_vals</span>
</span><span id="FSWEmbedding-1121"><a href="#FSWEmbedding-1121"><span class="linenos">1121</span></a>
</span><span id="FSWEmbedding-1122"><a href="#FSWEmbedding-1122"><span class="linenos">1122</span></a>        <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding-1123"><a href="#FSWEmbedding-1123"><span class="linenos">1123</span></a>            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="s1">&#39;When X_edge is provided, W must be provided explicitly&#39;</span>
</span><span id="FSWEmbedding-1124"><a href="#FSWEmbedding-1124"><span class="linenos">1124</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="p">(</span> <span class="s2">&quot;X_edge is on the wrong device. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1125"><a href="#FSWEmbedding-1125"><span class="linenos">1125</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="p">(</span> <span class="s2">&quot;X_edge has the wrong dtype. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1126"><a href="#FSWEmbedding-1126"><span class="linenos">1126</span></a>
</span><span id="FSWEmbedding-1127"><a href="#FSWEmbedding-1127"><span class="linenos">1127</span></a>            <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_sparse</span> <span class="ow">or</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">layout</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">:</span>
</span><span id="FSWEmbedding-1128"><a href="#FSWEmbedding-1128"><span class="linenos">1128</span></a>                <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">layout</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;Sparse X_edge has an unsupported sparsity layout &#39;</span><span class="si">%s</span><span class="s2">&#39;. Only the COO layout (torch.sparse_coo) is currently supported.&quot;</span> <span class="o">%</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">layout</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1129"><a href="#FSWEmbedding-1129"><span class="linenos">1129</span></a>
</span><span id="FSWEmbedding-1130"><a href="#FSWEmbedding-1130"><span class="linenos">1130</span></a>                <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_coalesced</span><span class="p">(),</span> <span class="s1">&#39;Sparse X_edge must be coalesced&#39;</span>
</span><span id="FSWEmbedding-1131"><a href="#FSWEmbedding-1131"><span class="linenos">1131</span></a>                <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;X_edge.dense_dim() must be 1 or 0&#39;</span>
</span><span id="FSWEmbedding-1132"><a href="#FSWEmbedding-1132"><span class="linenos">1132</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;X_edge.dense_dim() must be 1 since d_edge &gt; 1&#39;</span>
</span><span id="FSWEmbedding-1133"><a href="#FSWEmbedding-1133"><span class="linenos">1133</span></a>
</span><span id="FSWEmbedding-1134"><a href="#FSWEmbedding-1134"><span class="linenos">1134</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1135"><a href="#FSWEmbedding-1135"><span class="linenos">1135</span></a>                    <span class="n">X_edge_vals</span> <span class="o">=</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span><span id="FSWEmbedding-1136"><a href="#FSWEmbedding-1136"><span class="linenos">1136</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1137"><a href="#FSWEmbedding-1137"><span class="linenos">1137</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1138"><a href="#FSWEmbedding-1138"><span class="linenos">1138</span></a>                    <span class="n">X_edge_vals</span> <span class="o">=</span> <span class="n">X_edge</span>
</span><span id="FSWEmbedding-1139"><a href="#FSWEmbedding-1139"><span class="linenos">1139</span></a>
</span><span id="FSWEmbedding-1140"><a href="#FSWEmbedding-1140"><span class="linenos">1140</span></a>            <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1141"><a href="#FSWEmbedding-1141"><span class="linenos">1141</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X_edge_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;X_edge_vals cannot contain NaNs&quot;</span>
</span><span id="FSWEmbedding-1142"><a href="#FSWEmbedding-1142"><span class="linenos">1142</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">X_edge_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;All entries of X_edge_vals must be finite&quot;</span>
</span><span id="FSWEmbedding-1143"><a href="#FSWEmbedding-1143"><span class="linenos">1143</span></a>                <span class="k">del</span> <span class="n">X_edge_vals</span>
</span><span id="FSWEmbedding-1144"><a href="#FSWEmbedding-1144"><span class="linenos">1144</span></a>
</span><span id="FSWEmbedding-1145"><a href="#FSWEmbedding-1145"><span class="linenos">1145</span></a>            <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_sparse</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">,</span> <span class="s1">&#39;X_edge and W must either both or neither be sparse&#39;</span>
</span><span id="FSWEmbedding-1146"><a href="#FSWEmbedding-1146"><span class="linenos">1146</span></a>
</span><span id="FSWEmbedding-1147"><a href="#FSWEmbedding-1147"><span class="linenos">1147</span></a>
</span><span id="FSWEmbedding-1148"><a href="#FSWEmbedding-1148"><span class="linenos">1148</span></a>        <span class="c1">### B. Verify input sizes</span>
</span><span id="FSWEmbedding-1149"><a href="#FSWEmbedding-1149"><span class="linenos">1149</span></a>
</span><span id="FSWEmbedding-1150"><a href="#FSWEmbedding-1150"><span class="linenos">1150</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X must be a tensor of order at least 2&quot;</span>
</span><span id="FSWEmbedding-1151"><a href="#FSWEmbedding-1151"><span class="linenos">1151</span></a>        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">,</span> <span class="s2">&quot;The last dimension of X must equal d_in=</span><span class="si">%d</span><span class="s2">. Instead got </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="FSWEmbedding-1152"><a href="#FSWEmbedding-1152"><span class="linenos">1152</span></a>
</span><span id="FSWEmbedding-1153"><a href="#FSWEmbedding-1153"><span class="linenos">1153</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">graph_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1154"><a href="#FSWEmbedding-1154"><span class="linenos">1154</span></a>            <span class="c1"># batch_dims contains everything that precedes (n,d_in) in X.shape</span>
</span><span id="FSWEmbedding-1155"><a href="#FSWEmbedding-1155"><span class="linenos">1155</span></a>            <span class="n">batch_dims</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="FSWEmbedding-1156"><a href="#FSWEmbedding-1156"><span class="linenos">1156</span></a>            <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)]</span>
</span><span id="FSWEmbedding-1157"><a href="#FSWEmbedding-1157"><span class="linenos">1157</span></a>
</span><span id="FSWEmbedding-1158"><a href="#FSWEmbedding-1158"><span class="linenos">1158</span></a>            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
</span><span id="FSWEmbedding-1159"><a href="#FSWEmbedding-1159"><span class="linenos">1159</span></a>                <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]):</span>
</span><span id="FSWEmbedding-1160"><a href="#FSWEmbedding-1160"><span class="linenos">1160</span></a>                    <span class="n">err_str</span> <span class="o">=</span> <span class="s2">&quot;Shape mismatch between X and W: If X.shape = (b1,b2,...,bk,n,d_in) then W.shape should be (b1,b2,...,bk,n) (Perhaps missing argument graph_mode=True?)&quot;</span>
</span><span id="FSWEmbedding-1161"><a href="#FSWEmbedding-1161"><span class="linenos">1161</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1162"><a href="#FSWEmbedding-1162"><span class="linenos">1162</span></a>                    <span class="n">err_str</span> <span class="o">=</span> <span class="s2">&quot;Shape mismatch between X and W: If X.shape = (b1,b2,...,bk,n,d_in) then W.shape should be (b1,b2,...,bk,n) (unless graph_mode=True)&quot;</span>
</span><span id="FSWEmbedding-1163"><a href="#FSWEmbedding-1163"><span class="linenos">1163</span></a>
</span><span id="FSWEmbedding-1164"><a href="#FSWEmbedding-1164"><span class="linenos">1164</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">err_str</span>
</span><span id="FSWEmbedding-1165"><a href="#FSWEmbedding-1165"><span class="linenos">1165</span></a>
</span><span id="FSWEmbedding-1166"><a href="#FSWEmbedding-1166"><span class="linenos">1166</span></a>            <span class="k">elif</span> <span class="n">W</span> <span class="o">==</span> <span class="s1">&#39;unit&#39;</span><span class="p">:</span>
</span><span id="FSWEmbedding-1167"><a href="#FSWEmbedding-1167"><span class="linenos">1167</span></a>                <span class="c1"># Initialize with unit weights</span>
</span><span id="FSWEmbedding-1168"><a href="#FSWEmbedding-1168"><span class="linenos">1168</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-1169"><a href="#FSWEmbedding-1169"><span class="linenos">1169</span></a>
</span><span id="FSWEmbedding-1170"><a href="#FSWEmbedding-1170"><span class="linenos">1170</span></a>            <span class="k">elif</span> <span class="n">W</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>
</span><span id="FSWEmbedding-1171"><a href="#FSWEmbedding-1171"><span class="linenos">1171</span></a>                <span class="c1"># Initialize with uniform weights</span>
</span><span id="FSWEmbedding-1172"><a href="#FSWEmbedding-1172"><span class="linenos">1172</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-1173"><a href="#FSWEmbedding-1173"><span class="linenos">1173</span></a>
</span><span id="FSWEmbedding-1174"><a href="#FSWEmbedding-1174"><span class="linenos">1174</span></a>        <span class="k">elif</span> <span class="n">graph_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1175"><a href="#FSWEmbedding-1175"><span class="linenos">1175</span></a>            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="s1">&#39;W must be explicitly provided when graph_mode=True&#39;</span>
</span><span id="FSWEmbedding-1176"><a href="#FSWEmbedding-1176"><span class="linenos">1176</span></a>
</span><span id="FSWEmbedding-1177"><a href="#FSWEmbedding-1177"><span class="linenos">1177</span></a>            <span class="c1"># batch_dims contains everything that precedes (nRecipients, n) in W.shape</span>
</span><span id="FSWEmbedding-1178"><a href="#FSWEmbedding-1178"><span class="linenos">1178</span></a>            <span class="n">batch_dims</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="FSWEmbedding-1179"><a href="#FSWEmbedding-1179"><span class="linenos">1179</span></a>            <span class="n">nRecipients</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span><span id="FSWEmbedding-1180"><a href="#FSWEmbedding-1180"><span class="linenos">1180</span></a>            <span class="c1">#n = W.shape[-1]</span>
</span><span id="FSWEmbedding-1181"><a href="#FSWEmbedding-1181"><span class="linenos">1181</span></a>
</span><span id="FSWEmbedding-1182"><a href="#FSWEmbedding-1182"><span class="linenos">1182</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span> <span class="s2">&quot;Shape mismatch between X and W: When graph_mode=True, if W.shape = (b1,b2,...,bk,nRecipients,n) then X.shape should be (b1,b2,...,bk,n,d_in)&quot;</span>
</span><span id="FSWEmbedding-1183"><a href="#FSWEmbedding-1183"><span class="linenos">1183</span></a>
</span><span id="FSWEmbedding-1184"><a href="#FSWEmbedding-1184"><span class="linenos">1184</span></a>            <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding-1185"><a href="#FSWEmbedding-1185"><span class="linenos">1185</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_edge</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="c1"># For PyCharm to know</span>
</span><span id="FSWEmbedding-1186"><a href="#FSWEmbedding-1186"><span class="linenos">1186</span></a>
</span><span id="FSWEmbedding-1187"><a href="#FSWEmbedding-1187"><span class="linenos">1187</span></a>                <span class="c1"># Verify that X_edge has the right shape and is compatible with W</span>
</span><span id="FSWEmbedding-1188"><a href="#FSWEmbedding-1188"><span class="linenos">1188</span></a>                <span class="k">assert</span> <span class="p">(((</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="ow">or</span>
</span><span id="FSWEmbedding-1189"><a href="#FSWEmbedding-1189"><span class="linenos">1189</span></a>                        <span class="p">((</span><span class="n">X_edge</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">))),</span> <span class="p">(</span>
</span><span id="FSWEmbedding-1190"><a href="#FSWEmbedding-1190"><span class="linenos">1190</span></a>                    <span class="s2">&quot;Shape mismatch between X_edge and W: if W.shape = (b1,b2,...,bk,nRecipients,n) then X.shape should be (b1,b2,...,bk,nRecipients,n,d_edge) (with the possible exception (b1,b2,...,bk,nRecipients,n) when d_edge=1&quot;</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1191"><a href="#FSWEmbedding-1191"><span class="linenos">1191</span></a>
</span><span id="FSWEmbedding-1192"><a href="#FSWEmbedding-1192"><span class="linenos">1192</span></a>                <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding-1193"><a href="#FSWEmbedding-1193"><span class="linenos">1193</span></a>                    <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">values</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">values</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;Sparse X_edge must have the same number of values() as W&#39;</span>
</span><span id="FSWEmbedding-1194"><a href="#FSWEmbedding-1194"><span class="linenos">1194</span></a>                    <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding-1195"><a href="#FSWEmbedding-1195"><span class="linenos">1195</span></a>                        <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">indices</span><span class="p">()</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">indices</span><span class="p">())</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s1">&#39;Sparse X_edge must have the same nonzero pattern as W&#39;</span>
</span><span id="FSWEmbedding-1196"><a href="#FSWEmbedding-1196"><span class="linenos">1196</span></a>
</span><span id="FSWEmbedding-1197"><a href="#FSWEmbedding-1197"><span class="linenos">1197</span></a>                    <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-1198"><a href="#FSWEmbedding-1198"><span class="linenos">1198</span></a>                        <span class="n">X_edge</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">unsqueeze_dense_dim</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">X_edge</span><span class="p">)</span>
</span><span id="FSWEmbedding-1199"><a href="#FSWEmbedding-1199"><span class="linenos">1199</span></a>
</span><span id="FSWEmbedding-1200"><a href="#FSWEmbedding-1200"><span class="linenos">1200</span></a>
</span><span id="FSWEmbedding-1201"><a href="#FSWEmbedding-1201"><span class="linenos">1201</span></a>        <span class="c1">### C. Precalculate axis indices and output shape</span>
</span><span id="FSWEmbedding-1202"><a href="#FSWEmbedding-1202"><span class="linenos">1202</span></a>
</span><span id="FSWEmbedding-1203"><a href="#FSWEmbedding-1203"><span class="linenos">1203</span></a>        <span class="c1"># These are the different axes we use to store data for processing. These definitions are repeated in forward_helper()</span>
</span><span id="FSWEmbedding-1204"><a href="#FSWEmbedding-1204"><span class="linenos">1204</span></a>        <span class="c1"># element_axis corresponds to the index of the multiset elements</span>
</span><span id="FSWEmbedding-1205"><a href="#FSWEmbedding-1205"><span class="linenos">1205</span></a>        <span class="c1"># ambspace_axis corresponds to the elements&#39; coordinate index in the ambient space R^d_in</span>
</span><span id="FSWEmbedding-1206"><a href="#FSWEmbedding-1206"><span class="linenos">1206</span></a>        <span class="c1"># After projection, the ambient space coordinates are replaced by the slice number; thus slice_axis=ambspace_axis</span>
</span><span id="FSWEmbedding-1207"><a href="#FSWEmbedding-1207"><span class="linenos">1207</span></a>        <span class="c1"># If we&#39;re in Cartesian mode, the frequencies have their own axis freq_axis, otherwise it is the same axis as slice_axis.</span>
</span><span id="FSWEmbedding-1208"><a href="#FSWEmbedding-1208"><span class="linenos">1208</span></a>        <span class="n">recipient_axis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="kc">None</span>  <span class="c1"># Message-recipient vertices</span>
</span><span id="FSWEmbedding-1209"><a href="#FSWEmbedding-1209"><span class="linenos">1209</span></a>        <span class="n">element_axis</span>  <span class="o">=</span> <span class="n">recipient_axis</span><span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span> <span class="c1"># In graph mode this axis denotes the message-sender vertices</span>
</span><span id="FSWEmbedding-1210"><a href="#FSWEmbedding-1210"><span class="linenos">1210</span></a>        <span class="n">ambspace_axis</span> <span class="o">=</span> <span class="n">element_axis</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="FSWEmbedding-1211"><a href="#FSWEmbedding-1211"><span class="linenos">1211</span></a>        <span class="n">slice_axis</span>     <span class="o">=</span> <span class="n">ambspace_axis</span>
</span><span id="FSWEmbedding-1212"><a href="#FSWEmbedding-1212"><span class="linenos">1212</span></a>        <span class="c1"># noinspection PyUnusedLocal</span>
</span><span id="FSWEmbedding-1213"><a href="#FSWEmbedding-1213"><span class="linenos">1213</span></a>        <span class="n">freq_axis</span>     <span class="o">=</span> <span class="n">slice_axis</span> <span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="k">else</span> <span class="n">slice_axis</span>
</span><span id="FSWEmbedding-1214"><a href="#FSWEmbedding-1214"><span class="linenos">1214</span></a>        <span class="n">output_slice_axis</span> <span class="o">=</span> <span class="n">element_axis</span> <span class="c1"># In the output, the element axis is replaced by the slice axis</span>
</span><span id="FSWEmbedding-1215"><a href="#FSWEmbedding-1215"><span class="linenos">1215</span></a>
</span><span id="FSWEmbedding-1216"><a href="#FSWEmbedding-1216"><span class="linenos">1216</span></a>        <span class="n">output_shape_before_collapse_and_totmass_augmentation</span> <span class="o">=</span>  <span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">nRecipients</span><span class="p">,)</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="n">batch_dims</span>
</span><span id="FSWEmbedding-1217"><a href="#FSWEmbedding-1217"><span class="linenos">1217</span></a>        <span class="n">output_shape_before_collapse_and_totmass_augmentation</span> <span class="o">+=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,)</span>
</span><span id="FSWEmbedding-1218"><a href="#FSWEmbedding-1218"><span class="linenos">1218</span></a>
</span><span id="FSWEmbedding-1219"><a href="#FSWEmbedding-1219"><span class="linenos">1219</span></a>        <span class="c1">### D. Input is ok. Start working.</span>
</span><span id="FSWEmbedding-1220"><a href="#FSWEmbedding-1220"><span class="linenos">1220</span></a>
</span><span id="FSWEmbedding-1221"><a href="#FSWEmbedding-1221"><span class="linenos">1221</span></a>        <span class="c1"># Calculate W_sum, which contains the total mass of the input measures</span>
</span><span id="FSWEmbedding-1222"><a href="#FSWEmbedding-1222"><span class="linenos">1222</span></a>        <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding-1223"><a href="#FSWEmbedding-1223"><span class="linenos">1223</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding-1224"><a href="#FSWEmbedding-1224"><span class="linenos">1224</span></a>            <span class="n">slice_info_W</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_slice_info</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">calc_nnz_per_slice</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-1225"><a href="#FSWEmbedding-1225"><span class="linenos">1225</span></a>                                             <span class="n">use_custom_cuda_extension_if_available</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span> <span class="n">fail_if_cuda_extension_load_fails</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1226"><a href="#FSWEmbedding-1226"><span class="linenos">1226</span></a>            <span class="n">W_sum</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">sum_sparseToDense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">slice_info_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1227"><a href="#FSWEmbedding-1227"><span class="linenos">1227</span></a>
</span><span id="FSWEmbedding-1228"><a href="#FSWEmbedding-1228"><span class="linenos">1228</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1229"><a href="#FSWEmbedding-1229"><span class="linenos">1229</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding-1230"><a href="#FSWEmbedding-1230"><span class="linenos">1230</span></a>            <span class="n">W_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="FSWEmbedding-1231"><a href="#FSWEmbedding-1231"><span class="linenos">1231</span></a>
</span><span id="FSWEmbedding-1232"><a href="#FSWEmbedding-1232"><span class="linenos">1232</span></a>        <span class="c1"># Total-mass deficit to be compensated for by padding</span>
</span><span id="FSWEmbedding-1233"><a href="#FSWEmbedding-1233"><span class="linenos">1233</span></a>        <span class="n">W_pad</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">custom_lowclamp</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span> <span class="o">-</span> <span class="n">W_sum</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
</span><span id="FSWEmbedding-1234"><a href="#FSWEmbedding-1234"><span class="linenos">1234</span></a>
</span><span id="FSWEmbedding-1235"><a href="#FSWEmbedding-1235"><span class="linenos">1235</span></a>        <span class="c1"># Detect weight deficit and augment W and X accordingly</span>
</span><span id="FSWEmbedding-1236"><a href="#FSWEmbedding-1236"><span class="linenos">1236</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">W_pad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
</span><span id="FSWEmbedding-1237"><a href="#FSWEmbedding-1237"><span class="linenos">1237</span></a>            <span class="n">zshape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="FSWEmbedding-1238"><a href="#FSWEmbedding-1238"><span class="linenos">1238</span></a>            <span class="n">zshape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="FSWEmbedding-1239"><a href="#FSWEmbedding-1239"><span class="linenos">1239</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zshape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1240"><a href="#FSWEmbedding-1240"><span class="linenos">1240</span></a>
</span><span id="FSWEmbedding-1241"><a href="#FSWEmbedding-1241"><span class="linenos">1241</span></a>            <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding-1242"><a href="#FSWEmbedding-1242"><span class="linenos">1242</span></a>                <span class="c1"># Make sure this works</span>
</span><span id="FSWEmbedding-1243"><a href="#FSWEmbedding-1243"><span class="linenos">1243</span></a>                <span class="n">W_pad</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">to_sparse_full</span><span class="p">(</span><span class="n">W_pad</span><span class="p">)</span>
</span><span id="FSWEmbedding-1244"><a href="#FSWEmbedding-1244"><span class="linenos">1244</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">concat_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_pad</span><span class="p">)</span>
</span><span id="FSWEmbedding-1245"><a href="#FSWEmbedding-1245"><span class="linenos">1245</span></a>                <span class="n">slice_info_W</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_slice_info</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">calc_nnz_per_slice</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-1246"><a href="#FSWEmbedding-1246"><span class="linenos">1246</span></a>                                                 <span class="n">use_custom_cuda_extension_if_available</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span> <span class="n">fail_if_cuda_extension_load_fails</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1247"><a href="#FSWEmbedding-1247"><span class="linenos">1247</span></a>
</span><span id="FSWEmbedding-1248"><a href="#FSWEmbedding-1248"><span class="linenos">1248</span></a>                <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding-1249"><a href="#FSWEmbedding-1249"><span class="linenos">1249</span></a>                    <span class="n">X_edge_pad_inds</span> <span class="o">=</span> <span class="n">W_pad</span><span class="o">.</span><span class="n">indices</span><span class="p">()</span>
</span><span id="FSWEmbedding-1250"><a href="#FSWEmbedding-1250"><span class="linenos">1250</span></a>                    <span class="n">X_edge_pad_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nRecipients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="FSWEmbedding-1251"><a href="#FSWEmbedding-1251"><span class="linenos">1251</span></a>                    <span class="n">X_edge_pad_shape</span> <span class="o">=</span> <span class="n">replace_in_tuple</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1252"><a href="#FSWEmbedding-1252"><span class="linenos">1252</span></a>
</span><span id="FSWEmbedding-1253"><a href="#FSWEmbedding-1253"><span class="linenos">1253</span></a>                    <span class="n">X_edge_pad</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse_coo_tensor_coalesced</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">X_edge_pad_inds</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">X_edge_pad_vals</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">X_edge_pad_shape</span><span class="p">)</span>
</span><span id="FSWEmbedding-1254"><a href="#FSWEmbedding-1254"><span class="linenos">1254</span></a>                    <span class="n">X_edge</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">concat_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">X_edge</span><span class="p">,</span> <span class="n">X_edge_pad</span><span class="p">)</span>
</span><span id="FSWEmbedding-1255"><a href="#FSWEmbedding-1255"><span class="linenos">1255</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1256"><a href="#FSWEmbedding-1256"><span class="linenos">1256</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding-1257"><a href="#FSWEmbedding-1257"><span class="linenos">1257</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_pad</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1258"><a href="#FSWEmbedding-1258"><span class="linenos">1258</span></a>                <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding-1259"><a href="#FSWEmbedding-1259"><span class="linenos">1259</span></a>                    <span class="n">zshape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">+</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">,</span> <span class="p">]</span>
</span><span id="FSWEmbedding-1260"><a href="#FSWEmbedding-1260"><span class="linenos">1260</span></a>                    <span class="n">zshape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="FSWEmbedding-1261"><a href="#FSWEmbedding-1261"><span class="linenos">1261</span></a>                    <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">dim</span><span class="p">():</span>
</span><span id="FSWEmbedding-1262"><a href="#FSWEmbedding-1262"><span class="linenos">1262</span></a>                        <span class="n">X_edge</span> <span class="o">=</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1263"><a href="#FSWEmbedding-1263"><span class="linenos">1263</span></a>                    <span class="n">X_edge</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">X_edge</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zshape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1264"><a href="#FSWEmbedding-1264"><span class="linenos">1264</span></a>
</span><span id="FSWEmbedding-1265"><a href="#FSWEmbedding-1265"><span class="linenos">1265</span></a>            <span class="n">W_sum_padded</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">custom_lowclamp</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W_sum</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span><span class="p">)</span>
</span><span id="FSWEmbedding-1266"><a href="#FSWEmbedding-1266"><span class="linenos">1266</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1267"><a href="#FSWEmbedding-1267"><span class="linenos">1267</span></a>            <span class="n">W_sum_padded</span> <span class="o">=</span> <span class="n">W_sum</span>
</span><span id="FSWEmbedding-1268"><a href="#FSWEmbedding-1268"><span class="linenos">1268</span></a>
</span><span id="FSWEmbedding-1269"><a href="#FSWEmbedding-1269"><span class="linenos">1269</span></a>        <span class="k">del</span> <span class="n">W_pad</span>
</span><span id="FSWEmbedding-1270"><a href="#FSWEmbedding-1270"><span class="linenos">1270</span></a>
</span><span id="FSWEmbedding-1271"><a href="#FSWEmbedding-1271"><span class="linenos">1271</span></a>        <span class="c1"># Normalize W according to W_sum_padded</span>
</span><span id="FSWEmbedding-1272"><a href="#FSWEmbedding-1272"><span class="linenos">1272</span></a>        <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding-1273"><a href="#FSWEmbedding-1273"><span class="linenos">1273</span></a>            <span class="n">W</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">div_sparse_dense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_sum_padded</span><span class="p">,</span> <span class="n">slice_info_W</span><span class="p">,</span>
</span><span id="FSWEmbedding-1274"><a href="#FSWEmbedding-1274"><span class="linenos">1274</span></a>                                          <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1275"><a href="#FSWEmbedding-1275"><span class="linenos">1275</span></a>                                          <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1276"><a href="#FSWEmbedding-1276"><span class="linenos">1276</span></a>            <span class="k">del</span> <span class="n">slice_info_W</span><span class="p">,</span> <span class="n">W_sum_padded</span>
</span><span id="FSWEmbedding-1277"><a href="#FSWEmbedding-1277"><span class="linenos">1277</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1278"><a href="#FSWEmbedding-1278"><span class="linenos">1278</span></a>            <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">/</span> <span class="n">W_sum_padded</span>
</span><span id="FSWEmbedding-1279"><a href="#FSWEmbedding-1279"><span class="linenos">1279</span></a>            <span class="k">del</span> <span class="n">W_sum_padded</span>
</span><span id="FSWEmbedding-1280"><a href="#FSWEmbedding-1280"><span class="linenos">1280</span></a>
</span><span id="FSWEmbedding-1281"><a href="#FSWEmbedding-1281"><span class="linenos">1281</span></a>        <span class="c1"># For compatibility reasons, we support the case of zero-dimensional output tensor</span>
</span><span id="FSWEmbedding-1282"><a href="#FSWEmbedding-1282"><span class="linenos">1282</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-1283"><a href="#FSWEmbedding-1283"><span class="linenos">1283</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">output_shape_before_collapse_and_totmass_augmentation</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-1284"><a href="#FSWEmbedding-1284"><span class="linenos">1284</span></a>
</span><span id="FSWEmbedding-1285"><a href="#FSWEmbedding-1285"><span class="linenos">1285</span></a>        <span class="k">elif</span> <span class="p">(</span><span class="n">max_parallel_slices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_parallel_slices</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">):</span>
</span><span id="FSWEmbedding-1286"><a href="#FSWEmbedding-1286"><span class="linenos">1286</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_forward_helper</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">graph_mode</span><span class="p">,</span> <span class="n">X_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">,</span>
</span><span id="FSWEmbedding-1287"><a href="#FSWEmbedding-1287"><span class="linenos">1287</span></a>                                                 <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1288"><a href="#FSWEmbedding-1288"><span class="linenos">1288</span></a>                                                 <span class="n">fail_if_cuda_extension_load_fails</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1289"><a href="#FSWEmbedding-1289"><span class="linenos">1289</span></a>
</span><span id="FSWEmbedding-1290"><a href="#FSWEmbedding-1290"><span class="linenos">1290</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1291"><a href="#FSWEmbedding-1291"><span class="linenos">1291</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">max_parallel_slices</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">max_parallel_slices</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;max_parallel_slices must be None or a positive integer&#39;</span>
</span><span id="FSWEmbedding-1292"><a href="#FSWEmbedding-1292"><span class="linenos">1292</span></a>
</span><span id="FSWEmbedding-1293"><a href="#FSWEmbedding-1293"><span class="linenos">1293</span></a>            <span class="n">nIter</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">//</span> <span class="n">max_parallel_slices</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">%</span> <span class="n">max_parallel_slices</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">//</span> <span class="n">max_parallel_slices</span><span class="p">)</span>
</span><span id="FSWEmbedding-1294"><a href="#FSWEmbedding-1294"><span class="linenos">1294</span></a>
</span><span id="FSWEmbedding-1295"><a href="#FSWEmbedding-1295"><span class="linenos">1295</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">output_shape_before_collapse_and_totmass_augmentation</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-1296"><a href="#FSWEmbedding-1296"><span class="linenos">1296</span></a>
</span><span id="FSWEmbedding-1297"><a href="#FSWEmbedding-1297"><span class="linenos">1297</span></a>            <span class="k">for</span> <span class="n">iIter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
</span><span id="FSWEmbedding-1298"><a href="#FSWEmbedding-1298"><span class="linenos">1298</span></a>                <span class="n">inds_curr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">iIter</span> <span class="o">*</span> <span class="n">max_parallel_slices</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="p">(</span><span class="n">iIter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_parallel_slices</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding-1299"><a href="#FSWEmbedding-1299"><span class="linenos">1299</span></a>                <span class="n">slice_vecs_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">[</span><span class="n">inds_curr</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="FSWEmbedding-1300"><a href="#FSWEmbedding-1300"><span class="linenos">1300</span></a>                <span class="n">freqs_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">[</span><span class="n">inds_curr</span><span class="p">]</span>
</span><span id="FSWEmbedding-1301"><a href="#FSWEmbedding-1301"><span class="linenos">1301</span></a>
</span><span id="FSWEmbedding-1302"><a href="#FSWEmbedding-1302"><span class="linenos">1302</span></a>                <span class="n">out_curr</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_forward_helper</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">slice_vecs_curr</span><span class="p">,</span> <span class="n">freqs_curr</span><span class="p">,</span> <span class="n">graph_mode</span><span class="p">,</span> <span class="n">X_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">,</span>
</span><span id="FSWEmbedding-1303"><a href="#FSWEmbedding-1303"><span class="linenos">1303</span></a>                                                        <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1304"><a href="#FSWEmbedding-1304"><span class="linenos">1304</span></a>                                                        <span class="n">fail_if_cuda_extension_load_fails</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1305"><a href="#FSWEmbedding-1305"><span class="linenos">1305</span></a>
</span><span id="FSWEmbedding-1306"><a href="#FSWEmbedding-1306"><span class="linenos">1306</span></a>                <span class="n">assign_at</span><span class="p">(</span><span class="n">X_emb</span><span class="p">,</span> <span class="n">out_curr</span><span class="p">,</span> <span class="n">output_slice_axis</span><span class="p">,</span> <span class="n">inds_curr</span><span class="p">)</span>
</span><span id="FSWEmbedding-1307"><a href="#FSWEmbedding-1307"><span class="linenos">1307</span></a>
</span><span id="FSWEmbedding-1308"><a href="#FSWEmbedding-1308"><span class="linenos">1308</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding-1309"><a href="#FSWEmbedding-1309"><span class="linenos">1309</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">X_emb</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=</span><span class="n">element_axis</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1310"><a href="#FSWEmbedding-1310"><span class="linenos">1310</span></a>
</span><span id="FSWEmbedding-1311"><a href="#FSWEmbedding-1311"><span class="linenos">1311</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span><span class="p">:</span>
</span><span id="FSWEmbedding-1312"><a href="#FSWEmbedding-1312"><span class="linenos">1312</span></a>            <span class="k">match</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span><span class="p">:</span>
</span><span id="FSWEmbedding-1313"><a href="#FSWEmbedding-1313"><span class="linenos">1313</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">IDENTITY</span><span class="p">:</span>
</span><span id="FSWEmbedding-1314"><a href="#FSWEmbedding-1314"><span class="linenos">1314</span></a>                    <span class="n">encoded_total_mass</span> <span class="o">=</span> <span class="n">W_sum</span>
</span><span id="FSWEmbedding-1315"><a href="#FSWEmbedding-1315"><span class="linenos">1315</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">SQRT</span><span class="p">:</span>
</span><span id="FSWEmbedding-1316"><a href="#FSWEmbedding-1316"><span class="linenos">1316</span></a>                    <span class="c1"># x/(sqrt(x+1)+1) is a numerically-safe formulation of sqrt(1+x)-1</span>
</span><span id="FSWEmbedding-1317"><a href="#FSWEmbedding-1317"><span class="linenos">1317</span></a>                    <span class="c1"># note that we don&#39;t use sqrt(1+x) since we need the function to vanish at x=0,</span>
</span><span id="FSWEmbedding-1318"><a href="#FSWEmbedding-1318"><span class="linenos">1318</span></a>                    <span class="c1"># and we don&#39;t use sqrt(x) since we need it to have a gradient at x=0.</span>
</span><span id="FSWEmbedding-1319"><a href="#FSWEmbedding-1319"><span class="linenos">1319</span></a>                    <span class="n">encoded_total_mass</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span> <span class="n">W_sum</span> <span class="o">/</span> <span class="p">(</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">W_sum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding-1320"><a href="#FSWEmbedding-1320"><span class="linenos">1320</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">LOG</span><span class="p">:</span>
</span><span id="FSWEmbedding-1321"><a href="#FSWEmbedding-1321"><span class="linenos">1321</span></a>                    <span class="n">encoded_total_mass</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">W_sum</span><span class="p">)</span>
</span><span id="FSWEmbedding-1322"><a href="#FSWEmbedding-1322"><span class="linenos">1322</span></a>                <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="FSWEmbedding-1323"><a href="#FSWEmbedding-1323"><span class="linenos">1323</span></a>                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported encoding function: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding-1324"><a href="#FSWEmbedding-1324"><span class="linenos">1324</span></a>
</span><span id="FSWEmbedding-1325"><a href="#FSWEmbedding-1325"><span class="linenos">1325</span></a>            <span class="n">encoded_total_mass</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_scale</span>
</span><span id="FSWEmbedding-1326"><a href="#FSWEmbedding-1326"><span class="linenos">1326</span></a>
</span><span id="FSWEmbedding-1327"><a href="#FSWEmbedding-1327"><span class="linenos">1327</span></a>            <span class="k">del</span> <span class="n">W_sum</span>
</span><span id="FSWEmbedding-1328"><a href="#FSWEmbedding-1328"><span class="linenos">1328</span></a>
</span><span id="FSWEmbedding-1329"><a href="#FSWEmbedding-1329"><span class="linenos">1329</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="c1"># to silence PyCharm</span>
</span><span id="FSWEmbedding-1330"><a href="#FSWEmbedding-1330"><span class="linenos">1330</span></a>
</span><span id="FSWEmbedding-1331"><a href="#FSWEmbedding-1331"><span class="linenos">1331</span></a>            <span class="n">needs_emb_norm</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span> <span class="ow">in</span>
</span><span id="FSWEmbedding-1332"><a href="#FSWEmbedding-1332"><span class="linenos">1332</span></a>                              <span class="p">{</span><span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS</span><span class="p">,</span>
</span><span id="FSWEmbedding-1333"><a href="#FSWEmbedding-1333"><span class="linenos">1333</span></a>                               <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_SCALED</span><span class="p">,</span>
</span><span id="FSWEmbedding-1334"><a href="#FSWEmbedding-1334"><span class="linenos">1334</span></a>                               <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_LEGACY</span><span class="p">})</span>
</span><span id="FSWEmbedding-1335"><a href="#FSWEmbedding-1335"><span class="linenos">1335</span></a>
</span><span id="FSWEmbedding-1336"><a href="#FSWEmbedding-1336"><span class="linenos">1336</span></a>            <span class="k">if</span> <span class="n">needs_emb_norm</span><span class="p">:</span>
</span><span id="FSWEmbedding-1337"><a href="#FSWEmbedding-1337"><span class="linenos">1337</span></a>                <span class="n">X_emb_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X_emb</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">X_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
</span><span id="FSWEmbedding-1338"><a href="#FSWEmbedding-1338"><span class="linenos">1338</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1339"><a href="#FSWEmbedding-1339"><span class="linenos">1339</span></a>                <span class="n">X_emb_norm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding-1340"><a href="#FSWEmbedding-1340"><span class="linenos">1340</span></a>
</span><span id="FSWEmbedding-1341"><a href="#FSWEmbedding-1341"><span class="linenos">1341</span></a>            <span class="k">match</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span><span class="p">:</span>
</span><span id="FSWEmbedding-1342"><a href="#FSWEmbedding-1342"><span class="linenos">1342</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">DECOUPLED</span><span class="p">:</span>
</span><span id="FSWEmbedding-1343"><a href="#FSWEmbedding-1343"><span class="linenos">1343</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">,</span> <span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1344"><a href="#FSWEmbedding-1344"><span class="linenos">1344</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">SCALED</span><span class="p">:</span>
</span><span id="FSWEmbedding-1345"><a href="#FSWEmbedding-1345"><span class="linenos">1345</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">,</span> <span class="n">encoded_total_mass</span><span class="o">*</span><span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1346"><a href="#FSWEmbedding-1346"><span class="linenos">1346</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS</span><span class="p">:</span>
</span><span id="FSWEmbedding-1347"><a href="#FSWEmbedding-1347"><span class="linenos">1347</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">encoded_total_mass</span> <span class="o">*</span> <span class="n">X_emb_norm</span><span class="p">,</span> <span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1348"><a href="#FSWEmbedding-1348"><span class="linenos">1348</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_SCALED</span><span class="p">:</span>
</span><span id="FSWEmbedding-1349"><a href="#FSWEmbedding-1349"><span class="linenos">1349</span></a>                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_emb_norm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="c1"># to silence PyCharm</span>
</span><span id="FSWEmbedding-1350"><a href="#FSWEmbedding-1350"><span class="linenos">1350</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">X_emb_norm</span><span class="p">,</span> <span class="n">encoded_total_mass</span><span class="o">*</span><span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1351"><a href="#FSWEmbedding-1351"><span class="linenos">1351</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_LEGACY</span><span class="p">:</span>
</span><span id="FSWEmbedding-1352"><a href="#FSWEmbedding-1352"><span class="linenos">1352</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_total_mass_homogeneous_legacy_encoding_part1</span><span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">)</span> <span class="o">*</span> <span class="n">X_emb_norm</span><span class="p">,</span>
</span><span id="FSWEmbedding-1353"><a href="#FSWEmbedding-1353"><span class="linenos">1353</span></a>                                       <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_total_mass_homogeneous_legacy_encoding_part2</span><span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">)</span> <span class="o">*</span> <span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1354"><a href="#FSWEmbedding-1354"><span class="linenos">1354</span></a>                <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>  <span class="c1"># fallback</span>
</span><span id="FSWEmbedding-1355"><a href="#FSWEmbedding-1355"><span class="linenos">1355</span></a>                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported encoding method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding-1356"><a href="#FSWEmbedding-1356"><span class="linenos">1356</span></a>
</span><span id="FSWEmbedding-1357"><a href="#FSWEmbedding-1357"><span class="linenos">1357</span></a>            <span class="k">del</span> <span class="n">X_emb_norm</span>
</span><span id="FSWEmbedding-1358"><a href="#FSWEmbedding-1358"><span class="linenos">1358</span></a>
</span><span id="FSWEmbedding-1359"><a href="#FSWEmbedding-1359"><span class="linenos">1359</span></a>        <span class="c1"># Add bias</span>
</span><span id="FSWEmbedding-1360"><a href="#FSWEmbedding-1360"><span class="linenos">1360</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding-1361"><a href="#FSWEmbedding-1361"><span class="linenos">1361</span></a>            <span class="n">X_emb</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</span><span id="FSWEmbedding-1362"><a href="#FSWEmbedding-1362"><span class="linenos">1362</span></a>
</span><span id="FSWEmbedding-1363"><a href="#FSWEmbedding-1363"><span class="linenos">1363</span></a>        <span class="k">return</span> <span class="n">X_emb</span>
</span><span id="FSWEmbedding-1364"><a href="#FSWEmbedding-1364"><span class="linenos">1364</span></a>
</span><span id="FSWEmbedding-1365"><a href="#FSWEmbedding-1365"><span class="linenos">1365</span></a>
</span><span id="FSWEmbedding-1366"><a href="#FSWEmbedding-1366"><span class="linenos">1366</span></a>    <span class="nd">@staticmethod</span>
</span><span id="FSWEmbedding-1367"><a href="#FSWEmbedding-1367"><span class="linenos">1367</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_helper</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">slice_vectors</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">,</span> <span class="n">graph_mode</span><span class="p">,</span> <span class="n">X_edge</span><span class="p">,</span> <span class="n">cartesian_mode</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">,</span>
</span><span id="FSWEmbedding-1368"><a href="#FSWEmbedding-1368"><span class="linenos">1368</span></a>                        <span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1369"><a href="#FSWEmbedding-1369"><span class="linenos">1369</span></a>                        <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">):</span>
</span><span id="FSWEmbedding-1370"><a href="#FSWEmbedding-1370"><span class="linenos">1370</span></a>        <span class="c1"># This function computes the embedding of (X,W) for a subset of the slices and frequencies.</span>
</span><span id="FSWEmbedding-1371"><a href="#FSWEmbedding-1371"><span class="linenos">1371</span></a>        <span class="c1"># slice_vectors should be of size (num_slices x d_in), and frequencies should be of size num_frequencies (not num_frequencies x 1).</span>
</span><span id="FSWEmbedding-1372"><a href="#FSWEmbedding-1372"><span class="linenos">1372</span></a>
</span><span id="FSWEmbedding-1373"><a href="#FSWEmbedding-1373"><span class="linenos">1373</span></a>        <span class="n">d_in</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="FSWEmbedding-1374"><a href="#FSWEmbedding-1374"><span class="linenos">1374</span></a>        <span class="c1">#n = W.shape[-1]</span>
</span><span id="FSWEmbedding-1375"><a href="#FSWEmbedding-1375"><span class="linenos">1375</span></a>        <span class="n">nRecepients</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="FSWEmbedding-1376"><a href="#FSWEmbedding-1376"><span class="linenos">1376</span></a>        <span class="n">num_slices</span> <span class="o">=</span> <span class="n">slice_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FSWEmbedding-1377"><a href="#FSWEmbedding-1377"><span class="linenos">1377</span></a>        <span class="n">num_frequencies</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding-1378"><a href="#FSWEmbedding-1378"><span class="linenos">1378</span></a>        <span class="n">sparse_mode</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span>
</span><span id="FSWEmbedding-1379"><a href="#FSWEmbedding-1379"><span class="linenos">1379</span></a>        <span class="n">d_edge</span> <span class="o">=</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
</span><span id="FSWEmbedding-1380"><a href="#FSWEmbedding-1380"><span class="linenos">1380</span></a>
</span><span id="FSWEmbedding-1381"><a href="#FSWEmbedding-1381"><span class="linenos">1381</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">frequencies</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;This should not happen&quot;</span>
</span><span id="FSWEmbedding-1382"><a href="#FSWEmbedding-1382"><span class="linenos">1382</span></a>        <span class="k">assert</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">d_in</span> <span class="o">+</span> <span class="n">d_edge</span><span class="p">),</span> <span class="s2">&quot;This should not happen&quot;</span>
</span><span id="FSWEmbedding-1383"><a href="#FSWEmbedding-1383"><span class="linenos">1383</span></a>
</span><span id="FSWEmbedding-1384"><a href="#FSWEmbedding-1384"><span class="linenos">1384</span></a>        <span class="c1"># Calculate the projections of X</span>
</span><span id="FSWEmbedding-1385"><a href="#FSWEmbedding-1385"><span class="linenos">1385</span></a>        <span class="k">if</span> <span class="n">d_edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-1386"><a href="#FSWEmbedding-1386"><span class="linenos">1386</span></a>            <span class="n">Xp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">slice_vectors</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,],[</span><span class="mi">1</span><span class="p">,]))</span>
</span><span id="FSWEmbedding-1387"><a href="#FSWEmbedding-1387"><span class="linenos">1387</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1388"><a href="#FSWEmbedding-1388"><span class="linenos">1388</span></a>            <span class="c1"># noinspection PyUnresolvedReferences</span>
</span><span id="FSWEmbedding-1389"><a href="#FSWEmbedding-1389"><span class="linenos">1389</span></a>            <span class="n">Xp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">slice_vectors</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">d_in</span><span class="p">],</span> <span class="n">dims</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,],[</span><span class="mi">1</span><span class="p">,]))</span>
</span><span id="FSWEmbedding-1390"><a href="#FSWEmbedding-1390"><span class="linenos">1390</span></a>
</span><span id="FSWEmbedding-1391"><a href="#FSWEmbedding-1391"><span class="linenos">1391</span></a>        <span class="k">del</span> <span class="n">X</span>
</span><span id="FSWEmbedding-1392"><a href="#FSWEmbedding-1392"><span class="linenos">1392</span></a>
</span><span id="FSWEmbedding-1393"><a href="#FSWEmbedding-1393"><span class="linenos">1393</span></a>        <span class="k">if</span> <span class="n">d_edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-1394"><a href="#FSWEmbedding-1394"><span class="linenos">1394</span></a>            <span class="c1"># Sort the projected elements </span>
</span><span id="FSWEmbedding-1395"><a href="#FSWEmbedding-1395"><span class="linenos">1395</span></a>            <span class="c1"># Note: We sort before the graph-mode expansion because it makes things simpler in the case when W is sparse</span>
</span><span id="FSWEmbedding-1396"><a href="#FSWEmbedding-1396"><span class="linenos">1396</span></a>
</span><span id="FSWEmbedding-1397"><a href="#FSWEmbedding-1397"><span class="linenos">1397</span></a>            <span class="c1"># Sort along element/sender axis</span>
</span><span id="FSWEmbedding-1398"><a href="#FSWEmbedding-1398"><span class="linenos">1398</span></a>            <span class="k">if</span> <span class="n">sparse_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1399"><a href="#FSWEmbedding-1399"><span class="linenos">1399</span></a>                <span class="n">Xps</span><span class="p">,</span> <span class="n">Xpi</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">sort</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="FSWEmbedding-1400"><a href="#FSWEmbedding-1400"><span class="linenos">1400</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1401"><a href="#FSWEmbedding-1401"><span class="linenos">1401</span></a>                <span class="n">Xps</span><span class="p">,</span> <span class="n">Xpi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">Xp</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="FSWEmbedding-1402"><a href="#FSWEmbedding-1402"><span class="linenos">1402</span></a>
</span><span id="FSWEmbedding-1403"><a href="#FSWEmbedding-1403"><span class="linenos">1403</span></a>            <span class="k">del</span> <span class="n">Xp</span>
</span><span id="FSWEmbedding-1404"><a href="#FSWEmbedding-1404"><span class="linenos">1404</span></a>
</span><span id="FSWEmbedding-1405"><a href="#FSWEmbedding-1405"><span class="linenos">1405</span></a>            <span class="k">if</span> <span class="n">graph_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1406"><a href="#FSWEmbedding-1406"><span class="linenos">1406</span></a>                <span class="c1"># Create recepient axis before sender axis and slice axis</span>
</span><span id="FSWEmbedding-1407"><a href="#FSWEmbedding-1407"><span class="linenos">1407</span></a>                <span class="n">Xps</span> <span class="o">=</span> <span class="n">Xps</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>
</span><span id="FSWEmbedding-1408"><a href="#FSWEmbedding-1408"><span class="linenos">1408</span></a>                <span class="n">Xpi</span> <span class="o">=</span> <span class="n">Xpi</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span>
</span><span id="FSWEmbedding-1409"><a href="#FSWEmbedding-1409"><span class="linenos">1409</span></a>
</span><span id="FSWEmbedding-1410"><a href="#FSWEmbedding-1410"><span class="linenos">1410</span></a>        <span class="k">elif</span> <span class="n">sparse_mode</span><span class="p">:</span> <span class="c1"># d_edge &gt; 0, sparse_mode=True</span>
</span><span id="FSWEmbedding-1411"><a href="#FSWEmbedding-1411"><span class="linenos">1411</span></a>            <span class="n">Xe</span> <span class="o">=</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span><span id="FSWEmbedding-1412"><a href="#FSWEmbedding-1412"><span class="linenos">1412</span></a>            <span class="c1"># noinspection PyUnresolvedReferences</span>
</span><span id="FSWEmbedding-1413"><a href="#FSWEmbedding-1413"><span class="linenos">1413</span></a>            <span class="n">Xep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">Xe</span><span class="p">,</span> <span class="n">slice_vectors</span><span class="p">[:,</span><span class="n">d_in</span><span class="p">:],</span> <span class="n">dims</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,]))</span>
</span><span id="FSWEmbedding-1414"><a href="#FSWEmbedding-1414"><span class="linenos">1414</span></a>            <span class="k">del</span> <span class="n">Xe</span>
</span><span id="FSWEmbedding-1415"><a href="#FSWEmbedding-1415"><span class="linenos">1415</span></a>
</span><span id="FSWEmbedding-1416"><a href="#FSWEmbedding-1416"><span class="linenos">1416</span></a>            <span class="n">inds</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">indices</span><span class="p">()</span>
</span><span id="FSWEmbedding-1417"><a href="#FSWEmbedding-1417"><span class="linenos">1417</span></a>
</span><span id="FSWEmbedding-1418"><a href="#FSWEmbedding-1418"><span class="linenos">1418</span></a>            <span class="c1"># Remove recepient axis from inds</span>
</span><span id="FSWEmbedding-1419"><a href="#FSWEmbedding-1419"><span class="linenos">1419</span></a>            <span class="n">dims_without_recipient</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">inds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)]</span>
</span><span id="FSWEmbedding-1420"><a href="#FSWEmbedding-1420"><span class="linenos">1420</span></a>
</span><span id="FSWEmbedding-1421"><a href="#FSWEmbedding-1421"><span class="linenos">1421</span></a>            <span class="c1"># For each edge, get the corresponding sender vertex feature vector after projection</span>
</span><span id="FSWEmbedding-1422"><a href="#FSWEmbedding-1422"><span class="linenos">1422</span></a>            <span class="n">Xp_temp</span> <span class="o">=</span> <span class="n">Xp</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">inds</span><span class="p">[</span><span class="n">dims_without_recipient</span><span class="p">,:])]</span>
</span><span id="FSWEmbedding-1423"><a href="#FSWEmbedding-1423"><span class="linenos">1423</span></a>
</span><span id="FSWEmbedding-1424"><a href="#FSWEmbedding-1424"><span class="linenos">1424</span></a>            <span class="n">Xep</span> <span class="o">+=</span> <span class="n">Xp_temp</span>
</span><span id="FSWEmbedding-1425"><a href="#FSWEmbedding-1425"><span class="linenos">1425</span></a>            <span class="k">del</span> <span class="n">Xp_temp</span><span class="p">,</span> <span class="n">inds</span>
</span><span id="FSWEmbedding-1426"><a href="#FSWEmbedding-1426"><span class="linenos">1426</span></a>
</span><span id="FSWEmbedding-1427"><a href="#FSWEmbedding-1427"><span class="linenos">1427</span></a>            <span class="n">Xep_shape</span> <span class="o">=</span> <span class="n">replace_in_tuple</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">Xep</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="FSWEmbedding-1428"><a href="#FSWEmbedding-1428"><span class="linenos">1428</span></a>
</span><span id="FSWEmbedding-1429"><a href="#FSWEmbedding-1429"><span class="linenos">1429</span></a>            <span class="n">Xep</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse_coo_tensor_coalesced</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">W</span><span class="o">.</span><span class="n">indices</span><span class="p">(),</span> <span class="n">values</span><span class="o">=</span><span class="n">Xep</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Xep_shape</span><span class="p">)</span>
</span><span id="FSWEmbedding-1430"><a href="#FSWEmbedding-1430"><span class="linenos">1430</span></a>            <span class="n">Xep</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">flatten_dense_dim</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Xep</span><span class="p">)</span>
</span><span id="FSWEmbedding-1431"><a href="#FSWEmbedding-1431"><span class="linenos">1431</span></a>            <span class="n">Xeps</span><span class="p">,</span> <span class="n">Xepi</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">sort_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Xep</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="FSWEmbedding-1432"><a href="#FSWEmbedding-1432"><span class="linenos">1432</span></a>            <span class="k">del</span> <span class="n">Xep</span>
</span><span id="FSWEmbedding-1433"><a href="#FSWEmbedding-1433"><span class="linenos">1433</span></a>
</span><span id="FSWEmbedding-1434"><a href="#FSWEmbedding-1434"><span class="linenos">1434</span></a>        <span class="k">else</span><span class="p">:</span> <span class="c1"># d_edge &gt; 0, sparse_mode=False</span>
</span><span id="FSWEmbedding-1435"><a href="#FSWEmbedding-1435"><span class="linenos">1435</span></a>            <span class="c1"># Create recepient axis before sender axis and slice axis</span>
</span><span id="FSWEmbedding-1436"><a href="#FSWEmbedding-1436"><span class="linenos">1436</span></a>            <span class="n">Xpx</span> <span class="o">=</span> <span class="n">Xp</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span> <span class="c1">#.expand(tuple(W.shape) + (num_slices,))</span>
</span><span id="FSWEmbedding-1437"><a href="#FSWEmbedding-1437"><span class="linenos">1437</span></a>            <span class="c1"># Replicate Xpx along recepient axis</span>
</span><span id="FSWEmbedding-1438"><a href="#FSWEmbedding-1438"><span class="linenos">1438</span></a>            <span class="n">Xpx</span> <span class="o">=</span> <span class="n">Xpx</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">replace_in_tuple</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span><span class="o">*</span><span class="n">Xpx</span><span class="o">.</span><span class="n">dim</span><span class="p">(),</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="n">nRecepients</span><span class="p">))</span>
</span><span id="FSWEmbedding-1439"><a href="#FSWEmbedding-1439"><span class="linenos">1439</span></a>            <span class="c1"># Add edge-feature part of inner product to each recepient for each sender and projection</span>
</span><span id="FSWEmbedding-1440"><a href="#FSWEmbedding-1440"><span class="linenos">1440</span></a>            <span class="c1"># noinspection PyUnresolvedReferences</span>
</span><span id="FSWEmbedding-1441"><a href="#FSWEmbedding-1441"><span class="linenos">1441</span></a>            <span class="n">Xpx</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">X_edge</span><span class="p">,</span> <span class="n">slice_vectors</span><span class="p">[:,</span><span class="n">d_in</span><span class="p">:],</span> <span class="n">dims</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,]))</span>
</span><span id="FSWEmbedding-1442"><a href="#FSWEmbedding-1442"><span class="linenos">1442</span></a>            <span class="c1"># Sort along element/sender axis</span>
</span><span id="FSWEmbedding-1443"><a href="#FSWEmbedding-1443"><span class="linenos">1443</span></a>            <span class="n">Xps</span><span class="p">,</span> <span class="n">Xpi</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">sort</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Xpx</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="FSWEmbedding-1444"><a href="#FSWEmbedding-1444"><span class="linenos">1444</span></a>            <span class="c1">#Xps, Xpi = torch.sort(Xpx, dim=-2, descending=False, stable=True)</span>
</span><span id="FSWEmbedding-1445"><a href="#FSWEmbedding-1445"><span class="linenos">1445</span></a>
</span><span id="FSWEmbedding-1446"><a href="#FSWEmbedding-1446"><span class="linenos">1446</span></a>            <span class="k">del</span> <span class="n">Xpx</span>
</span><span id="FSWEmbedding-1447"><a href="#FSWEmbedding-1447"><span class="linenos">1447</span></a>
</span><span id="FSWEmbedding-1448"><a href="#FSWEmbedding-1448"><span class="linenos">1448</span></a>        <span class="c1"># Axis numbers as in the implementation of forward()</span>
</span><span id="FSWEmbedding-1449"><a href="#FSWEmbedding-1449"><span class="linenos">1449</span></a>        <span class="c1"># Note: These numbers are true only from here</span>
</span><span id="FSWEmbedding-1450"><a href="#FSWEmbedding-1450"><span class="linenos">1450</span></a>        <span class="n">recipient_axis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="kc">None</span>  <span class="c1"># Message-recipient vertices</span>
</span><span id="FSWEmbedding-1451"><a href="#FSWEmbedding-1451"><span class="linenos">1451</span></a>        <span class="n">element_axis</span>  <span class="o">=</span> <span class="n">recipient_axis</span><span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span> <span class="c1"># In graph mode this axis denotes the message-sender vertices</span>
</span><span id="FSWEmbedding-1452"><a href="#FSWEmbedding-1452"><span class="linenos">1452</span></a>        <span class="n">ambspace_axis</span> <span class="o">=</span> <span class="n">element_axis</span> <span class="o">+</span> <span class="mi">1</span>        
</span><span id="FSWEmbedding-1453"><a href="#FSWEmbedding-1453"><span class="linenos">1453</span></a>        <span class="n">slice_axis</span>     <span class="o">=</span> <span class="n">ambspace_axis</span>
</span><span id="FSWEmbedding-1454"><a href="#FSWEmbedding-1454"><span class="linenos">1454</span></a>        <span class="n">freq_axis</span>     <span class="o">=</span> <span class="n">slice_axis</span> <span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="n">cartesian_mode</span> <span class="k">else</span> <span class="n">slice_axis</span>
</span><span id="FSWEmbedding-1455"><a href="#FSWEmbedding-1455"><span class="linenos">1455</span></a>        <span class="c1"># noinspection PyUnusedLocal</span>
</span><span id="FSWEmbedding-1456"><a href="#FSWEmbedding-1456"><span class="linenos">1456</span></a>        <span class="n">output_slice_axis</span> <span class="o">=</span> <span class="n">element_axis</span> <span class="c1"># In the output, the element axis is replaced by the slice axis</span>
</span><span id="FSWEmbedding-1457"><a href="#FSWEmbedding-1457"><span class="linenos">1457</span></a>
</span><span id="FSWEmbedding-1458"><a href="#FSWEmbedding-1458"><span class="linenos">1458</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">frequencies</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="FSWEmbedding-1459"><a href="#FSWEmbedding-1459"><span class="linenos">1459</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">freq_axis</span><span class="p">):</span>
</span><span id="FSWEmbedding-1460"><a href="#FSWEmbedding-1460"><span class="linenos">1460</span></a>            <span class="n">frequencies</span> <span class="o">=</span> <span class="n">frequencies</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="FSWEmbedding-1461"><a href="#FSWEmbedding-1461"><span class="linenos">1461</span></a>
</span><span id="FSWEmbedding-1462"><a href="#FSWEmbedding-1462"><span class="linenos">1462</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1463"><a href="#FSWEmbedding-1463"><span class="linenos">1463</span></a>            <span class="k">if</span> <span class="n">graph_mode</span> <span class="ow">and</span> <span class="p">(</span><span class="n">d_edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
</span><span id="FSWEmbedding-1464"><a href="#FSWEmbedding-1464"><span class="linenos">1464</span></a>                <span class="n">Xps</span> <span class="o">=</span> <span class="n">Xps</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,))</span>
</span><span id="FSWEmbedding-1465"><a href="#FSWEmbedding-1465"><span class="linenos">1465</span></a>                <span class="n">Xpi</span> <span class="o">=</span> <span class="n">Xpi</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,))</span>
</span><span id="FSWEmbedding-1466"><a href="#FSWEmbedding-1466"><span class="linenos">1466</span></a>
</span><span id="FSWEmbedding-1467"><a href="#FSWEmbedding-1467"><span class="linenos">1467</span></a>            <span class="c1"># Sort the weights according to their corresponding projected elements</span>
</span><span id="FSWEmbedding-1468"><a href="#FSWEmbedding-1468"><span class="linenos">1468</span></a>            <span class="n">W_big</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">Xps</span><span class="p">)</span>
</span><span id="FSWEmbedding-1469"><a href="#FSWEmbedding-1469"><span class="linenos">1469</span></a>            <span class="n">Wps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">W_big</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">Xpi</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
</span><span id="FSWEmbedding-1470"><a href="#FSWEmbedding-1470"><span class="linenos">1470</span></a>
</span><span id="FSWEmbedding-1471"><a href="#FSWEmbedding-1471"><span class="linenos">1471</span></a>            <span class="k">if</span> <span class="n">cartesian_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1472"><a href="#FSWEmbedding-1472"><span class="linenos">1472</span></a>                <span class="n">Wps</span> <span class="o">=</span> <span class="n">Wps</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1473"><a href="#FSWEmbedding-1473"><span class="linenos">1473</span></a>                <span class="n">Xps</span> <span class="o">=</span> <span class="n">Xps</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">Xps</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">num_frequencies</span><span class="p">,))</span>
</span><span id="FSWEmbedding-1474"><a href="#FSWEmbedding-1474"><span class="linenos">1474</span></a>
</span><span id="FSWEmbedding-1475"><a href="#FSWEmbedding-1475"><span class="linenos">1475</span></a>            <span class="c1"># Once we have Wps we don&#39;t need W_big and Xpi</span>
</span><span id="FSWEmbedding-1476"><a href="#FSWEmbedding-1476"><span class="linenos">1476</span></a>            <span class="k">del</span> <span class="n">W_big</span><span class="p">,</span> <span class="n">Xpi</span>
</span><span id="FSWEmbedding-1477"><a href="#FSWEmbedding-1477"><span class="linenos">1477</span></a>
</span><span id="FSWEmbedding-1478"><a href="#FSWEmbedding-1478"><span class="linenos">1478</span></a>            <span class="n">Wps_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">Wps</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1479"><a href="#FSWEmbedding-1479"><span class="linenos">1479</span></a>
</span><span id="FSWEmbedding-1480"><a href="#FSWEmbedding-1480"><span class="linenos">1480</span></a>            <span class="c1"># Here we assume sinc(x) = sin(pi*x)/(pi*x)</span>
</span><span id="FSWEmbedding-1481"><a href="#FSWEmbedding-1481"><span class="linenos">1481</span></a>            <span class="n">sincs</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Wps_sum</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sinc</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">frequencies</span> <span class="o">*</span> <span class="n">Wps_sum</span><span class="p">)</span>
</span><span id="FSWEmbedding-1482"><a href="#FSWEmbedding-1482"><span class="linenos">1482</span></a>            <span class="n">sinc_diffs</span> <span class="o">=</span> <span class="n">diff_zeropad</span><span class="p">(</span><span class="n">sincs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1483"><a href="#FSWEmbedding-1483"><span class="linenos">1483</span></a>            <span class="k">del</span> <span class="n">sincs</span>
</span><span id="FSWEmbedding-1484"><a href="#FSWEmbedding-1484"><span class="linenos">1484</span></a>
</span><span id="FSWEmbedding-1485"><a href="#FSWEmbedding-1485"><span class="linenos">1485</span></a>        <span class="k">elif</span> <span class="n">sparse_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1486"><a href="#FSWEmbedding-1486"><span class="linenos">1486</span></a>            <span class="c1"># We unsqueeze W to add a slice axis, in order to sort W according to each projection of X</span>
</span><span id="FSWEmbedding-1487"><a href="#FSWEmbedding-1487"><span class="linenos">1487</span></a>            <span class="c1"># Note: This repmat is unavoidable, because we sort the weights according to different permutations along slice_axis</span>
</span><span id="FSWEmbedding-1488"><a href="#FSWEmbedding-1488"><span class="linenos">1488</span></a>            <span class="n">W_unsqueeze</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">unsqueeze_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1489"><a href="#FSWEmbedding-1489"><span class="linenos">1489</span></a>            <span class="k">del</span> <span class="n">W</span>
</span><span id="FSWEmbedding-1490"><a href="#FSWEmbedding-1490"><span class="linenos">1490</span></a>
</span><span id="FSWEmbedding-1491"><a href="#FSWEmbedding-1491"><span class="linenos">1491</span></a>            <span class="c1"># 1.71 seconds</span>
</span><span id="FSWEmbedding-1492"><a href="#FSWEmbedding-1492"><span class="linenos">1492</span></a>            <span class="n">W_big</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">repmat_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W_unsqueeze</span><span class="p">,</span> <span class="n">num_slices</span><span class="p">,</span> <span class="n">slice_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1493"><a href="#FSWEmbedding-1493"><span class="linenos">1493</span></a>            <span class="k">del</span> <span class="n">W_unsqueeze</span>
</span><span id="FSWEmbedding-1494"><a href="#FSWEmbedding-1494"><span class="linenos">1494</span></a>
</span><span id="FSWEmbedding-1495"><a href="#FSWEmbedding-1495"><span class="linenos">1495</span></a>            <span class="k">if</span> <span class="n">d_edge</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-1496"><a href="#FSWEmbedding-1496"><span class="linenos">1496</span></a>                <span class="n">Wps</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">permute_sparse_vals</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W_big</span><span class="p">,</span> <span class="n">Xepi</span><span class="p">)</span>
</span><span id="FSWEmbedding-1497"><a href="#FSWEmbedding-1497"><span class="linenos">1497</span></a>                <span class="k">del</span> <span class="n">Xepi</span>
</span><span id="FSWEmbedding-1498"><a href="#FSWEmbedding-1498"><span class="linenos">1498</span></a>            <span class="k">elif</span> <span class="n">graph_mode</span><span class="p">:</span> 
</span><span id="FSWEmbedding-1499"><a href="#FSWEmbedding-1499"><span class="linenos">1499</span></a>                <span class="c1"># 1.82 seconds</span>
</span><span id="FSWEmbedding-1500"><a href="#FSWEmbedding-1500"><span class="linenos">1500</span></a>                <span class="n">Wps</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">permute_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W_big</span><span class="p">,</span> <span class="n">element_axis</span><span class="p">,</span> <span class="n">Xpi</span><span class="p">,</span> <span class="n">recipient_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1501"><a href="#FSWEmbedding-1501"><span class="linenos">1501</span></a>                <span class="k">del</span> <span class="n">Xpi</span>
</span><span id="FSWEmbedding-1502"><a href="#FSWEmbedding-1502"><span class="linenos">1502</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1503"><a href="#FSWEmbedding-1503"><span class="linenos">1503</span></a>                <span class="n">Wps</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">permute_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W_big</span><span class="p">,</span> <span class="n">element_axis</span><span class="p">,</span> <span class="n">Xpi</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span id="FSWEmbedding-1504"><a href="#FSWEmbedding-1504"><span class="linenos">1504</span></a>                <span class="k">del</span> <span class="n">Xpi</span>
</span><span id="FSWEmbedding-1505"><a href="#FSWEmbedding-1505"><span class="linenos">1505</span></a>
</span><span id="FSWEmbedding-1506"><a href="#FSWEmbedding-1506"><span class="linenos">1506</span></a>            <span class="c1"># Once we have Wps we don&#39;t need W_big and Xpi</span>
</span><span id="FSWEmbedding-1507"><a href="#FSWEmbedding-1507"><span class="linenos">1507</span></a>            <span class="k">del</span> <span class="n">W_big</span>
</span><span id="FSWEmbedding-1508"><a href="#FSWEmbedding-1508"><span class="linenos">1508</span></a>
</span><span id="FSWEmbedding-1509"><a href="#FSWEmbedding-1509"><span class="linenos">1509</span></a>            <span class="c1"># 2.6 seconds</span>
</span><span id="FSWEmbedding-1510"><a href="#FSWEmbedding-1510"><span class="linenos">1510</span></a>            <span class="n">slice_info_elements</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_slice_info</span><span class="p">(</span><span class="n">Wps</span><span class="p">,</span> <span class="n">element_axis</span><span class="p">,</span> <span class="n">calc_nnz_per_slice</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-1511"><a href="#FSWEmbedding-1511"><span class="linenos">1511</span></a>                                                    <span class="n">use_custom_cuda_extension_if_available</span><span class="o">=</span><span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span> <span class="n">fail_if_cuda_extension_load_fails</span><span class="o">=</span><span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1512"><a href="#FSWEmbedding-1512"><span class="linenos">1512</span></a>            <span class="n">Wps_sum</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">cumsum_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Wps</span><span class="p">,</span> <span class="n">element_axis</span><span class="p">,</span> <span class="n">slice_info_elements</span><span class="p">,</span>
</span><span id="FSWEmbedding-1513"><a href="#FSWEmbedding-1513"><span class="linenos">1513</span></a>                                             <span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1514"><a href="#FSWEmbedding-1514"><span class="linenos">1514</span></a>                                             <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1515"><a href="#FSWEmbedding-1515"><span class="linenos">1515</span></a>
</span><span id="FSWEmbedding-1516"><a href="#FSWEmbedding-1516"><span class="linenos">1516</span></a>            <span class="n">sp</span><span class="o">.</span><span class="n">verify_coalescence</span><span class="p">(</span><span class="n">Wps</span><span class="p">)</span>
</span><span id="FSWEmbedding-1517"><a href="#FSWEmbedding-1517"><span class="linenos">1517</span></a>            <span class="n">sp</span><span class="o">.</span><span class="n">verify_coalescence</span><span class="p">(</span><span class="n">Wps_sum</span><span class="p">)</span>
</span><span id="FSWEmbedding-1518"><a href="#FSWEmbedding-1518"><span class="linenos">1518</span></a>
</span><span id="FSWEmbedding-1519"><a href="#FSWEmbedding-1519"><span class="linenos">1519</span></a>            <span class="k">if</span> <span class="n">cartesian_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1520"><a href="#FSWEmbedding-1520"><span class="linenos">1520</span></a>                <span class="c1"># Note:</span>
</span><span id="FSWEmbedding-1521"><a href="#FSWEmbedding-1521"><span class="linenos">1521</span></a>                <span class="c1"># These repmats may be avoided if ag.sinc_cos_sparse could take frequencies as a separate input, and broadcast all inputs accordingly.</span>
</span><span id="FSWEmbedding-1522"><a href="#FSWEmbedding-1522"><span class="linenos">1522</span></a>                <span class="c1"># But sinc_diffs is of the same size as Wps and Wps_sum, so we could reduce the memory usage at most by 2/3, and only in cartesian mode.</span>
</span><span id="FSWEmbedding-1523"><a href="#FSWEmbedding-1523"><span class="linenos">1523</span></a>                <span class="c1"># This may not worth the effort.</span>
</span><span id="FSWEmbedding-1524"><a href="#FSWEmbedding-1524"><span class="linenos">1524</span></a>
</span><span id="FSWEmbedding-1525"><a href="#FSWEmbedding-1525"><span class="linenos">1525</span></a>                <span class="n">Wps</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">repmat_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">ag</span><span class="o">.</span><span class="n">unsqueeze_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Wps</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">num_frequencies</span><span class="p">,</span> <span class="n">freq_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1526"><a href="#FSWEmbedding-1526"><span class="linenos">1526</span></a>                <span class="n">Wps_sum</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">repmat_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">ag</span><span class="o">.</span><span class="n">unsqueeze_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Wps_sum</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">num_frequencies</span><span class="p">,</span> <span class="n">freq_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1527"><a href="#FSWEmbedding-1527"><span class="linenos">1527</span></a>                <span class="n">Xps</span> <span class="o">=</span> <span class="n">Xps</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">Xps</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">num_frequencies</span><span class="p">,))</span>
</span><span id="FSWEmbedding-1528"><a href="#FSWEmbedding-1528"><span class="linenos">1528</span></a>               
</span><span id="FSWEmbedding-1529"><a href="#FSWEmbedding-1529"><span class="linenos">1529</span></a>            <span class="c1"># Here we use the sum-to-product identity sin(2a)-sin(2b) = 2*sin(a-b)*cos(a+b)            </span>
</span><span id="FSWEmbedding-1530"><a href="#FSWEmbedding-1530"><span class="linenos">1530</span></a>            <span class="c1"># This formula probably leads to a loss of one significant digit, but it is much easier in the sparse case than using diff().</span>
</span><span id="FSWEmbedding-1531"><a href="#FSWEmbedding-1531"><span class="linenos">1531</span></a>            
</span><span id="FSWEmbedding-1532"><a href="#FSWEmbedding-1532"><span class="linenos">1532</span></a>            <span class="c1"># Variant 2 is more memory efficient</span>
</span><span id="FSWEmbedding-1533"><a href="#FSWEmbedding-1533"><span class="linenos">1533</span></a>            <span class="n">variant</span> <span class="o">=</span> <span class="mi">2</span>
</span><span id="FSWEmbedding-1534"><a href="#FSWEmbedding-1534"><span class="linenos">1534</span></a>
</span><span id="FSWEmbedding-1535"><a href="#FSWEmbedding-1535"><span class="linenos">1535</span></a>            <span class="k">if</span> <span class="n">variant</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FSWEmbedding-1536"><a href="#FSWEmbedding-1536"><span class="linenos">1536</span></a>                <span class="n">arg2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">frequencies</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">Wps_sum</span> <span class="o">-</span> <span class="n">Wps</span><span class="p">)</span>
</span><span id="FSWEmbedding-1537"><a href="#FSWEmbedding-1537"><span class="linenos">1537</span></a>                <span class="k">del</span> <span class="n">Wps_sum</span>
</span><span id="FSWEmbedding-1538"><a href="#FSWEmbedding-1538"><span class="linenos">1538</span></a>                <span class="n">assert_coalesced</span><span class="p">(</span><span class="n">arg2</span><span class="p">)</span>
</span><span id="FSWEmbedding-1539"><a href="#FSWEmbedding-1539"><span class="linenos">1539</span></a>
</span><span id="FSWEmbedding-1540"><a href="#FSWEmbedding-1540"><span class="linenos">1540</span></a>            <span class="k">elif</span> <span class="n">variant</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>                               
</span><span id="FSWEmbedding-1541"><a href="#FSWEmbedding-1541"><span class="linenos">1541</span></a>                <span class="n">arg2</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">add_same_pattern</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Wps</span><span class="p">,</span> <span class="n">Wps_sum</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="FSWEmbedding-1542"><a href="#FSWEmbedding-1542"><span class="linenos">1542</span></a>                <span class="k">del</span> <span class="n">Wps_sum</span>
</span><span id="FSWEmbedding-1543"><a href="#FSWEmbedding-1543"><span class="linenos">1543</span></a>                <span class="c1"># 1.22 seconds</span>
</span><span id="FSWEmbedding-1544"><a href="#FSWEmbedding-1544"><span class="linenos">1544</span></a>                <span class="n">slice_info_freqs</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_slice_info</span><span class="p">(</span><span class="n">arg2</span><span class="p">,</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_broadcast_dims_B_to_A</span><span class="p">(</span><span class="n">arg2</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">),</span>
</span><span id="FSWEmbedding-1545"><a href="#FSWEmbedding-1545"><span class="linenos">1545</span></a>                                                     <span class="n">calc_nnz_per_slice</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-1546"><a href="#FSWEmbedding-1546"><span class="linenos">1546</span></a>                                                     <span class="n">use_custom_cuda_extension_if_available</span><span class="o">=</span><span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1547"><a href="#FSWEmbedding-1547"><span class="linenos">1547</span></a>                                                     <span class="n">fail_if_cuda_extension_load_fails</span><span class="o">=</span><span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1548"><a href="#FSWEmbedding-1548"><span class="linenos">1548</span></a>                <span class="c1"># 0.15 seconds</span>
</span><span id="FSWEmbedding-1549"><a href="#FSWEmbedding-1549"><span class="linenos">1549</span></a>                <span class="n">arg2</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">mul_sparse_dense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">arg2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">slice_info_freqs</span><span class="p">,</span>
</span><span id="FSWEmbedding-1550"><a href="#FSWEmbedding-1550"><span class="linenos">1550</span></a>                                                 <span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1551"><a href="#FSWEmbedding-1551"><span class="linenos">1551</span></a>                                                 <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1552"><a href="#FSWEmbedding-1552"><span class="linenos">1552</span></a>
</span><span id="FSWEmbedding-1553"><a href="#FSWEmbedding-1553"><span class="linenos">1553</span></a>            <span class="c1"># 0.14 seconds</span>
</span><span id="FSWEmbedding-1554"><a href="#FSWEmbedding-1554"><span class="linenos">1554</span></a>            <span class="n">arg1</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">mul_sparse_dense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Wps</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">,</span> <span class="n">slice_info_freqs</span><span class="p">,</span>
</span><span id="FSWEmbedding-1555"><a href="#FSWEmbedding-1555"><span class="linenos">1555</span></a>                                             <span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1556"><a href="#FSWEmbedding-1556"><span class="linenos">1556</span></a>                                             <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1557"><a href="#FSWEmbedding-1557"><span class="linenos">1557</span></a>
</span><span id="FSWEmbedding-1558"><a href="#FSWEmbedding-1558"><span class="linenos">1558</span></a>            <span class="n">sp</span><span class="o">.</span><span class="n">verify_coalescence</span><span class="p">(</span><span class="n">arg1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1559"><a href="#FSWEmbedding-1559"><span class="linenos">1559</span></a>            <span class="n">sp</span><span class="o">.</span><span class="n">verify_coalescence</span><span class="p">(</span><span class="n">arg2</span><span class="p">)</span>
</span><span id="FSWEmbedding-1560"><a href="#FSWEmbedding-1560"><span class="linenos">1560</span></a>
</span><span id="FSWEmbedding-1561"><a href="#FSWEmbedding-1561"><span class="linenos">1561</span></a>            <span class="c1"># 0.53 seconds</span>
</span><span id="FSWEmbedding-1562"><a href="#FSWEmbedding-1562"><span class="linenos">1562</span></a>            <span class="n">sinc_cos</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">sinc_cos_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">)</span>
</span><span id="FSWEmbedding-1563"><a href="#FSWEmbedding-1563"><span class="linenos">1563</span></a>            <span class="k">del</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span>
</span><span id="FSWEmbedding-1564"><a href="#FSWEmbedding-1564"><span class="linenos">1564</span></a>            <span class="n">sinc_diffs</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">mul_same_pattern</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span> <span class="n">Wps</span><span class="p">,</span> <span class="n">sinc_cos</span><span class="p">,</span> <span class="mi">2</span> <span class="p">)</span> 
</span><span id="FSWEmbedding-1565"><a href="#FSWEmbedding-1565"><span class="linenos">1565</span></a>
</span><span id="FSWEmbedding-1566"><a href="#FSWEmbedding-1566"><span class="linenos">1566</span></a>            <span class="n">sp</span><span class="o">.</span><span class="n">verify_coalescence</span><span class="p">(</span><span class="n">sinc_cos</span><span class="p">)</span>
</span><span id="FSWEmbedding-1567"><a href="#FSWEmbedding-1567"><span class="linenos">1567</span></a>            <span class="n">sp</span><span class="o">.</span><span class="n">verify_coalescence</span><span class="p">(</span><span class="n">sinc_diffs</span><span class="p">)</span>
</span><span id="FSWEmbedding-1568"><a href="#FSWEmbedding-1568"><span class="linenos">1568</span></a>
</span><span id="FSWEmbedding-1569"><a href="#FSWEmbedding-1569"><span class="linenos">1569</span></a>            <span class="k">del</span> <span class="n">Wps</span><span class="p">,</span> <span class="n">sinc_cos</span>
</span><span id="FSWEmbedding-1570"><a href="#FSWEmbedding-1570"><span class="linenos">1570</span></a>           
</span><span id="FSWEmbedding-1571"><a href="#FSWEmbedding-1571"><span class="linenos">1571</span></a>        <span class="c1"># From here we only need sinc_diffs and Xps               </span>
</span><span id="FSWEmbedding-1572"><a href="#FSWEmbedding-1572"><span class="linenos">1572</span></a>
</span><span id="FSWEmbedding-1573"><a href="#FSWEmbedding-1573"><span class="linenos">1573</span></a>        <span class="k">if</span> <span class="n">sparse_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding-1574"><a href="#FSWEmbedding-1574"><span class="linenos">1574</span></a>            <span class="k">if</span> <span class="n">d_edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding-1575"><a href="#FSWEmbedding-1575"><span class="linenos">1575</span></a>                <span class="c1"># 1.4 seconds</span>
</span><span id="FSWEmbedding-1576"><a href="#FSWEmbedding-1576"><span class="linenos">1576</span></a>                <span class="n">slice_info_Xps</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_slice_info</span><span class="p">(</span><span class="n">sinc_diffs</span><span class="p">,</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_broadcast_dims_B_to_A</span><span class="p">(</span><span class="n">sinc_diffs</span><span class="p">,</span> <span class="n">Xps</span><span class="p">),</span>
</span><span id="FSWEmbedding-1577"><a href="#FSWEmbedding-1577"><span class="linenos">1577</span></a>                                                   <span class="n">calc_nnz_per_slice</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding-1578"><a href="#FSWEmbedding-1578"><span class="linenos">1578</span></a>                                                   <span class="n">use_custom_cuda_extension_if_available</span><span class="o">=</span><span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1579"><a href="#FSWEmbedding-1579"><span class="linenos">1579</span></a>                                                   <span class="n">fail_if_cuda_extension_load_fails</span><span class="o">=</span><span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1580"><a href="#FSWEmbedding-1580"><span class="linenos">1580</span></a>                <span class="c1"># 0.26 seconds</span>
</span><span id="FSWEmbedding-1581"><a href="#FSWEmbedding-1581"><span class="linenos">1581</span></a>                <span class="n">products</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">mul_sparse_dense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sinc_diffs</span><span class="p">,</span> <span class="n">Xps</span><span class="p">,</span> <span class="n">slice_info_Xps</span><span class="p">,</span>
</span><span id="FSWEmbedding-1582"><a href="#FSWEmbedding-1582"><span class="linenos">1582</span></a>                                                     <span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1583"><a href="#FSWEmbedding-1583"><span class="linenos">1583</span></a>                                                     <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1584"><a href="#FSWEmbedding-1584"><span class="linenos">1584</span></a>                <span class="k">del</span> <span class="n">sinc_diffs</span><span class="p">,</span> <span class="n">Xps</span><span class="p">,</span> <span class="n">slice_info_Xps</span>
</span><span id="FSWEmbedding-1585"><a href="#FSWEmbedding-1585"><span class="linenos">1585</span></a>                <span class="n">sp</span><span class="o">.</span><span class="n">verify_coalescence</span><span class="p">(</span><span class="n">products</span><span class="p">)</span>
</span><span id="FSWEmbedding-1586"><a href="#FSWEmbedding-1586"><span class="linenos">1586</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding-1587"><a href="#FSWEmbedding-1587"><span class="linenos">1587</span></a>                <span class="n">products</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">mul_same_pattern</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sinc_diffs</span><span class="p">,</span> <span class="n">Xeps</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1588"><a href="#FSWEmbedding-1588"><span class="linenos">1588</span></a>                <span class="k">del</span> <span class="n">sinc_diffs</span><span class="p">,</span> <span class="n">Xeps</span>
</span><span id="FSWEmbedding-1589"><a href="#FSWEmbedding-1589"><span class="linenos">1589</span></a>
</span><span id="FSWEmbedding-1590"><a href="#FSWEmbedding-1590"><span class="linenos">1590</span></a>            <span class="c1"># 0.49 seconds</span>
</span><span id="FSWEmbedding-1591"><a href="#FSWEmbedding-1591"><span class="linenos">1591</span></a>            <span class="n">product_sums</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">sum_sparseToDense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">products</span><span class="p">,</span> <span class="n">element_axis</span><span class="p">,</span> <span class="n">slice_info_elements</span><span class="p">,</span>
</span><span id="FSWEmbedding-1592"><a href="#FSWEmbedding-1592"><span class="linenos">1592</span></a>                                                      <span class="n">use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding-1593"><a href="#FSWEmbedding-1593"><span class="linenos">1593</span></a>                                                      <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding-1594"><a href="#FSWEmbedding-1594"><span class="linenos">1594</span></a>            <span class="k">del</span> <span class="n">products</span><span class="p">,</span> <span class="n">slice_info_elements</span>
</span><span id="FSWEmbedding-1595"><a href="#FSWEmbedding-1595"><span class="linenos">1595</span></a>            
</span><span id="FSWEmbedding-1596"><a href="#FSWEmbedding-1596"><span class="linenos">1596</span></a>        <span class="k">else</span><span class="p">:</span> <span class="c1"># not sparse</span>
</span><span id="FSWEmbedding-1597"><a href="#FSWEmbedding-1597"><span class="linenos">1597</span></a>            <span class="n">product_sums</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sinc_diffs</span> <span class="o">*</span> <span class="n">Xps</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="FSWEmbedding-1598"><a href="#FSWEmbedding-1598"><span class="linenos">1598</span></a>            <span class="k">del</span> <span class="n">sinc_diffs</span><span class="p">,</span> <span class="n">Xps</span>
</span><span id="FSWEmbedding-1599"><a href="#FSWEmbedding-1599"><span class="linenos">1599</span></a>
</span><span id="FSWEmbedding-1600"><a href="#FSWEmbedding-1600"><span class="linenos">1600</span></a>        <span class="c1"># We squeeze the element axis after having summed up along it</span>
</span><span id="FSWEmbedding-1601"><a href="#FSWEmbedding-1601"><span class="linenos">1601</span></a>        <span class="n">product_sums</span> <span class="o">=</span> <span class="n">product_sums</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1602"><a href="#FSWEmbedding-1602"><span class="linenos">1602</span></a>        <span class="n">frequencies</span> <span class="o">=</span> <span class="n">frequencies</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">)</span>
</span><span id="FSWEmbedding-1603"><a href="#FSWEmbedding-1603"><span class="linenos">1603</span></a>
</span><span id="FSWEmbedding-1604"><a href="#FSWEmbedding-1604"><span class="linenos">1604</span></a>        <span class="c1"># frequencies and product_sums are always dense</span>
</span><span id="FSWEmbedding-1605"><a href="#FSWEmbedding-1605"><span class="linenos">1605</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">frequencies</span><span class="p">)</span> <span class="o">*</span> <span class="n">product_sums</span>            
</span><span id="FSWEmbedding-1606"><a href="#FSWEmbedding-1606"><span class="linenos">1606</span></a>        <span class="k">del</span> <span class="n">product_sums</span>
</span><span id="FSWEmbedding-1607"><a href="#FSWEmbedding-1607"><span class="linenos">1607</span></a>
</span><span id="FSWEmbedding-1608"><a href="#FSWEmbedding-1608"><span class="linenos">1608</span></a>        <span class="k">return</span> <span class="n">out</span>
</span><span id="FSWEmbedding-1609"><a href="#FSWEmbedding-1609"><span class="linenos">1609</span></a>
</span><span id="FSWEmbedding-1610"><a href="#FSWEmbedding-1610"><span class="linenos">1610</span></a>
</span><span id="FSWEmbedding-1611"><a href="#FSWEmbedding-1611"><span class="linenos">1611</span></a>
</span><span id="FSWEmbedding-1612"><a href="#FSWEmbedding-1612"><span class="linenos">1612</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_get_mutual_coherence</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FSWEmbedding-1613"><a href="#FSWEmbedding-1613"><span class="linenos">1613</span></a>        <span class="n">gram</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1614"><a href="#FSWEmbedding-1614"><span class="linenos">1614</span></a>        <span class="n">inds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span><span class="p">)</span>
</span><span id="FSWEmbedding-1615"><a href="#FSWEmbedding-1615"><span class="linenos">1615</span></a>        <span class="n">gram</span><span class="p">[</span><span class="n">inds</span><span class="p">,</span><span class="n">inds</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="FSWEmbedding-1616"><a href="#FSWEmbedding-1616"><span class="linenos">1616</span></a>
</span><span id="FSWEmbedding-1617"><a href="#FSWEmbedding-1617"><span class="linenos">1617</span></a>        <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">gram</span><span class="p">))</span>
</span><span id="FSWEmbedding-1618"><a href="#FSWEmbedding-1618"><span class="linenos">1618</span></a>        <span class="k">return</span> <span class="n">mu</span>
</span><span id="FSWEmbedding-1619"><a href="#FSWEmbedding-1619"><span class="linenos">1619</span></a>
</span><span id="FSWEmbedding-1620"><a href="#FSWEmbedding-1620"><span class="linenos">1620</span></a>
</span><span id="FSWEmbedding-1621"><a href="#FSWEmbedding-1621"><span class="linenos">1621</span></a>    <span class="nd">@staticmethod</span>
</span><span id="FSWEmbedding-1622"><a href="#FSWEmbedding-1622"><span class="linenos">1622</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_total_mass_homogeneous_legacy_encoding_part1</span><span class="p">(</span><span class="n">totmass</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="FSWEmbedding-1623"><a href="#FSWEmbedding-1623"><span class="linenos">1623</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">totmass</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">totmass</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">-</span><span class="n">totmass</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1624"><a href="#FSWEmbedding-1624"><span class="linenos">1624</span></a>        <span class="k">return</span> <span class="n">out</span>
</span><span id="FSWEmbedding-1625"><a href="#FSWEmbedding-1625"><span class="linenos">1625</span></a>
</span><span id="FSWEmbedding-1626"><a href="#FSWEmbedding-1626"><span class="linenos">1626</span></a>    <span class="nd">@staticmethod</span>
</span><span id="FSWEmbedding-1627"><a href="#FSWEmbedding-1627"><span class="linenos">1627</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">_total_mass_homogeneous_legacy_encoding_part2</span><span class="p">(</span><span class="n">totmass</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
</span><span id="FSWEmbedding-1628"><a href="#FSWEmbedding-1628"><span class="linenos">1628</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">totmass</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">totmass</span><span class="o">.</span><span class="n">square</span><span class="p">(),</span> <span class="mi">2</span><span class="o">*</span><span class="n">totmass</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding-1629"><a href="#FSWEmbedding-1629"><span class="linenos">1629</span></a>        <span class="k">return</span> <span class="n">out</span>
</span></pre></div>


            <div class="docstring"><p>Fourier Sliced-Wasserstein (FSW) embedding module.</p>

<p>Maps input multisets (or, more generally, discrete measures) in
$\mathbb{R}^{d_\text{in}}$ to fixed-length vectors in
$\mathbb{R}^{d_\text{out}}$ via the Fourier Sliced-Wasserstein
embedding as described in [Amir &amp; Dym, ICLR 2025].</p>

<h6 id="features">Features</h6>

<p>‚Ä¢ <strong>Batched inputs</strong>: eupports arbitrary number of batch dimensions.
‚Ä¢ <strong>Graph mode</strong>: efficient message-aggregation, including sparse adjacency support.
‚Ä¢ <strong>Differentiability</strong>: Full autograd/gradient support.</p>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FSWEmbedding.__init__">FSWEmbedding.__init__</a></code>:  Constructor parameters.<br />
<code><a href="#FSWEmbedding.forward">FSWEmbedding.forward</a></code>:  Input/output tensor shapes and options.  </p>
</div>


                            <div id="FSWEmbedding.__init__" class="classattr">
                                        <input id="FSWEmbedding.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">FSWEmbedding</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">d_in</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">	<span class="n">d_out</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">num_slices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">num_frequencies</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">flatten_cartesian_axes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">d_edge</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>,</span><span class="param">	<span class="n">encode_total_mass</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">total_mass_encoding_transformation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n"><a href="#TotalMassEncodingTransformation">TotalMassEncodingTransformation</a></span> <span class="o">=</span> <span class="s1">&#39;identity&#39;</span>,</span><span class="param">	<span class="n">total_mass_encoding_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n"><a href="#TotalMassEncodingMethod">TotalMassEncodingMethod</a></span> <span class="o">=</span> <span class="s1">&#39;decoupled&#39;</span>,</span><span class="param">	<span class="n">total_mass_encoding_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>,</span><span class="param">	<span class="n">total_mass_padding_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="mf">1.0</span>,</span><span class="param">	<span class="n">learnable_slices</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">learnable_frequencies</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">frequency_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n"><a href="#FrequencyInitMethod">FrequencyInitMethod</a></span> <span class="o">=</span> <span class="s1">&#39;random&#39;</span>,</span><span class="param">	<span class="n">minimize_slice_coherence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">enable_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>,</span><span class="param">	<span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">use_custom_cuda_extension_if_available</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">fail_if_cuda_extension_load_fails</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">report</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">report_on_coherence_minimization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span>)</span>

                <label class="view-source-button" for="FSWEmbedding.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.__init__-294"><a href="#FSWEmbedding.__init__-294"><span class="linenos">294</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-295"><a href="#FSWEmbedding.__init__-295"><span class="linenos">295</span></a>                 <span class="n">d_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-296"><a href="#FSWEmbedding.__init__-296"><span class="linenos">296</span></a>                 <span class="n">d_out</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-297"><a href="#FSWEmbedding.__init__-297"><span class="linenos">297</span></a>                 <span class="n">num_slices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-298"><a href="#FSWEmbedding.__init__-298"><span class="linenos">298</span></a>                 <span class="n">num_frequencies</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-299"><a href="#FSWEmbedding.__init__-299"><span class="linenos">299</span></a>                 <span class="n">flatten_cartesian_axes</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-300"><a href="#FSWEmbedding.__init__-300"><span class="linenos">300</span></a>                 <span class="n">d_edge</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-301"><a href="#FSWEmbedding.__init__-301"><span class="linenos">301</span></a>                 <span class="n">encode_total_mass</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-302"><a href="#FSWEmbedding.__init__-302"><span class="linenos">302</span></a>                 <span class="n">total_mass_encoding_transformation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">TotalMassEncodingTransformation</span> <span class="o">=</span> <span class="s1">&#39;identity&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-303"><a href="#FSWEmbedding.__init__-303"><span class="linenos">303</span></a>                 <span class="n">total_mass_encoding_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">TotalMassEncodingMethod</span> <span class="o">=</span> <span class="s1">&#39;decoupled&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-304"><a href="#FSWEmbedding.__init__-304"><span class="linenos">304</span></a>                 <span class="n">total_mass_encoding_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-305"><a href="#FSWEmbedding.__init__-305"><span class="linenos">305</span></a>                 <span class="n">total_mass_padding_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-306"><a href="#FSWEmbedding.__init__-306"><span class="linenos">306</span></a>                 <span class="n">learnable_slices</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-307"><a href="#FSWEmbedding.__init__-307"><span class="linenos">307</span></a>                 <span class="n">learnable_frequencies</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-308"><a href="#FSWEmbedding.__init__-308"><span class="linenos">308</span></a>                 <span class="n">frequency_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">FrequencyInitMethod</span> <span class="o">=</span> <span class="s1">&#39;random&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-309"><a href="#FSWEmbedding.__init__-309"><span class="linenos">309</span></a>                 <span class="n">minimize_slice_coherence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-310"><a href="#FSWEmbedding.__init__-310"><span class="linenos">310</span></a>                 <span class="n">enable_bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-311"><a href="#FSWEmbedding.__init__-311"><span class="linenos">311</span></a>                 <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-312"><a href="#FSWEmbedding.__init__-312"><span class="linenos">312</span></a>                 <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-313"><a href="#FSWEmbedding.__init__-313"><span class="linenos">313</span></a>                 <span class="n">use_custom_cuda_extension_if_available</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-314"><a href="#FSWEmbedding.__init__-314"><span class="linenos">314</span></a>                 <span class="n">fail_if_cuda_extension_load_fails</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-315"><a href="#FSWEmbedding.__init__-315"><span class="linenos">315</span></a>                 <span class="n">report</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.__init__-316"><a href="#FSWEmbedding.__init__-316"><span class="linenos">316</span></a>                 <span class="n">report_on_coherence_minimization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span id="FSWEmbedding.__init__-317"><a href="#FSWEmbedding.__init__-317"><span class="linenos">317</span></a><span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.__init__-318"><a href="#FSWEmbedding.__init__-318"><span class="linenos">318</span></a><span class="sd">        Initialize an FSWEmbedding module.</span>
</span><span id="FSWEmbedding.__init__-319"><a href="#FSWEmbedding.__init__-319"><span class="linenos">319</span></a>
</span><span id="FSWEmbedding.__init__-320"><a href="#FSWEmbedding.__init__-320"><span class="linenos">320</span></a><span class="sd">        Parameters</span>
</span><span id="FSWEmbedding.__init__-321"><a href="#FSWEmbedding.__init__-321"><span class="linenos">321</span></a><span class="sd">        ----------</span>
</span><span id="FSWEmbedding.__init__-322"><a href="#FSWEmbedding.__init__-322"><span class="linenos">322</span></a><span class="sd">        d_in : int</span>
</span><span id="FSWEmbedding.__init__-323"><a href="#FSWEmbedding.__init__-323"><span class="linenos">323</span></a><span class="sd">            The dimension of input multiset elements or, more generally, measure support points.  </span>
</span><span id="FSWEmbedding.__init__-324"><a href="#FSWEmbedding.__init__-324"><span class="linenos">324</span></a><span class="sd">            Coresponds to $d$ in $\mathcal{S}_{\leq N}\left(\mathbb{R}^d\right)$, $\mathcal{P}_{\leq N}\left(\mathbb{R}^d\right)$, or $\mathcal{M}_{\leq N}\left(\mathbb{R}^d\right)$ in our paper. </span>
</span><span id="FSWEmbedding.__init__-325"><a href="#FSWEmbedding.__init__-325"><span class="linenos">325</span></a><span class="sd">        d_out : int; optional</span>
</span><span id="FSWEmbedding.__init__-326"><a href="#FSWEmbedding.__init__-326"><span class="linenos">326</span></a><span class="sd">            Desired embedding dimension.  </span>
</span><span id="FSWEmbedding.__init__-327"><a href="#FSWEmbedding.__init__-327"><span class="linenos">327</span></a><span class="sd">            If not set, both `num_slices` and `num_frequencies` must be explicitly provided.</span>
</span><span id="FSWEmbedding.__init__-328"><a href="#FSWEmbedding.__init__-328"><span class="linenos">328</span></a><span class="sd">        num_slices : int; optional</span>
</span><span id="FSWEmbedding.__init__-329"><a href="#FSWEmbedding.__init__-329"><span class="linenos">329</span></a><span class="sd">            Number of slices.  </span>
</span><span id="FSWEmbedding.__init__-330"><a href="#FSWEmbedding.__init__-330"><span class="linenos">330</span></a><span class="sd">            When provided, activates `cartesian_mode`, and `d_out` should be left None.  </span>
</span><span id="FSWEmbedding.__init__-331"><a href="#FSWEmbedding.__init__-331"><span class="linenos">331</span></a><span class="sd">            See also: `flatten_cartesian_axes`</span>
</span><span id="FSWEmbedding.__init__-332"><a href="#FSWEmbedding.__init__-332"><span class="linenos">332</span></a><span class="sd">        num_frequencies : int; optional</span>
</span><span id="FSWEmbedding.__init__-333"><a href="#FSWEmbedding.__init__-333"><span class="linenos">333</span></a><span class="sd">            Number of frequencies per slice.  </span>
</span><span id="FSWEmbedding.__init__-334"><a href="#FSWEmbedding.__init__-334"><span class="linenos">334</span></a><span class="sd">            When provided, activates `cartesian_mode`, and `d_out` should be left None.  </span>
</span><span id="FSWEmbedding.__init__-335"><a href="#FSWEmbedding.__init__-335"><span class="linenos">335</span></a><span class="sd">            See also: `flatten_cartesian_axes`</span>
</span><span id="FSWEmbedding.__init__-336"><a href="#FSWEmbedding.__init__-336"><span class="linenos">336</span></a><span class="sd">        flatten_cartesian_axes : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-337"><a href="#FSWEmbedding.__init__-337"><span class="linenos">337</span></a><span class="sd">            If True, flattens the slice and frequency dimensions into a single output axis.  </span>
</span><span id="FSWEmbedding.__init__-338"><a href="#FSWEmbedding.__init__-338"><span class="linenos">338</span></a><span class="sd">            Only relevant if `num_slices` and `num_frequencies` are provided.</span>
</span><span id="FSWEmbedding.__init__-339"><a href="#FSWEmbedding.__init__-339"><span class="linenos">339</span></a><span class="sd">        d_edge : int; default=0</span>
</span><span id="FSWEmbedding.__init__-340"><a href="#FSWEmbedding.__init__-340"><span class="linenos">340</span></a><span class="sd">            Dimension of edge feature vectors. Used only for graph inputs.  </span>
</span><span id="FSWEmbedding.__init__-341"><a href="#FSWEmbedding.__init__-341"><span class="linenos">341</span></a><span class="sd">            See the `graph_mode` argument of `FSWEmbedding.forward` for details.</span>
</span><span id="FSWEmbedding.__init__-342"><a href="#FSWEmbedding.__init__-342"><span class="linenos">342</span></a><span class="sd">        encode_total_mass : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-343"><a href="#FSWEmbedding.__init__-343"><span class="linenos">343</span></a><span class="sd">            Whether to incorporate the input multiset size (or, more generally, the *total mass* of the input measure)</span>
</span><span id="FSWEmbedding.__init__-344"><a href="#FSWEmbedding.__init__-344"><span class="linenos">344</span></a><span class="sd">            into the embedding output.</span>
</span><span id="FSWEmbedding.__init__-345"><a href="#FSWEmbedding.__init__-345"><span class="linenos">345</span></a><span class="sd">        total_mass_encoding_transformation : {&#39;identity&#39;, &#39;sqrt&#39;, &#39;log&#39;} or TotalMassEncodingFunction; default=&#39;identity&#39;</span>
</span><span id="FSWEmbedding.__init__-346"><a href="#FSWEmbedding.__init__-346"><span class="linenos">346</span></a><span class="sd">            Transformation applied to the total mass *before* embedding.  </span>
</span><span id="FSWEmbedding.__init__-347"><a href="#FSWEmbedding.__init__-347"><span class="linenos">347</span></a><span class="sd">            See also: `TotalMassEncodingFunction`</span>
</span><span id="FSWEmbedding.__init__-348"><a href="#FSWEmbedding.__init__-348"><span class="linenos">348</span></a><span class="sd">        total_mass_encoding_method : {&#39;decoupled&#39;, &#39;scaled&#39;, &#39;homogeneous&#39;, &#39;homogeneous_scaled&#39;, &#39;homogeneous_legacy&#39;} or TotalMassEncodingMethod; default=&#39;decoupled&#39;</span>
</span><span id="FSWEmbedding.__init__-349"><a href="#FSWEmbedding.__init__-349"><span class="linenos">349</span></a><span class="sd">            Strategy for combining the total mass with the core embedding.  </span>
</span><span id="FSWEmbedding.__init__-350"><a href="#FSWEmbedding.__init__-350"><span class="linenos">350</span></a><span class="sd">            See also: `TotalMassEncodingMethod`</span>
</span><span id="FSWEmbedding.__init__-351"><a href="#FSWEmbedding.__init__-351"><span class="linenos">351</span></a><span class="sd">        total_mass_encoding_scale : float; default=1.0</span>
</span><span id="FSWEmbedding.__init__-352"><a href="#FSWEmbedding.__init__-352"><span class="linenos">352</span></a><span class="sd">            The encoded total mass is multiplied by this scaling factor.  </span>
</span><span id="FSWEmbedding.__init__-353"><a href="#FSWEmbedding.__init__-353"><span class="linenos">353</span></a><span class="sd">            See also: `TotalMassEncodingMethod`</span>
</span><span id="FSWEmbedding.__init__-354"><a href="#FSWEmbedding.__init__-354"><span class="linenos">354</span></a><span class="sd">        total_mass_padding_thresh : float or int; default=1.0</span>
</span><span id="FSWEmbedding.__init__-355"><a href="#FSWEmbedding.__init__-355"><span class="linenos">355</span></a><span class="sd">            Inputs with total mass below this threshold are padded with the zero vector to reach it; see</span>
</span><span id="FSWEmbedding.__init__-356"><a href="#FSWEmbedding.__init__-356"><span class="linenos">356</span></a><span class="sd">            in [Amir and Dym, ICLR 2025], Appendix A.1.  </span>
</span><span id="FSWEmbedding.__init__-357"><a href="#FSWEmbedding.__init__-357"><span class="linenos">357</span></a><span class="sd">            See also: `TotalMassEncodingMethod`</span>
</span><span id="FSWEmbedding.__init__-358"><a href="#FSWEmbedding.__init__-358"><span class="linenos">358</span></a><span class="sd">        learnable_slices : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-359"><a href="#FSWEmbedding.__init__-359"><span class="linenos">359</span></a><span class="sd">            If True, slice vectors are learnable parameters.  </span>
</span><span id="FSWEmbedding.__init__-360"><a href="#FSWEmbedding.__init__-360"><span class="linenos">360</span></a><span class="sd">        learnable_frequencies : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-361"><a href="#FSWEmbedding.__init__-361"><span class="linenos">361</span></a><span class="sd">            If True, frequency values are learnable parameters.</span>
</span><span id="FSWEmbedding.__init__-362"><a href="#FSWEmbedding.__init__-362"><span class="linenos">362</span></a><span class="sd">        frequency_init : float, str, tuple of float, or FrequencyInitMethod; default=&#39;random&#39;</span>
</span><span id="FSWEmbedding.__init__-363"><a href="#FSWEmbedding.__init__-363"><span class="linenos">363</span></a><span class="sd">            Initialization scheme for frequencies:</span>
</span><span id="FSWEmbedding.__init__-364"><a href="#FSWEmbedding.__init__-364"><span class="linenos">364</span></a><span class="sd">              - A float: sets all frequencies to the same value.</span>
</span><span id="FSWEmbedding.__init__-365"><a href="#FSWEmbedding.__init__-365"><span class="linenos">365</span></a><span class="sd">              - A tuple `(low, high)` of floats: sets evenly spaced values in that interval.</span>
</span><span id="FSWEmbedding.__init__-366"><a href="#FSWEmbedding.__init__-366"><span class="linenos">366</span></a><span class="sd">              - &#39;random&#39;: frequencies are drawn independently from the distribution $\mathcal{D_{\xi}}$, defined in</span>
</span><span id="FSWEmbedding.__init__-367"><a href="#FSWEmbedding.__init__-367"><span class="linenos">367</span></a><span class="sd">                          [Amir and Dym, ICLR 2025], Section 3.</span>
</span><span id="FSWEmbedding.__init__-368"><a href="#FSWEmbedding.__init__-368"><span class="linenos">368</span></a><span class="sd">              - &#39;even&#39;: frequencies are spaced evenly according to their distribution $\mathcal{D_{\xi}}$, with spaces</span>
</span><span id="FSWEmbedding.__init__-369"><a href="#FSWEmbedding.__init__-369"><span class="linenos">369</span></a><span class="sd">                        inversely proportional to the density.  </span>
</span><span id="FSWEmbedding.__init__-370"><a href="#FSWEmbedding.__init__-370"><span class="linenos">370</span></a><span class="sd">            See also: `FrequencyInitMethod`</span>
</span><span id="FSWEmbedding.__init__-371"><a href="#FSWEmbedding.__init__-371"><span class="linenos">371</span></a><span class="sd">        minimize_slice_coherence : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-372"><a href="#FSWEmbedding.__init__-372"><span class="linenos">372</span></a><span class="sd">            If True, minimizes the *mutual coherence* between slices for a more uniform spread on the unit sphere.  </span>
</span><span id="FSWEmbedding.__init__-373"><a href="#FSWEmbedding.__init__-373"><span class="linenos">373</span></a><span class="sd">            If False, slice vectors are drawn uniformly at random from the unit sphere.</span>
</span><span id="FSWEmbedding.__init__-374"><a href="#FSWEmbedding.__init__-374"><span class="linenos">374</span></a><span class="sd">        enable_bias : bool; default=True</span>
</span><span id="FSWEmbedding.__init__-375"><a href="#FSWEmbedding.__init__-375"><span class="linenos">375</span></a><span class="sd">            If True, adds a learnable bias vector to the output embedding. When enabled, the bias is initialized</span>
</span><span id="FSWEmbedding.__init__-376"><a href="#FSWEmbedding.__init__-376"><span class="linenos">376</span></a><span class="sd">            to zero.  </span>
</span><span id="FSWEmbedding.__init__-377"><a href="#FSWEmbedding.__init__-377"><span class="linenos">377</span></a><span class="sd">        device : torch.device, int, str, or None, optional</span>
</span><span id="FSWEmbedding.__init__-378"><a href="#FSWEmbedding.__init__-378"><span class="linenos">378</span></a><span class="sd">            The torch device on which to allocate tensors (e.g., &#39;cpu&#39;, &#39;cuda&#39;, or an index).  </span>
</span><span id="FSWEmbedding.__init__-379"><a href="#FSWEmbedding.__init__-379"><span class="linenos">379</span></a><span class="sd">            If not provided, the default device defined in Torch is used.</span>
</span><span id="FSWEmbedding.__init__-380"><a href="#FSWEmbedding.__init__-380"><span class="linenos">380</span></a><span class="sd">        dtype : torch.dtype, optional</span>
</span><span id="FSWEmbedding.__init__-381"><a href="#FSWEmbedding.__init__-381"><span class="linenos">381</span></a><span class="sd">            Data type of input and output tensors (e.g., torch.float32).</span>
</span><span id="FSWEmbedding.__init__-382"><a href="#FSWEmbedding.__init__-382"><span class="linenos">382</span></a><span class="sd">            If not provided, the default dtype defined in Torch is used.</span>
</span><span id="FSWEmbedding.__init__-383"><a href="#FSWEmbedding.__init__-383"><span class="linenos">383</span></a><span class="sd">        use_custom_cuda_extension_if_available : bool or None, optional</span>
</span><span id="FSWEmbedding.__init__-384"><a href="#FSWEmbedding.__init__-384"><span class="linenos">384</span></a><span class="sd">            Whether to use the custom CUDA kernel if present.</span>
</span><span id="FSWEmbedding.__init__-385"><a href="#FSWEmbedding.__init__-385"><span class="linenos">385</span></a><span class="sd">            Default: Linux: True, all other systems: False</span>
</span><span id="FSWEmbedding.__init__-386"><a href="#FSWEmbedding.__init__-386"><span class="linenos">386</span></a><span class="sd">        fail_if_cuda_extension_load_fails : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-387"><a href="#FSWEmbedding.__init__-387"><span class="linenos">387</span></a><span class="sd">            Whether to raise a runtime error (rather than a warning) if the CUDA extension failes to load.</span>
</span><span id="FSWEmbedding.__init__-388"><a href="#FSWEmbedding.__init__-388"><span class="linenos">388</span></a><span class="sd">        report : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-389"><a href="#FSWEmbedding.__init__-389"><span class="linenos">389</span></a><span class="sd">            If True, prints a report with diagnostic information during initialization and forward computation.</span>
</span><span id="FSWEmbedding.__init__-390"><a href="#FSWEmbedding.__init__-390"><span class="linenos">390</span></a><span class="sd">        report_on_coherence_minimization : bool; default=False</span>
</span><span id="FSWEmbedding.__init__-391"><a href="#FSWEmbedding.__init__-391"><span class="linenos">391</span></a><span class="sd">            If True, prints special diagnostics during slice coherence minimization.</span>
</span><span id="FSWEmbedding.__init__-392"><a href="#FSWEmbedding.__init__-392"><span class="linenos">392</span></a>
</span><span id="FSWEmbedding.__init__-393"><a href="#FSWEmbedding.__init__-393"><span class="linenos">393</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding.__init__-394"><a href="#FSWEmbedding.__init__-394"><span class="linenos">394</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding.__init__-395"><a href="#FSWEmbedding.__init__-395"><span class="linenos">395</span></a><span class="sd">        If Cartesian mode is activated and `encode_total_mass` is True, `flatten_cartesian_axes` must be True.</span>
</span><span id="FSWEmbedding.__init__-396"><a href="#FSWEmbedding.__init__-396"><span class="linenos">396</span></a>
</span><span id="FSWEmbedding.__init__-397"><a href="#FSWEmbedding.__init__-397"><span class="linenos">397</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding.__init__-398"><a href="#FSWEmbedding.__init__-398"><span class="linenos">398</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding.__init__-399"><a href="#FSWEmbedding.__init__-399"><span class="linenos">399</span></a><span class="sd">        FrequencyInitMethod :</span>
</span><span id="FSWEmbedding.__init__-400"><a href="#FSWEmbedding.__init__-400"><span class="linenos">400</span></a><span class="sd">            Enum for selecting frequency initialization strategies.</span>
</span><span id="FSWEmbedding.__init__-401"><a href="#FSWEmbedding.__init__-401"><span class="linenos">401</span></a><span class="sd">        TotalMassEncodingTransformation :</span>
</span><span id="FSWEmbedding.__init__-402"><a href="#FSWEmbedding.__init__-402"><span class="linenos">402</span></a><span class="sd">            Enum for total mass transformations.</span>
</span><span id="FSWEmbedding.__init__-403"><a href="#FSWEmbedding.__init__-403"><span class="linenos">403</span></a><span class="sd">        TotalMassEncodingMethod :</span>
</span><span id="FSWEmbedding.__init__-404"><a href="#FSWEmbedding.__init__-404"><span class="linenos">404</span></a><span class="sd">            Enum for strategies to incorporate total mass into the embedding.</span>
</span><span id="FSWEmbedding.__init__-405"><a href="#FSWEmbedding.__init__-405"><span class="linenos">405</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.__init__-406"><a href="#FSWEmbedding.__init__-406"><span class="linenos">406</span></a>
</span><span id="FSWEmbedding.__init__-407"><a href="#FSWEmbedding.__init__-407"><span class="linenos">407</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="FSWEmbedding.__init__-408"><a href="#FSWEmbedding.__init__-408"><span class="linenos">408</span></a>
</span><span id="FSWEmbedding.__init__-409"><a href="#FSWEmbedding.__init__-409"><span class="linenos">409</span></a>        <span class="c1"># Process sizes</span>
</span><span id="FSWEmbedding.__init__-410"><a href="#FSWEmbedding.__init__-410"><span class="linenos">410</span></a>        <span class="k">assert</span> <span class="n">d_in</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;d_in must be nonnegative&#39;</span>
</span><span id="FSWEmbedding.__init__-411"><a href="#FSWEmbedding.__init__-411"><span class="linenos">411</span></a>        <span class="k">assert</span> <span class="n">d_edge</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;d_edge must be nonnegative&#39;</span>
</span><span id="FSWEmbedding.__init__-412"><a href="#FSWEmbedding.__init__-412"><span class="linenos">412</span></a>        <span class="k">assert</span> <span class="p">(</span><span class="n">d_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">d_out</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;d_out must be nonnegative or None&#39;</span>
</span><span id="FSWEmbedding.__init__-413"><a href="#FSWEmbedding.__init__-413"><span class="linenos">413</span></a>
</span><span id="FSWEmbedding.__init__-414"><a href="#FSWEmbedding.__init__-414"><span class="linenos">414</span></a>        <span class="k">if</span> <span class="n">d_out</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-415"><a href="#FSWEmbedding.__init__-415"><span class="linenos">415</span></a>            <span class="c1"># If the output should be empty, we force encode_total_mass to be False</span>
</span><span id="FSWEmbedding.__init__-416"><a href="#FSWEmbedding.__init__-416"><span class="linenos">416</span></a>            <span class="n">encode_total_mass</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="FSWEmbedding.__init__-417"><a href="#FSWEmbedding.__init__-417"><span class="linenos">417</span></a>
</span><span id="FSWEmbedding.__init__-418"><a href="#FSWEmbedding.__init__-418"><span class="linenos">418</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">d_in</span>
</span><span id="FSWEmbedding.__init__-419"><a href="#FSWEmbedding.__init__-419"><span class="linenos">419</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">d_edge</span>
</span><span id="FSWEmbedding.__init__-420"><a href="#FSWEmbedding.__init__-420"><span class="linenos">420</span></a>
</span><span id="FSWEmbedding.__init__-421"><a href="#FSWEmbedding.__init__-421"><span class="linenos">421</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">encode_total_mass</span>
</span><span id="FSWEmbedding.__init__-422"><a href="#FSWEmbedding.__init__-422"><span class="linenos">422</span></a>
</span><span id="FSWEmbedding.__init__-423"><a href="#FSWEmbedding.__init__-423"><span class="linenos">423</span></a>        <span class="n">total_mass_padding_thresh</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_mass_padding_thresh</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-424"><a href="#FSWEmbedding.__init__-424"><span class="linenos">424</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">total_mass_padding_thresh</span><span class="p">),</span> <span class="s1">&#39;total_mass_padding_thresh cannot be inf&#39;</span>
</span><span id="FSWEmbedding.__init__-425"><a href="#FSWEmbedding.__init__-425"><span class="linenos">425</span></a>        <span class="k">assert</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">total_mass_padding_thresh</span><span class="p">),</span> <span class="s1">&#39;total_mass_padding_thresh cannot be NaN&#39;</span>
</span><span id="FSWEmbedding.__init__-426"><a href="#FSWEmbedding.__init__-426"><span class="linenos">426</span></a>        <span class="k">assert</span> <span class="n">total_mass_padding_thresh</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;total_mass_padding_thresh must be positive&#39;</span>
</span><span id="FSWEmbedding.__init__-427"><a href="#FSWEmbedding.__init__-427"><span class="linenos">427</span></a>
</span><span id="FSWEmbedding.__init__-428"><a href="#FSWEmbedding.__init__-428"><span class="linenos">428</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">total_mass_padding_thresh</span>
</span><span id="FSWEmbedding.__init__-429"><a href="#FSWEmbedding.__init__-429"><span class="linenos">429</span></a>        <span class="k">del</span> <span class="n">total_mass_padding_thresh</span>
</span><span id="FSWEmbedding.__init__-430"><a href="#FSWEmbedding.__init__-430"><span class="linenos">430</span></a>
</span><span id="FSWEmbedding.__init__-431"><a href="#FSWEmbedding.__init__-431"><span class="linenos">431</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span> <span class="o">=</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">resolve</span><span class="p">(</span><span class="n">total_mass_encoding_method</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-432"><a href="#FSWEmbedding.__init__-432"><span class="linenos">432</span></a>        <span class="k">del</span> <span class="n">total_mass_encoding_method</span>
</span><span id="FSWEmbedding.__init__-433"><a href="#FSWEmbedding.__init__-433"><span class="linenos">433</span></a>
</span><span id="FSWEmbedding.__init__-434"><a href="#FSWEmbedding.__init__-434"><span class="linenos">434</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_scale</span> <span class="o">=</span> <span class="n">total_mass_encoding_scale</span>
</span><span id="FSWEmbedding.__init__-435"><a href="#FSWEmbedding.__init__-435"><span class="linenos">435</span></a>        <span class="k">del</span> <span class="n">total_mass_encoding_scale</span>
</span><span id="FSWEmbedding.__init__-436"><a href="#FSWEmbedding.__init__-436"><span class="linenos">436</span></a>
</span><span id="FSWEmbedding.__init__-437"><a href="#FSWEmbedding.__init__-437"><span class="linenos">437</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span> <span class="o">=</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">resolve</span><span class="p">(</span><span class="n">total_mass_encoding_transformation</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-438"><a href="#FSWEmbedding.__init__-438"><span class="linenos">438</span></a>        <span class="k">del</span> <span class="n">total_mass_encoding_transformation</span>
</span><span id="FSWEmbedding.__init__-439"><a href="#FSWEmbedding.__init__-439"><span class="linenos">439</span></a>
</span><span id="FSWEmbedding.__init__-440"><a href="#FSWEmbedding.__init__-440"><span class="linenos">440</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-441"><a href="#FSWEmbedding.__init__-441"><span class="linenos">441</span></a>            <span class="n">input_space_name</span> <span class="o">=</span> <span class="s1">&#39;R^</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span>
</span><span id="FSWEmbedding.__init__-442"><a href="#FSWEmbedding.__init__-442"><span class="linenos">442</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-443"><a href="#FSWEmbedding.__init__-443"><span class="linenos">443</span></a>            <span class="n">input_space_name</span> <span class="o">=</span> <span class="s1">&#39;R^(</span><span class="si">%d</span><span class="s1">+</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-444"><a href="#FSWEmbedding.__init__-444"><span class="linenos">444</span></a>
</span><span id="FSWEmbedding.__init__-445"><a href="#FSWEmbedding.__init__-445"><span class="linenos">445</span></a>        <span class="n">total_mass_encoding_dim</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span> <span class="k">else</span> <span class="mi">0</span>
</span><span id="FSWEmbedding.__init__-446"><a href="#FSWEmbedding.__init__-446"><span class="linenos">446</span></a>
</span><span id="FSWEmbedding.__init__-447"><a href="#FSWEmbedding.__init__-447"><span class="linenos">447</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">d_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_slices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_frequencies</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding.__init__-448"><a href="#FSWEmbedding.__init__-448"><span class="linenos">448</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FSWEmbedding.__init__-449"><a href="#FSWEmbedding.__init__-449"><span class="linenos">449</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>  <span class="o">=</span> <span class="kc">False</span>
</span><span id="FSWEmbedding.__init__-450"><a href="#FSWEmbedding.__init__-450"><span class="linenos">450</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">=</span> <span class="n">d_out</span>
</span><span id="FSWEmbedding.__init__-451"><a href="#FSWEmbedding.__init__-451"><span class="linenos">451</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">=</span> <span class="n">d_out</span> <span class="o">-</span> <span class="n">total_mass_encoding_dim</span>
</span><span id="FSWEmbedding.__init__-452"><a href="#FSWEmbedding.__init__-452"><span class="linenos">452</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span> <span class="o">=</span> <span class="n">d_out</span> <span class="o">-</span> <span class="n">total_mass_encoding_dim</span>
</span><span id="FSWEmbedding.__init__-453"><a href="#FSWEmbedding.__init__-453"><span class="linenos">453</span></a>            <span class="n">output_space_name</span> <span class="o">=</span> <span class="s1">&#39;R^</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span>
</span><span id="FSWEmbedding.__init__-454"><a href="#FSWEmbedding.__init__-454"><span class="linenos">454</span></a>
</span><span id="FSWEmbedding.__init__-455"><a href="#FSWEmbedding.__init__-455"><span class="linenos">455</span></a>        <span class="k">elif</span> <span class="p">(</span><span class="n">d_out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_slices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">num_frequencies</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding.__init__-456"><a href="#FSWEmbedding.__init__-456"><span class="linenos">456</span></a>            <span class="k">assert</span> <span class="n">flatten_cartesian_axes</span>  <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">encode_total_mass</span><span class="p">),</span> <span class="s1">&#39;Cartesian mode with flatten_cartesian_axes =False is not supported when encode_total_mass=True&#39;</span>
</span><span id="FSWEmbedding.__init__-457"><a href="#FSWEmbedding.__init__-457"><span class="linenos">457</span></a>
</span><span id="FSWEmbedding.__init__-458"><a href="#FSWEmbedding.__init__-458"><span class="linenos">458</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="FSWEmbedding.__init__-459"><a href="#FSWEmbedding.__init__-459"><span class="linenos">459</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>  <span class="o">=</span> <span class="n">flatten_cartesian_axes</span>
</span><span id="FSWEmbedding.__init__-460"><a href="#FSWEmbedding.__init__-460"><span class="linenos">460</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">=</span> <span class="n">num_slices</span>
</span><span id="FSWEmbedding.__init__-461"><a href="#FSWEmbedding.__init__-461"><span class="linenos">461</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span> <span class="o">=</span> <span class="n">num_frequencies</span>
</span><span id="FSWEmbedding.__init__-462"><a href="#FSWEmbedding.__init__-462"><span class="linenos">462</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">=</span> <span class="n">num_slices</span> <span class="o">*</span> <span class="n">num_frequencies</span> <span class="o">+</span> <span class="n">total_mass_encoding_dim</span>
</span><span id="FSWEmbedding.__init__-463"><a href="#FSWEmbedding.__init__-463"><span class="linenos">463</span></a>            <span class="n">output_space_name</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;R^</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>  <span class="k">else</span> <span class="p">(</span><span class="s1">&#39;R^(</span><span class="si">%d</span><span class="se">\u00d7</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">))</span>
</span><span id="FSWEmbedding.__init__-464"><a href="#FSWEmbedding.__init__-464"><span class="linenos">464</span></a>
</span><span id="FSWEmbedding.__init__-465"><a href="#FSWEmbedding.__init__-465"><span class="linenos">465</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-466"><a href="#FSWEmbedding.__init__-466"><span class="linenos">466</span></a>            <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;Expected exactly one of (d_out != None) or (num_slices != None and num_frequencies != None)&quot;</span>
</span><span id="FSWEmbedding.__init__-467"><a href="#FSWEmbedding.__init__-467"><span class="linenos">467</span></a>
</span><span id="FSWEmbedding.__init__-468"><a href="#FSWEmbedding.__init__-468"><span class="linenos">468</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;d_out must be nonnegative&#39;</span>
</span><span id="FSWEmbedding.__init__-469"><a href="#FSWEmbedding.__init__-469"><span class="linenos">469</span></a>
</span><span id="FSWEmbedding.__init__-470"><a href="#FSWEmbedding.__init__-470"><span class="linenos">470</span></a>        <span class="c1">#d_out = self.d_out</span>
</span><span id="FSWEmbedding.__init__-471"><a href="#FSWEmbedding.__init__-471"><span class="linenos">471</span></a>        <span class="n">num_slices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span>
</span><span id="FSWEmbedding.__init__-472"><a href="#FSWEmbedding.__init__-472"><span class="linenos">472</span></a>        <span class="n">num_frequencies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span>
</span><span id="FSWEmbedding.__init__-473"><a href="#FSWEmbedding.__init__-473"><span class="linenos">473</span></a>
</span><span id="FSWEmbedding.__init__-474"><a href="#FSWEmbedding.__init__-474"><span class="linenos">474</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span> <span class="o">=</span> <span class="n">minimize_slice_coherence</span>
</span><span id="FSWEmbedding.__init__-475"><a href="#FSWEmbedding.__init__-475"><span class="linenos">475</span></a>
</span><span id="FSWEmbedding.__init__-476"><a href="#FSWEmbedding.__init__-476"><span class="linenos">476</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span> <span class="o">=</span> <span class="n">learnable_slices</span>
</span><span id="FSWEmbedding.__init__-477"><a href="#FSWEmbedding.__init__-477"><span class="linenos">477</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span> <span class="o">=</span> <span class="n">learnable_frequencies</span>
</span><span id="FSWEmbedding.__init__-478"><a href="#FSWEmbedding.__init__-478"><span class="linenos">478</span></a>
</span><span id="FSWEmbedding.__init__-479"><a href="#FSWEmbedding.__init__-479"><span class="linenos">479</span></a>        <span class="c1"># Note: frequency_init is checked for correctness downstream at generate_embedding_parameters()</span>
</span><span id="FSWEmbedding.__init__-480"><a href="#FSWEmbedding.__init__-480"><span class="linenos">480</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span> <span class="o">=</span> <span class="n">frequency_init</span>
</span><span id="FSWEmbedding.__init__-481"><a href="#FSWEmbedding.__init__-481"><span class="linenos">481</span></a>
</span><span id="FSWEmbedding.__init__-482"><a href="#FSWEmbedding.__init__-482"><span class="linenos">482</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span> <span class="o">=</span> <span class="n">enable_bias</span>
</span><span id="FSWEmbedding.__init__-483"><a href="#FSWEmbedding.__init__-483"><span class="linenos">483</span></a>
</span><span id="FSWEmbedding.__init__-484"><a href="#FSWEmbedding.__init__-484"><span class="linenos">484</span></a>        <span class="c1"># _device_new and _dtype_new are only defined here on __init__ and passed on to reset_parameters(), which then deletes them</span>
</span><span id="FSWEmbedding.__init__-485"><a href="#FSWEmbedding.__init__-485"><span class="linenos">485</span></a>        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-486"><a href="#FSWEmbedding.__init__-486"><span class="linenos">486</span></a>            <span class="c1"># Use get_default_device if available (PyTorch 2.3+)</span>
</span><span id="FSWEmbedding.__init__-487"><a href="#FSWEmbedding.__init__-487"><span class="linenos">487</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;get_default_device&quot;</span><span class="p">):</span>
</span><span id="FSWEmbedding.__init__-488"><a href="#FSWEmbedding.__init__-488"><span class="linenos">488</span></a>                <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_device</span><span class="p">()</span>
</span><span id="FSWEmbedding.__init__-489"><a href="#FSWEmbedding.__init__-489"><span class="linenos">489</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-490"><a href="#FSWEmbedding.__init__-490"><span class="linenos">490</span></a>                <span class="c1"># Fallback: infer from a dummy tensor</span>
</span><span id="FSWEmbedding.__init__-491"><a href="#FSWEmbedding.__init__-491"><span class="linenos">491</span></a>                <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span><span class="o">.</span><span class="n">device</span>
</span><span id="FSWEmbedding.__init__-492"><a href="#FSWEmbedding.__init__-492"><span class="linenos">492</span></a>
</span><span id="FSWEmbedding.__init__-493"><a href="#FSWEmbedding.__init__-493"><span class="linenos">493</span></a>        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-494"><a href="#FSWEmbedding.__init__-494"><span class="linenos">494</span></a>            <span class="c1"># Use get_default_dtype if available</span>
</span><span id="FSWEmbedding.__init__-495"><a href="#FSWEmbedding.__init__-495"><span class="linenos">495</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s2">&quot;get_default_dtype&quot;</span><span class="p">):</span>
</span><span id="FSWEmbedding.__init__-496"><a href="#FSWEmbedding.__init__-496"><span class="linenos">496</span></a>                <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span>
</span><span id="FSWEmbedding.__init__-497"><a href="#FSWEmbedding.__init__-497"><span class="linenos">497</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-498"><a href="#FSWEmbedding.__init__-498"><span class="linenos">498</span></a>                <span class="c1"># Fallback: infer from a dummy tensor</span>
</span><span id="FSWEmbedding.__init__-499"><a href="#FSWEmbedding.__init__-499"><span class="linenos">499</span></a>                <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([])</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="FSWEmbedding.__init__-500"><a href="#FSWEmbedding.__init__-500"><span class="linenos">500</span></a>
</span><span id="FSWEmbedding.__init__-501"><a href="#FSWEmbedding.__init__-501"><span class="linenos">501</span></a>        <span class="k">assert</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_floating_point</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_complex</span><span class="p">),</span> <span class="s1">&#39;dtype must be real floating-point; instead got dtype=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">dtype</span>
</span><span id="FSWEmbedding.__init__-502"><a href="#FSWEmbedding.__init__-502"><span class="linenos">502</span></a>
</span><span id="FSWEmbedding.__init__-503"><a href="#FSWEmbedding.__init__-503"><span class="linenos">503</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_device_new</span> <span class="o">=</span> <span class="n">device</span>
</span><span id="FSWEmbedding.__init__-504"><a href="#FSWEmbedding.__init__-504"><span class="linenos">504</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_new</span> <span class="o">=</span> <span class="n">dtype</span>
</span><span id="FSWEmbedding.__init__-505"><a href="#FSWEmbedding.__init__-505"><span class="linenos">505</span></a>
</span><span id="FSWEmbedding.__init__-506"><a href="#FSWEmbedding.__init__-506"><span class="linenos">506</span></a>        <span class="k">if</span> <span class="n">use_custom_cuda_extension_if_available</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-507"><a href="#FSWEmbedding.__init__-507"><span class="linenos">507</span></a>            <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;Windows&#39;</span><span class="p">,</span> <span class="s1">&#39;Darwin&#39;</span><span class="p">}:</span>
</span><span id="FSWEmbedding.__init__-508"><a href="#FSWEmbedding.__init__-508"><span class="linenos">508</span></a>                <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FSWEmbedding.__init__-509"><a href="#FSWEmbedding.__init__-509"><span class="linenos">509</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-510"><a href="#FSWEmbedding.__init__-510"><span class="linenos">510</span></a>                <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="FSWEmbedding.__init__-511"><a href="#FSWEmbedding.__init__-511"><span class="linenos">511</span></a>
</span><span id="FSWEmbedding.__init__-512"><a href="#FSWEmbedding.__init__-512"><span class="linenos">512</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="n">use_custom_cuda_extension_if_available</span>
</span><span id="FSWEmbedding.__init__-513"><a href="#FSWEmbedding.__init__-513"><span class="linenos">513</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span> <span class="o">=</span> <span class="n">fail_if_cuda_extension_load_fails</span>
</span><span id="FSWEmbedding.__init__-514"><a href="#FSWEmbedding.__init__-514"><span class="linenos">514</span></a>
</span><span id="FSWEmbedding.__init__-515"><a href="#FSWEmbedding.__init__-515"><span class="linenos">515</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">report</span>
</span><span id="FSWEmbedding.__init__-516"><a href="#FSWEmbedding.__init__-516"><span class="linenos">516</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span> <span class="o">=</span> <span class="n">report_on_coherence_minimization</span>
</span><span id="FSWEmbedding.__init__-517"><a href="#FSWEmbedding.__init__-517"><span class="linenos">517</span></a>
</span><span id="FSWEmbedding.__init__-518"><a href="#FSWEmbedding.__init__-518"><span class="linenos">518</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-519"><a href="#FSWEmbedding.__init__-519"><span class="linenos">519</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;Fourier Sliced-Wasserstein Embedding&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-520"><a href="#FSWEmbedding.__init__-520"><span class="linenos">520</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;version </span><span class="si">%s</span><span class="s1">, </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">version</span><span class="p">,</span> <span class="n">version_date</span><span class="p">))</span>
</span><span id="FSWEmbedding.__init__-521"><a href="#FSWEmbedding.__init__-521"><span class="linenos">521</span></a>
</span><span id="FSWEmbedding.__init__-522"><a href="#FSWEmbedding.__init__-522"><span class="linenos">522</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-523"><a href="#FSWEmbedding.__init__-523"><span class="linenos">523</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;Based on our paper titled &quot;Fourier Sliced-Wasserstrin Embedding for Multisets and Measures&quot;, ICLR 2025&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-524"><a href="#FSWEmbedding.__init__-524"><span class="linenos">524</span></a>
</span><span id="FSWEmbedding.__init__-525"><a href="#FSWEmbedding.__init__-525"><span class="linenos">525</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-526"><a href="#FSWEmbedding.__init__-526"><span class="linenos">526</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;Constructing embedding for sets in </span><span class="si">%s</span><span class="s1"> into </span><span class="si">%s</span><span class="s1">  &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">input_space_name</span><span class="p">,</span> <span class="n">output_space_name</span><span class="p">))</span>
</span><span id="FSWEmbedding.__init__-527"><a href="#FSWEmbedding.__init__-527"><span class="linenos">527</span></a>
</span><span id="FSWEmbedding.__init__-528"><a href="#FSWEmbedding.__init__-528"><span class="linenos">528</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding.__init__-529"><a href="#FSWEmbedding.__init__-529"><span class="linenos">529</span></a>            <span class="n">slice_freq_str</span> <span class="o">=</span> <span class="s1">&#39;Using </span><span class="si">%d</span><span class="s1"> slices </span><span class="se">\u00d7</span><span class="s1"> </span><span class="si">%d</span><span class="s1"> frequencies, collapsed to one </span><span class="si">%d</span><span class="s1"> dimensional axis; &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="p">,</span> <span class="n">num_slices</span><span class="o">*</span><span class="n">num_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-530"><a href="#FSWEmbedding.__init__-530"><span class="linenos">530</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-531"><a href="#FSWEmbedding.__init__-531"><span class="linenos">531</span></a>            <span class="n">slice_freq_str</span> <span class="o">=</span> <span class="s1">&#39;Using </span><span class="si">%d</span><span class="s1"> slices </span><span class="se">\u00d7</span><span class="s1"> </span><span class="si">%s</span><span class="s1"> frequencies; &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-532"><a href="#FSWEmbedding.__init__-532"><span class="linenos">532</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-533"><a href="#FSWEmbedding.__init__-533"><span class="linenos">533</span></a>            <span class="n">slice_freq_str</span> <span class="o">=</span> <span class="s1">&#39;Using </span><span class="si">%d</span><span class="s1"> (slice, frequency) pairs; &#39;</span> <span class="o">%</span> <span class="n">num_slices</span>
</span><span id="FSWEmbedding.__init__-534"><a href="#FSWEmbedding.__init__-534"><span class="linenos">534</span></a>
</span><span id="FSWEmbedding.__init__-535"><a href="#FSWEmbedding.__init__-535"><span class="linenos">535</span></a>        <span class="n">qprint</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="n">slice_freq_str</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-536"><a href="#FSWEmbedding.__init__-536"><span class="linenos">536</span></a>
</span><span id="FSWEmbedding.__init__-537"><a href="#FSWEmbedding.__init__-537"><span class="linenos">537</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-538"><a href="#FSWEmbedding.__init__-538"><span class="linenos">538</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-539"><a href="#FSWEmbedding.__init__-539"><span class="linenos">539</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices, frequences and biases&#39;</span>
</span><span id="FSWEmbedding.__init__-540"><a href="#FSWEmbedding.__init__-540"><span class="linenos">540</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-541"><a href="#FSWEmbedding.__init__-541"><span class="linenos">541</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices and frequences, no bias&#39;</span>
</span><span id="FSWEmbedding.__init__-542"><a href="#FSWEmbedding.__init__-542"><span class="linenos">542</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-543"><a href="#FSWEmbedding.__init__-543"><span class="linenos">543</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-544"><a href="#FSWEmbedding.__init__-544"><span class="linenos">544</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices and biases, fixed frequencies&#39;</span>
</span><span id="FSWEmbedding.__init__-545"><a href="#FSWEmbedding.__init__-545"><span class="linenos">545</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-546"><a href="#FSWEmbedding.__init__-546"><span class="linenos">546</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;learnable slices, fixed frequences, no bias&#39;</span>
</span><span id="FSWEmbedding.__init__-547"><a href="#FSWEmbedding.__init__-547"><span class="linenos">547</span></a>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-548"><a href="#FSWEmbedding.__init__-548"><span class="linenos">548</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-549"><a href="#FSWEmbedding.__init__-549"><span class="linenos">549</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices, learnable frequencies, fixed biases (initialized to zero)&#39;</span>
</span><span id="FSWEmbedding.__init__-550"><a href="#FSWEmbedding.__init__-550"><span class="linenos">550</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-551"><a href="#FSWEmbedding.__init__-551"><span class="linenos">551</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices, learnable frequencies, no biases&#39;</span>
</span><span id="FSWEmbedding.__init__-552"><a href="#FSWEmbedding.__init__-552"><span class="linenos">552</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-553"><a href="#FSWEmbedding.__init__-553"><span class="linenos">553</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-554"><a href="#FSWEmbedding.__init__-554"><span class="linenos">554</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices and frequencies, fixed biases (initialized to zero)&#39;</span>
</span><span id="FSWEmbedding.__init__-555"><a href="#FSWEmbedding.__init__-555"><span class="linenos">555</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.__init__-556"><a href="#FSWEmbedding.__init__-556"><span class="linenos">556</span></a>                <span class="n">learnable_str</span> <span class="o">=</span> <span class="s1">&#39;fixed slices and frequencies, no bias&#39;</span>
</span><span id="FSWEmbedding.__init__-557"><a href="#FSWEmbedding.__init__-557"><span class="linenos">557</span></a>
</span><span id="FSWEmbedding.__init__-558"><a href="#FSWEmbedding.__init__-558"><span class="linenos">558</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="n">learnable_str</span><span class="p">)</span>
</span><span id="FSWEmbedding.__init__-559"><a href="#FSWEmbedding.__init__-559"><span class="linenos">559</span></a>
</span><span id="FSWEmbedding.__init__-560"><a href="#FSWEmbedding.__init__-560"><span class="linenos">560</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="s1">&#39;device: </span><span class="si">%s</span><span class="s1">    dtype: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device_new</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_new</span><span class="p">))</span>
</span><span id="FSWEmbedding.__init__-561"><a href="#FSWEmbedding.__init__-561"><span class="linenos">561</span></a>
</span><span id="FSWEmbedding.__init__-562"><a href="#FSWEmbedding.__init__-562"><span class="linenos">562</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding.__init__-563"><a href="#FSWEmbedding.__init__-563"><span class="linenos">563</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding.__init__-564"><a href="#FSWEmbedding.__init__-564"><span class="linenos">564</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding.__init__-565"><a href="#FSWEmbedding.__init__-565"><span class="linenos">565</span></a>
</span><span id="FSWEmbedding.__init__-566"><a href="#FSWEmbedding.__init__-566"><span class="linenos">566</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Initialize an FSWEmbedding module.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>d_in</strong> (int):
The dimension of input multiset elements or, more generally, measure support points.<br />
Coresponds to $d$ in $\mathcal{S}_{\leq N}\left(\mathbb{R}^d\right)$, $\mathcal{P}_{\leq N}\left(\mathbb{R}^d\right)$, or $\mathcal{M}_{\leq N}\left(\mathbb{R}^d\right)$ in our paper.</li>
<li><strong>d_out</strong> (int; optional):
Desired embedding dimension.<br />
If not set, both <code><a href="#FSWEmbedding.num_slices">num_slices</a></code> and <code><a href="#FSWEmbedding.num_frequencies">num_frequencies</a></code> must be explicitly provided.</li>
<li><strong>num_slices</strong> (int; optional):
Number of slices.<br />
When provided, activates <code><a href="#FSWEmbedding.cartesian_mode">cartesian_mode</a></code>, and <code><a href="#FSWEmbedding.d_out">d_out</a></code> should be left None.<br />
See also: <code><a href="#FSWEmbedding.flatten_cartesian_axes">flatten_cartesian_axes</a></code></li>
<li><strong>num_frequencies</strong> (int; optional):
Number of frequencies per slice.<br />
When provided, activates <code><a href="#FSWEmbedding.cartesian_mode">cartesian_mode</a></code>, and <code><a href="#FSWEmbedding.d_out">d_out</a></code> should be left None.<br />
See also: <code><a href="#FSWEmbedding.flatten_cartesian_axes">flatten_cartesian_axes</a></code></li>
<li><strong>flatten_cartesian_axes</strong> (bool; default=False):
If True, flattens the slice and frequency dimensions into a single output axis.<br />
Only relevant if <code><a href="#FSWEmbedding.num_slices">num_slices</a></code> and <code><a href="#FSWEmbedding.num_frequencies">num_frequencies</a></code> are provided.</li>
<li><strong>d_edge</strong> (int; default=0):
Dimension of edge feature vectors. Used only for graph inputs.<br />
See the <code>graph_mode</code> argument of <code><a href="#FSWEmbedding.forward">FSWEmbedding.forward</a></code> for details.</li>
<li><strong>encode_total_mass</strong> (bool; default=False):
Whether to incorporate the input multiset size (or, more generally, the <em>total mass</em> of the input measure)
into the embedding output.</li>
<li><strong>total_mass_encoding_transformation</strong> ({'identity', 'sqrt', 'log'} or TotalMassEncodingFunction; default='identity'):
Transformation applied to the total mass <em>before</em> embedding.<br />
See also: <code>TotalMassEncodingFunction</code></li>
<li><strong>total_mass_encoding_method</strong> ({'decoupled', 'scaled', 'homogeneous', 'homogeneous_scaled', 'homogeneous_legacy'} or TotalMassEncodingMethod; default='decoupled'):
Strategy for combining the total mass with the core embedding.<br />
See also: <code><a href="#TotalMassEncodingMethod">TotalMassEncodingMethod</a></code></li>
<li><strong>total_mass_encoding_scale</strong> (float; default=1.0):
The encoded total mass is multiplied by this scaling factor.<br />
See also: <code><a href="#TotalMassEncodingMethod">TotalMassEncodingMethod</a></code></li>
<li><strong>total_mass_padding_thresh</strong> (float or int; default=1.0):
Inputs with total mass below this threshold are padded with the zero vector to reach it; see
in [Amir and Dym, ICLR 2025], Appendix A.1.<br />
See also: <code><a href="#TotalMassEncodingMethod">TotalMassEncodingMethod</a></code></li>
<li><strong>learnable_slices</strong> (bool; default=False):
If True, slice vectors are learnable parameters.</li>
<li><strong>learnable_frequencies</strong> (bool; default=False):
If True, frequency values are learnable parameters.</li>
<li><strong>frequency_init</strong> (float, str, tuple of float, or FrequencyInitMethod; default='random'):
Initialization scheme for frequencies:
<ul>
<li>A float: sets all frequencies to the same value.</li>
<li>A tuple <code>(low, high)</code> of floats: sets evenly spaced values in that interval.</li>
<li>'random': frequencies are drawn independently from the distribution $\mathcal{D_{\xi}}$, defined in
[Amir and Dym, ICLR 2025], Section 3.</li>
<li>'even': frequencies are spaced evenly according to their distribution $\mathcal{D_{\xi}}$, with spaces
inversely proportional to the density.<br />
See also: <code><a href="#FrequencyInitMethod">FrequencyInitMethod</a></code></li>
</ul></li>
<li><strong>minimize_slice_coherence</strong> (bool; default=False):
If True, minimizes the <em>mutual coherence</em> between slices for a more uniform spread on the unit sphere.<br />
If False, slice vectors are drawn uniformly at random from the unit sphere.</li>
<li><strong>enable_bias</strong> (bool; default=True):
If True, adds a learnable bias vector to the output embedding. When enabled, the bias is initialized
to zero.</li>
<li><strong>device</strong> (torch.device, int, str, or None, optional):
The torch device on which to allocate tensors (e.g., 'cpu', 'cuda', or an index).<br />
If not provided, the default device defined in Torch is used.</li>
<li><strong>dtype</strong> (torch.dtype, optional):
Data type of input and output tensors (e.g., torch.float32).
If not provided, the default dtype defined in Torch is used.</li>
<li><strong>use_custom_cuda_extension_if_available</strong> (bool or None, optional):
Whether to use the custom CUDA kernel if present.
Default: Linux: True, all other systems: False</li>
<li><strong>fail_if_cuda_extension_load_fails</strong> (bool; default=False):
Whether to raise a runtime error (rather than a warning) if the CUDA extension failes to load.</li>
<li><strong>report</strong> (bool; default=False):
If True, prints a report with diagnostic information during initialization and forward computation.</li>
<li><strong>report_on_coherence_minimization</strong> (bool; default=False):
If True, prints special diagnostics during slice coherence minimization.</li>
</ul>

<h6 id="notes">Notes</h6>

<p>If Cartesian mode is activated and <code><a href="#FSWEmbedding.encode_total_mass">encode_total_mass</a></code> is True, <code><a href="#FSWEmbedding.flatten_cartesian_axes">flatten_cartesian_axes</a></code> must be True.</p>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FrequencyInitMethod">FrequencyInitMethod</a></code>: 
Enum for selecting frequency initialization strategies.<br />
<code><a href="#TotalMassEncodingTransformation">TotalMassEncodingTransformation</a></code>: 
Enum for total mass transformations.<br />
<code><a href="#TotalMassEncodingMethod">TotalMassEncodingMethod</a></code>: 
Enum for strategies to incorporate total mass into the embedding.  </p>
</div>


                            </div>
                            <div id="FSWEmbedding.slice_vectors" class="classattr">
                                <div class="attr variable">
            <span class="name">slice_vectors</span>

        
    </div>
    <a class="headerlink" href="#FSWEmbedding.slice_vectors"></a>
    
    

                            </div>
                            <div id="FSWEmbedding.frequencies" class="classattr">
                                <div class="attr variable">
            <span class="name">frequencies</span>

        
    </div>
    <a class="headerlink" href="#FSWEmbedding.frequencies"></a>
    
    

                            </div>
                            <div id="FSWEmbedding.bias" class="classattr">
                                <div class="attr variable">
            <span class="name">bias</span>

        
    </div>
    <a class="headerlink" href="#FSWEmbedding.bias"></a>
    
    

                            </div>
                            <div id="FSWEmbedding.from_config" class="classattr">
                                        <input id="FSWEmbedding.from_config-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-classmethod">@classmethod</div>

        <span class="def">def</span>
        <span class="name">from_config</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">config</span><span class="p">:</span> <span class="nb">dict</span></span><span class="return-annotation">) -> <span class="n"><a href="#FSWEmbedding">FSWEmbedding</a></span>:</span></span>

                <label class="view-source-button" for="FSWEmbedding.from_config-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.from_config"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.from_config-568"><a href="#FSWEmbedding.from_config-568"><span class="linenos">568</span></a>    <span class="nd">@classmethod</span>
</span><span id="FSWEmbedding.from_config-569"><a href="#FSWEmbedding.from_config-569"><span class="linenos">569</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;FSWEmbedding&quot;</span><span class="p">:</span>
</span><span id="FSWEmbedding.from_config-570"><a href="#FSWEmbedding.from_config-570"><span class="linenos">570</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.from_config-571"><a href="#FSWEmbedding.from_config-571"><span class="linenos">571</span></a><span class="sd">        Construct an FSWEmbedding instance from a configuration dictionary.</span>
</span><span id="FSWEmbedding.from_config-572"><a href="#FSWEmbedding.from_config-572"><span class="linenos">572</span></a>
</span><span id="FSWEmbedding.from_config-573"><a href="#FSWEmbedding.from_config-573"><span class="linenos">573</span></a><span class="sd">        Parameters</span>
</span><span id="FSWEmbedding.from_config-574"><a href="#FSWEmbedding.from_config-574"><span class="linenos">574</span></a><span class="sd">        ----------</span>
</span><span id="FSWEmbedding.from_config-575"><a href="#FSWEmbedding.from_config-575"><span class="linenos">575</span></a><span class="sd">        config : dict</span>
</span><span id="FSWEmbedding.from_config-576"><a href="#FSWEmbedding.from_config-576"><span class="linenos">576</span></a><span class="sd">            Dictionary of keyword arguments matching the `__init__` parameters.</span>
</span><span id="FSWEmbedding.from_config-577"><a href="#FSWEmbedding.from_config-577"><span class="linenos">577</span></a>
</span><span id="FSWEmbedding.from_config-578"><a href="#FSWEmbedding.from_config-578"><span class="linenos">578</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding.from_config-579"><a href="#FSWEmbedding.from_config-579"><span class="linenos">579</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding.from_config-580"><a href="#FSWEmbedding.from_config-580"><span class="linenos">580</span></a><span class="sd">        FSWEmbedding</span>
</span><span id="FSWEmbedding.from_config-581"><a href="#FSWEmbedding.from_config-581"><span class="linenos">581</span></a><span class="sd">            A new instance initialized with the provided configuration.</span>
</span><span id="FSWEmbedding.from_config-582"><a href="#FSWEmbedding.from_config-582"><span class="linenos">582</span></a>
</span><span id="FSWEmbedding.from_config-583"><a href="#FSWEmbedding.from_config-583"><span class="linenos">583</span></a><span class="sd">        Raises</span>
</span><span id="FSWEmbedding.from_config-584"><a href="#FSWEmbedding.from_config-584"><span class="linenos">584</span></a><span class="sd">        ------</span>
</span><span id="FSWEmbedding.from_config-585"><a href="#FSWEmbedding.from_config-585"><span class="linenos">585</span></a><span class="sd">        TypeError</span>
</span><span id="FSWEmbedding.from_config-586"><a href="#FSWEmbedding.from_config-586"><span class="linenos">586</span></a><span class="sd">            If any keys in the dictionary are not valid constructor arguments.</span>
</span><span id="FSWEmbedding.from_config-587"><a href="#FSWEmbedding.from_config-587"><span class="linenos">587</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.from_config-588"><a href="#FSWEmbedding.from_config-588"><span class="linenos">588</span></a>        <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
</span><span id="FSWEmbedding.from_config-589"><a href="#FSWEmbedding.from_config-589"><span class="linenos">589</span></a>        <span class="n">valid_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">-</span> <span class="p">{</span><span class="s1">&#39;self&#39;</span><span class="p">}</span>
</span><span id="FSWEmbedding.from_config-590"><a href="#FSWEmbedding.from_config-590"><span class="linenos">590</span></a>        <span class="n">invalid_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="o">-</span> <span class="n">valid_keys</span>
</span><span id="FSWEmbedding.from_config-591"><a href="#FSWEmbedding.from_config-591"><span class="linenos">591</span></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">invalid_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FSWEmbedding.from_config-592"><a href="#FSWEmbedding.from_config-592"><span class="linenos">592</span></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected config key: &#39;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">invalid_keys</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding.from_config-593"><a href="#FSWEmbedding.from_config-593"><span class="linenos">593</span></a>        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">invalid_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FSWEmbedding.from_config-594"><a href="#FSWEmbedding.from_config-594"><span class="linenos">594</span></a>            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected config keys: </span><span class="si">{</span><span class="n">invalid_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding.from_config-595"><a href="#FSWEmbedding.from_config-595"><span class="linenos">595</span></a>        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Construct an FSWEmbedding instance from a configuration dictionary.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>config</strong> (dict):
Dictionary of keyword arguments matching the <code><a href="#FSWEmbedding.__init__">__init__</a></code> parameters.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>FSWEmbedding</strong>: A new instance initialized with the provided configuration.</li>
</ul>

<h6 id="raises">Raises</h6>

<ul>
<li><strong>TypeError</strong>: If any keys in the dictionary are not valid constructor arguments.</li>
</ul>
</div>


                            </div>
                            <div id="FSWEmbedding.reset_parameters" class="classattr">
                                        <input id="FSWEmbedding.reset_parameters-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reset_parameters</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">frequency_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n"><a href="#FrequencyInitMethod">FrequencyInitMethod</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">minimize_slice_coherence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">report</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">report_on_coherence_minimization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FSWEmbedding.reset_parameters-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.reset_parameters"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.reset_parameters-598"><a href="#FSWEmbedding.reset_parameters-598"><span class="linenos">598</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-599"><a href="#FSWEmbedding.reset_parameters-599"><span class="linenos">599</span></a>                         <span class="n">frequency_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span><span class="nb">float</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">FrequencyInitMethod</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-600"><a href="#FSWEmbedding.reset_parameters-600"><span class="linenos">600</span></a>                         <span class="n">minimize_slice_coherence</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-601"><a href="#FSWEmbedding.reset_parameters-601"><span class="linenos">601</span></a>                         <span class="n">report</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-602"><a href="#FSWEmbedding.reset_parameters-602"><span class="linenos">602</span></a>                         <span class="n">report_on_coherence_minimization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding.reset_parameters-603"><a href="#FSWEmbedding.reset_parameters-603"><span class="linenos">603</span></a>
</span><span id="FSWEmbedding.reset_parameters-604"><a href="#FSWEmbedding.reset_parameters-604"><span class="linenos">604</span></a>        <span class="c1"># Apply user updates for these parameters</span>
</span><span id="FSWEmbedding.reset_parameters-605"><a href="#FSWEmbedding.reset_parameters-605"><span class="linenos">605</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">frequency_init</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-606"><a href="#FSWEmbedding.reset_parameters-606"><span class="linenos">606</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">minimize_slice_coherence</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-607"><a href="#FSWEmbedding.reset_parameters-607"><span class="linenos">607</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">report</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-608"><a href="#FSWEmbedding.reset_parameters-608"><span class="linenos">608</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span> <span class="o">=</span> <span class="n">ifnone</span><span class="p">(</span><span class="n">report_on_coherence_minimization</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-609"><a href="#FSWEmbedding.reset_parameters-609"><span class="linenos">609</span></a>
</span><span id="FSWEmbedding.reset_parameters-610"><a href="#FSWEmbedding.reset_parameters-610"><span class="linenos">610</span></a>        <span class="c1"># To make sure we don&#39;t use these values inside the function; if any of then is None, we must use its self. counterpart.</span>
</span><span id="FSWEmbedding.reset_parameters-611"><a href="#FSWEmbedding.reset_parameters-611"><span class="linenos">611</span></a>        <span class="k">del</span> <span class="n">minimize_slice_coherence</span><span class="p">,</span> <span class="n">frequency_init</span><span class="p">,</span> <span class="n">report</span><span class="p">,</span> <span class="n">report_on_coherence_minimization</span>
</span><span id="FSWEmbedding.reset_parameters-612"><a href="#FSWEmbedding.reset_parameters-612"><span class="linenos">612</span></a>
</span><span id="FSWEmbedding.reset_parameters-613"><a href="#FSWEmbedding.reset_parameters-613"><span class="linenos">613</span></a>        <span class="n">qprintln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-614"><a href="#FSWEmbedding.reset_parameters-614"><span class="linenos">614</span></a>
</span><span id="FSWEmbedding.reset_parameters-615"><a href="#FSWEmbedding.reset_parameters-615"><span class="linenos">615</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_device_new&#39;</span><span class="p">):</span>
</span><span id="FSWEmbedding.reset_parameters-616"><a href="#FSWEmbedding.reset_parameters-616"><span class="linenos">616</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">,</span> <span class="s1">&#39;Generating embedding parameters:&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-617"><a href="#FSWEmbedding.reset_parameters-617"><span class="linenos">617</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.reset_parameters-618"><a href="#FSWEmbedding.reset_parameters-618"><span class="linenos">618</span></a>            <span class="n">qprintln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">,</span> <span class="s1">&#39;Resetting embedding parameters:&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-619"><a href="#FSWEmbedding.reset_parameters-619"><span class="linenos">619</span></a>
</span><span id="FSWEmbedding.reset_parameters-620"><a href="#FSWEmbedding.reset_parameters-620"><span class="linenos">620</span></a>
</span><span id="FSWEmbedding.reset_parameters-621"><a href="#FSWEmbedding.reset_parameters-621"><span class="linenos">621</span></a>        <span class="c1"># If we&#39;re running for the first time, get the device and dtype that were set in the __init__ method;</span>
</span><span id="FSWEmbedding.reset_parameters-622"><a href="#FSWEmbedding.reset_parameters-622"><span class="linenos">622</span></a>        <span class="c1"># otherwise use the current device and dtype.</span>
</span><span id="FSWEmbedding.reset_parameters-623"><a href="#FSWEmbedding.reset_parameters-623"><span class="linenos">623</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_device_new&#39;</span><span class="p">):</span>
</span><span id="FSWEmbedding.reset_parameters-624"><a href="#FSWEmbedding.reset_parameters-624"><span class="linenos">624</span></a>            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_new</span>
</span><span id="FSWEmbedding.reset_parameters-625"><a href="#FSWEmbedding.reset_parameters-625"><span class="linenos">625</span></a>            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_device_new&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-626"><a href="#FSWEmbedding.reset_parameters-626"><span class="linenos">626</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.reset_parameters-627"><a href="#FSWEmbedding.reset_parameters-627"><span class="linenos">627</span></a>            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
</span><span id="FSWEmbedding.reset_parameters-628"><a href="#FSWEmbedding.reset_parameters-628"><span class="linenos">628</span></a>
</span><span id="FSWEmbedding.reset_parameters-629"><a href="#FSWEmbedding.reset_parameters-629"><span class="linenos">629</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_dtype_new&#39;</span><span class="p">):</span>
</span><span id="FSWEmbedding.reset_parameters-630"><a href="#FSWEmbedding.reset_parameters-630"><span class="linenos">630</span></a>            <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_new</span>
</span><span id="FSWEmbedding.reset_parameters-631"><a href="#FSWEmbedding.reset_parameters-631"><span class="linenos">631</span></a>            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_dtype_new&#39;</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-632"><a href="#FSWEmbedding.reset_parameters-632"><span class="linenos">632</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.reset_parameters-633"><a href="#FSWEmbedding.reset_parameters-633"><span class="linenos">633</span></a>            <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="FSWEmbedding.reset_parameters-634"><a href="#FSWEmbedding.reset_parameters-634"><span class="linenos">634</span></a>
</span><span id="FSWEmbedding.reset_parameters-635"><a href="#FSWEmbedding.reset_parameters-635"><span class="linenos">635</span></a>
</span><span id="FSWEmbedding.reset_parameters-636"><a href="#FSWEmbedding.reset_parameters-636"><span class="linenos">636</span></a>        <span class="n">total_mass_encoding_dim</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span> <span class="k">else</span> <span class="mi">0</span>
</span><span id="FSWEmbedding.reset_parameters-637"><a href="#FSWEmbedding.reset_parameters-637"><span class="linenos">637</span></a>
</span><span id="FSWEmbedding.reset_parameters-638"><a href="#FSWEmbedding.reset_parameters-638"><span class="linenos">638</span></a>        <span class="c1"># Generate slice vectors and frequencies</span>
</span><span id="FSWEmbedding.reset_parameters-639"><a href="#FSWEmbedding.reset_parameters-639"><span class="linenos">639</span></a>        <span class="c1"># We always generate (and optimize) them in float64 and then convert to the desired dtype.</span>
</span><span id="FSWEmbedding.reset_parameters-640"><a href="#FSWEmbedding.reset_parameters-640"><span class="linenos">640</span></a>        <span class="n">slice_vectors</span><span class="p">,</span> <span class="n">frequencies</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_generate_embedding_parameters</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-641"><a href="#FSWEmbedding.reset_parameters-641"><span class="linenos">641</span></a>                                                                                       <span class="n">num_slices</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-642"><a href="#FSWEmbedding.reset_parameters-642"><span class="linenos">642</span></a>                                                                                       <span class="n">cartesian_mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-643"><a href="#FSWEmbedding.reset_parameters-643"><span class="linenos">643</span></a>                                                                                       <span class="n">flatten_cartesian_axes</span> <span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-644"><a href="#FSWEmbedding.reset_parameters-644"><span class="linenos">644</span></a>                                                                                       <span class="n">total_mass_encoding_dim</span><span class="o">=</span><span class="n">total_mass_encoding_dim</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-645"><a href="#FSWEmbedding.reset_parameters-645"><span class="linenos">645</span></a>                                                                                       <span class="n">frequency_init</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_frequency_init</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-646"><a href="#FSWEmbedding.reset_parameters-646"><span class="linenos">646</span></a>                                                                                       <span class="n">minimize_slice_coherence</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_minimize_slice_coherence</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-647"><a href="#FSWEmbedding.reset_parameters-647"><span class="linenos">647</span></a>                                                                                       <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-648"><a href="#FSWEmbedding.reset_parameters-648"><span class="linenos">648</span></a>                                                                                       <span class="n">report</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report</span><span class="p">,</span>
</span><span id="FSWEmbedding.reset_parameters-649"><a href="#FSWEmbedding.reset_parameters-649"><span class="linenos">649</span></a>                                                                                       <span class="n">report_on_coherence_minimization</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_on_coherence_minimization</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-650"><a href="#FSWEmbedding.reset_parameters-650"><span class="linenos">650</span></a>
</span><span id="FSWEmbedding.reset_parameters-651"><a href="#FSWEmbedding.reset_parameters-651"><span class="linenos">651</span></a>        <span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">slice_vectors</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-652"><a href="#FSWEmbedding.reset_parameters-652"><span class="linenos">652</span></a>        <span class="n">frequencies</span> <span class="o">=</span> <span class="n">frequencies</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-653"><a href="#FSWEmbedding.reset_parameters-653"><span class="linenos">653</span></a>
</span><span id="FSWEmbedding.reset_parameters-654"><a href="#FSWEmbedding.reset_parameters-654"><span class="linenos">654</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-655"><a href="#FSWEmbedding.reset_parameters-655"><span class="linenos">655</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-656"><a href="#FSWEmbedding.reset_parameters-656"><span class="linenos">656</span></a>
</span><span id="FSWEmbedding.reset_parameters-657"><a href="#FSWEmbedding.reset_parameters-657"><span class="linenos">657</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding.reset_parameters-658"><a href="#FSWEmbedding.reset_parameters-658"><span class="linenos">658</span></a>            <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-659"><a href="#FSWEmbedding.reset_parameters-659"><span class="linenos">659</span></a>
</span><span id="FSWEmbedding.reset_parameters-660"><a href="#FSWEmbedding.reset_parameters-660"><span class="linenos">660</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding.reset_parameters-661"><a href="#FSWEmbedding.reset_parameters-661"><span class="linenos">661</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">))</span>
</span><span id="FSWEmbedding.reset_parameters-662"><a href="#FSWEmbedding.reset_parameters-662"><span class="linenos">662</span></a>
</span><span id="FSWEmbedding.reset_parameters-663"><a href="#FSWEmbedding.reset_parameters-663"><span class="linenos">663</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-664"><a href="#FSWEmbedding.reset_parameters-664"><span class="linenos">664</span></a>
</span><span id="FSWEmbedding.reset_parameters-665"><a href="#FSWEmbedding.reset_parameters-665"><span class="linenos">665</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.reset_parameters-666"><a href="#FSWEmbedding.reset_parameters-666"><span class="linenos">666</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding.reset_parameters-667"><a href="#FSWEmbedding.reset_parameters-667"><span class="linenos">667</span></a>
</span><span id="FSWEmbedding.reset_parameters-668"><a href="#FSWEmbedding.reset_parameters-668"><span class="linenos">668</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="FSWEmbedding.reset_parameters-669"><a href="#FSWEmbedding.reset_parameters-669"><span class="linenos">669</span></a>
</span><span id="FSWEmbedding.reset_parameters-670"><a href="#FSWEmbedding.reset_parameters-670"><span class="linenos">670</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


    

                            </div>
                            <div id="FSWEmbedding.to" class="classattr">
                                        <input id="FSWEmbedding.to-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="o">*</span><span class="n">args</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FSWEmbedding.to-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.to"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.to-674"><a href="#FSWEmbedding.to-674"><span class="linenos">674</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FSWEmbedding.to-675"><a href="#FSWEmbedding.to-675"><span class="linenos">675</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Moves the module to the specified device or dtype.</span>
</span><span id="FSWEmbedding.to-676"><a href="#FSWEmbedding.to-676"><span class="linenos">676</span></a>
</span><span id="FSWEmbedding.to-677"><a href="#FSWEmbedding.to-677"><span class="linenos">677</span></a><span class="sd">        Example:</span>
</span><span id="FSWEmbedding.to-678"><a href="#FSWEmbedding.to-678"><span class="linenos">678</span></a>
</span><span id="FSWEmbedding.to-679"><a href="#FSWEmbedding.to-679"><span class="linenos">679</span></a><span class="sd">            module.to(torch.float32)</span>
</span><span id="FSWEmbedding.to-680"><a href="#FSWEmbedding.to-680"><span class="linenos">680</span></a><span class="sd">            module.to(device=&#39;cuda&#39;)</span>
</span><span id="FSWEmbedding.to-681"><a href="#FSWEmbedding.to-681"><span class="linenos">681</span></a>
</span><span id="FSWEmbedding.to-682"><a href="#FSWEmbedding.to-682"><span class="linenos">682</span></a><span class="sd">        See also: torch.nn.Module.to()</span>
</span><span id="FSWEmbedding.to-683"><a href="#FSWEmbedding.to-683"><span class="linenos">683</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.to-684"><a href="#FSWEmbedding.to-684"><span class="linenos">684</span></a>        <span class="k">if</span> <span class="s1">&#39;dtype&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
</span><span id="FSWEmbedding.to-685"><a href="#FSWEmbedding.to-685"><span class="linenos">685</span></a>            <span class="n">arg</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;dtype&#39;</span><span class="p">]</span>
</span><span id="FSWEmbedding.to-686"><a href="#FSWEmbedding.to-686"><span class="linenos">686</span></a>
</span><span id="FSWEmbedding.to-687"><a href="#FSWEmbedding.to-687"><span class="linenos">687</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="s1">&#39;invalid input type </span><span class="si">%s</span><span class="s1"> at argument &#39;&#39;dtype&#39;&#39;&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
</span><span id="FSWEmbedding.to-688"><a href="#FSWEmbedding.to-688"><span class="linenos">688</span></a>            <span class="k">assert</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_floating_point</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_complex</span><span class="p">,</span> <span class="s1">&#39;dtype must be real floating-point; instead got dtype=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">arg</span>
</span><span id="FSWEmbedding.to-689"><a href="#FSWEmbedding.to-689"><span class="linenos">689</span></a>
</span><span id="FSWEmbedding.to-690"><a href="#FSWEmbedding.to-690"><span class="linenos">690</span></a>        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
</span><span id="FSWEmbedding.to-691"><a href="#FSWEmbedding.to-691"><span class="linenos">691</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
</span><span id="FSWEmbedding.to-692"><a href="#FSWEmbedding.to-692"><span class="linenos">692</span></a>                <span class="k">assert</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_floating_point</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">arg</span><span class="o">.</span><span class="n">is_complex</span><span class="p">,</span> <span class="s1">&#39;dtype must be real floating-point; instead got dtype=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">arg</span>
</span><span id="FSWEmbedding.to-693"><a href="#FSWEmbedding.to-693"><span class="linenos">693</span></a>
</span><span id="FSWEmbedding.to-694"><a href="#FSWEmbedding.to-694"><span class="linenos">694</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FSWEmbedding.to-695"><a href="#FSWEmbedding.to-695"><span class="linenos">695</span></a>
</span><span id="FSWEmbedding.to-696"><a href="#FSWEmbedding.to-696"><span class="linenos">696</span></a>        <span class="k">return</span> <span class="bp">self</span>
</span></pre></div>


            <div class="docstring"><p>Moves the module to the specified device or dtype.</p>

<p>Example:</p>

<pre><code>module.to(torch.float32)
module.to(device='cuda')
</code></pre>

<p>See also: torch.nn.Module.to()</p>
</div>


                            </div>
                            <div id="FSWEmbedding.num_slices" class="classattr">
                                        <input id="FSWEmbedding.num_slices-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">num_slices</span><span class="annotation">: int</span>

                <label class="view-source-button" for="FSWEmbedding.num_slices-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.num_slices"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.num_slices-699"><a href="#FSWEmbedding.num_slices-699"><span class="linenos">699</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.num_slices-700"><a href="#FSWEmbedding.num_slices-700"><span class="linenos">700</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">num_slices</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding.num_slices-701"><a href="#FSWEmbedding.num_slices-701"><span class="linenos">701</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of slices used in the embedding.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.num_slices-702"><a href="#FSWEmbedding.num_slices-702"><span class="linenos">702</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span>
</span></pre></div>


            <div class="docstring"><p>Number of slices used in the embedding.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.num_frequencies" class="classattr">
                                        <input id="FSWEmbedding.num_frequencies-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">num_frequencies</span><span class="annotation">: int</span>

                <label class="view-source-button" for="FSWEmbedding.num_frequencies-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.num_frequencies"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.num_frequencies-704"><a href="#FSWEmbedding.num_frequencies-704"><span class="linenos">704</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.num_frequencies-705"><a href="#FSWEmbedding.num_frequencies-705"><span class="linenos">705</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">num_frequencies</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding.num_frequencies-706"><a href="#FSWEmbedding.num_frequencies-706"><span class="linenos">706</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of frequencies used in the embedding. In Cartesian mode, this is the number of frequencies per slice.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.num_frequencies-707"><a href="#FSWEmbedding.num_frequencies-707"><span class="linenos">707</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span>
</span></pre></div>


            <div class="docstring"><p>Number of frequencies used in the embedding. In Cartesian mode, this is the number of frequencies per slice.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.cartesian_mode" class="classattr">
                                        <input id="FSWEmbedding.cartesian_mode-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">cartesian_mode</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="FSWEmbedding.cartesian_mode-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.cartesian_mode"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.cartesian_mode-709"><a href="#FSWEmbedding.cartesian_mode-709"><span class="linenos">709</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.cartesian_mode-710"><a href="#FSWEmbedding.cartesian_mode-710"><span class="linenos">710</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">cartesian_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding.cartesian_mode-711"><a href="#FSWEmbedding.cartesian_mode-711"><span class="linenos">711</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;If True, the embedding is computed for each (slice, frequency) pair in the Cartesian product of slices</span>
</span><span id="FSWEmbedding.cartesian_mode-712"><a href="#FSWEmbedding.cartesian_mode-712"><span class="linenos">712</span></a><span class="sd">        and frequencies.</span>
</span><span id="FSWEmbedding.cartesian_mode-713"><a href="#FSWEmbedding.cartesian_mode-713"><span class="linenos">713</span></a><span class="sd">        In Cartesian mode, the embeding dimension is `d_out` = `num_slices √ó num_frequencies`.</span>
</span><span id="FSWEmbedding.cartesian_mode-714"><a href="#FSWEmbedding.cartesian_mode-714"><span class="linenos">714</span></a><span class="sd">        Cartesian mode is activated by providing `num_slices` and `num_frequencies` to `FSWEmbedding.__init__`bool</span>
</span><span id="FSWEmbedding.cartesian_mode-715"><a href="#FSWEmbedding.cartesian_mode-715"><span class="linenos">715</span></a><span class="sd">        See also: `flatten_cartesian_axes`&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.cartesian_mode-716"><a href="#FSWEmbedding.cartesian_mode-716"><span class="linenos">716</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span>
</span></pre></div>


            <div class="docstring"><p>If True, the embedding is computed for each (slice, frequency) pair in the Cartesian product of slices
and frequencies.
In Cartesian mode, the embeding dimension is <code><a href="#FSWEmbedding.d_out">d_out</a></code> = <code>num_slices √ó num_frequencies</code>.
Cartesian mode is activated by providing <code><a href="#FSWEmbedding.num_slices">num_slices</a></code> and <code><a href="#FSWEmbedding.num_frequencies">num_frequencies</a></code> to <code><a href="#FSWEmbedding.__init__">FSWEmbedding.__init__</a></code>bool
See also: <code><a href="#FSWEmbedding.flatten_cartesian_axes">flatten_cartesian_axes</a></code></p>
</div>


                            </div>
                            <div id="FSWEmbedding.flatten_cartesian_axes" class="classattr">
                                        <input id="FSWEmbedding.flatten_cartesian_axes-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">flatten_cartesian_axes</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="FSWEmbedding.flatten_cartesian_axes-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.flatten_cartesian_axes"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.flatten_cartesian_axes-718"><a href="#FSWEmbedding.flatten_cartesian_axes-718"><span class="linenos">718</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.flatten_cartesian_axes-719"><a href="#FSWEmbedding.flatten_cartesian_axes-719"><span class="linenos">719</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">flatten_cartesian_axes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding.flatten_cartesian_axes-720"><a href="#FSWEmbedding.flatten_cartesian_axes-720"><span class="linenos">720</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;In Cartesian mode, tells Whether the slice and frequency axes are flattened into a single dimension.</span>
</span><span id="FSWEmbedding.flatten_cartesian_axes-721"><a href="#FSWEmbedding.flatten_cartesian_axes-721"><span class="linenos">721</span></a><span class="sd">        If True, each input multiset/distribution corresponds to a two-dimensional output, with the shape (`num_slices`, `num_frequencies`).</span>
</span><span id="FSWEmbedding.flatten_cartesian_axes-722"><a href="#FSWEmbedding.flatten_cartesian_axes-722"><span class="linenos">722</span></a><span class="sd">        If False, the otput is shaped `num_slices` √ó `num_frequencies`.</span>
</span><span id="FSWEmbedding.flatten_cartesian_axes-723"><a href="#FSWEmbedding.flatten_cartesian_axes-723"><span class="linenos">723</span></a><span class="sd">        This setting is only relevant if `cartesian_mode` is True.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.flatten_cartesian_axes-724"><a href="#FSWEmbedding.flatten_cartesian_axes-724"><span class="linenos">724</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span>
</span></pre></div>


            <div class="docstring"><p>In Cartesian mode, tells Whether the slice and frequency axes are flattened into a single dimension.
If True, each input multiset/distribution corresponds to a two-dimensional output, with the shape (<code><a href="#FSWEmbedding.num_slices">num_slices</a></code>, <code><a href="#FSWEmbedding.num_frequencies">num_frequencies</a></code>).
If False, the otput is shaped <code><a href="#FSWEmbedding.num_slices">num_slices</a></code> √ó <code><a href="#FSWEmbedding.num_frequencies">num_frequencies</a></code>.
This setting is only relevant if <code><a href="#FSWEmbedding.cartesian_mode">cartesian_mode</a></code> is True.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.learnable_slices" class="classattr">
                                        <input id="FSWEmbedding.learnable_slices-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">learnable_slices</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="FSWEmbedding.learnable_slices-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.learnable_slices"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.learnable_slices-726"><a href="#FSWEmbedding.learnable_slices-726"><span class="linenos">726</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.learnable_slices-727"><a href="#FSWEmbedding.learnable_slices-727"><span class="linenos">727</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">learnable_slices</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding.learnable_slices-728"><a href="#FSWEmbedding.learnable_slices-728"><span class="linenos">728</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether slice directions are learnable parameters.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.learnable_slices-729"><a href="#FSWEmbedding.learnable_slices-729"><span class="linenos">729</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span>
</span></pre></div>


            <div class="docstring"><p>Whether slice directions are learnable parameters.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.learnable_frequencies" class="classattr">
                                        <input id="FSWEmbedding.learnable_frequencies-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">learnable_frequencies</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="FSWEmbedding.learnable_frequencies-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.learnable_frequencies"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.learnable_frequencies-731"><a href="#FSWEmbedding.learnable_frequencies-731"><span class="linenos">731</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.learnable_frequencies-732"><a href="#FSWEmbedding.learnable_frequencies-732"><span class="linenos">732</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">learnable_frequencies</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding.learnable_frequencies-733"><a href="#FSWEmbedding.learnable_frequencies-733"><span class="linenos">733</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether frequency values are learnable parameters.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.learnable_frequencies-734"><a href="#FSWEmbedding.learnable_frequencies-734"><span class="linenos">734</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span>
</span></pre></div>


            <div class="docstring"><p>Whether frequency values are learnable parameters.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.enable_bias" class="classattr">
                                        <input id="FSWEmbedding.enable_bias-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">enable_bias</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="FSWEmbedding.enable_bias-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.enable_bias"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.enable_bias-736"><a href="#FSWEmbedding.enable_bias-736"><span class="linenos">736</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.enable_bias-737"><a href="#FSWEmbedding.enable_bias-737"><span class="linenos">737</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">enable_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding.enable_bias-738"><a href="#FSWEmbedding.enable_bias-738"><span class="linenos">738</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether a learnable bias vector is added to the output embedding.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.enable_bias-739"><a href="#FSWEmbedding.enable_bias-739"><span class="linenos">739</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span>
</span></pre></div>


            <div class="docstring"><p>Whether a learnable bias vector is added to the output embedding.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.encode_total_mass" class="classattr">
                                        <input id="FSWEmbedding.encode_total_mass-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">encode_total_mass</span><span class="annotation">: bool</span>

                <label class="view-source-button" for="FSWEmbedding.encode_total_mass-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.encode_total_mass"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.encode_total_mass-741"><a href="#FSWEmbedding.encode_total_mass-741"><span class="linenos">741</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.encode_total_mass-742"><a href="#FSWEmbedding.encode_total_mass-742"><span class="linenos">742</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">encode_total_mass</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span id="FSWEmbedding.encode_total_mass-743"><a href="#FSWEmbedding.encode_total_mass-743"><span class="linenos">743</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether the total mass of the input measure is encoded into the embedding.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.encode_total_mass-744"><a href="#FSWEmbedding.encode_total_mass-744"><span class="linenos">744</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span>
</span></pre></div>


            <div class="docstring"><p>Whether the total mass of the input measure is encoded into the embedding.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.total_mass_encoding_transformation" class="classattr">
                                        <input id="FSWEmbedding.total_mass_encoding_transformation-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">total_mass_encoding_transformation</span><span class="annotation">: <a href="#TotalMassEncodingTransformation">TotalMassEncodingTransformation</a></span>

                <label class="view-source-button" for="FSWEmbedding.total_mass_encoding_transformation-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.total_mass_encoding_transformation"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.total_mass_encoding_transformation-746"><a href="#FSWEmbedding.total_mass_encoding_transformation-746"><span class="linenos">746</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.total_mass_encoding_transformation-747"><a href="#FSWEmbedding.total_mass_encoding_transformation-747"><span class="linenos">747</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_encoding_transformation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TotalMassEncodingTransformation</span><span class="p">:</span>
</span><span id="FSWEmbedding.total_mass_encoding_transformation-748"><a href="#FSWEmbedding.total_mass_encoding_transformation-748"><span class="linenos">748</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Function applied to the total mass before it is stored.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.total_mass_encoding_transformation-749"><a href="#FSWEmbedding.total_mass_encoding_transformation-749"><span class="linenos">749</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span>
</span></pre></div>


            <div class="docstring"><p>Function applied to the total mass before it is stored.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.total_mass_encoding_method" class="classattr">
                                        <input id="FSWEmbedding.total_mass_encoding_method-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">total_mass_encoding_method</span><span class="annotation">: <a href="#TotalMassEncodingMethod">TotalMassEncodingMethod</a></span>

                <label class="view-source-button" for="FSWEmbedding.total_mass_encoding_method-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.total_mass_encoding_method"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.total_mass_encoding_method-751"><a href="#FSWEmbedding.total_mass_encoding_method-751"><span class="linenos">751</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.total_mass_encoding_method-752"><a href="#FSWEmbedding.total_mass_encoding_method-752"><span class="linenos">752</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_encoding_method</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TotalMassEncodingMethod</span><span class="p">:</span>
</span><span id="FSWEmbedding.total_mass_encoding_method-753"><a href="#FSWEmbedding.total_mass_encoding_method-753"><span class="linenos">753</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Strategy used to incorporate total mass into the final embedding vector.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.total_mass_encoding_method-754"><a href="#FSWEmbedding.total_mass_encoding_method-754"><span class="linenos">754</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span>
</span></pre></div>


            <div class="docstring"><p>Strategy used to incorporate total mass into the final embedding vector.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.total_mass_encoding_scale" class="classattr">
                                        <input id="FSWEmbedding.total_mass_encoding_scale-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">total_mass_encoding_scale</span><span class="annotation">: float</span>

                <label class="view-source-button" for="FSWEmbedding.total_mass_encoding_scale-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.total_mass_encoding_scale"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.total_mass_encoding_scale-756"><a href="#FSWEmbedding.total_mass_encoding_scale-756"><span class="linenos">756</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.total_mass_encoding_scale-757"><a href="#FSWEmbedding.total_mass_encoding_scale-757"><span class="linenos">757</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_encoding_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="FSWEmbedding.total_mass_encoding_scale-758"><a href="#FSWEmbedding.total_mass_encoding_scale-758"><span class="linenos">758</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;The encoded total mass is scaled by this factor.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.total_mass_encoding_scale-759"><a href="#FSWEmbedding.total_mass_encoding_scale-759"><span class="linenos">759</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_scale</span>
</span></pre></div>


            <div class="docstring"><p>The encoded total mass is scaled by this factor.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.total_mass_padding_thresh" class="classattr">
                                        <input id="FSWEmbedding.total_mass_padding_thresh-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">total_mass_padding_thresh</span><span class="annotation">: float</span>

                <label class="view-source-button" for="FSWEmbedding.total_mass_padding_thresh-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.total_mass_padding_thresh"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.total_mass_padding_thresh-761"><a href="#FSWEmbedding.total_mass_padding_thresh-761"><span class="linenos">761</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.total_mass_padding_thresh-762"><a href="#FSWEmbedding.total_mass_padding_thresh-762"><span class="linenos">762</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">total_mass_padding_thresh</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span><span id="FSWEmbedding.total_mass_padding_thresh-763"><a href="#FSWEmbedding.total_mass_padding_thresh-763"><span class="linenos">763</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Minimum total mass threshold; inputs below this value are padded to reach it.&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.total_mass_padding_thresh-764"><a href="#FSWEmbedding.total_mass_padding_thresh-764"><span class="linenos">764</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span>
</span></pre></div>


            <div class="docstring"><p>Minimum total mass threshold; inputs below this value are padded to reach it.</p>
</div>


                            </div>
                            <div id="FSWEmbedding.d_in" class="classattr">
                                        <input id="FSWEmbedding.d_in-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">d_in</span><span class="annotation">: int</span>

                <label class="view-source-button" for="FSWEmbedding.d_in-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.d_in"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.d_in-767"><a href="#FSWEmbedding.d_in-767"><span class="linenos">767</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.d_in-768"><a href="#FSWEmbedding.d_in-768"><span class="linenos">768</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">d_in</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding.d_in-769"><a href="#FSWEmbedding.d_in-769"><span class="linenos">769</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;int: Ambient dimension of the input elements.</span>
</span><span id="FSWEmbedding.d_in-770"><a href="#FSWEmbedding.d_in-770"><span class="linenos">770</span></a>
</span><span id="FSWEmbedding.d_in-771"><a href="#FSWEmbedding.d_in-771"><span class="linenos">771</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding.d_in-772"><a href="#FSWEmbedding.d_in-772"><span class="linenos">772</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding.d_in-773"><a href="#FSWEmbedding.d_in-773"><span class="linenos">773</span></a><span class="sd">        int</span>
</span><span id="FSWEmbedding.d_in-774"><a href="#FSWEmbedding.d_in-774"><span class="linenos">774</span></a><span class="sd">            The input dimensionality of the multiset elements (i.e., the last dimension of the input tensors).</span>
</span><span id="FSWEmbedding.d_in-775"><a href="#FSWEmbedding.d_in-775"><span class="linenos">775</span></a>
</span><span id="FSWEmbedding.d_in-776"><a href="#FSWEmbedding.d_in-776"><span class="linenos">776</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding.d_in-777"><a href="#FSWEmbedding.d_in-777"><span class="linenos">777</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding.d_in-778"><a href="#FSWEmbedding.d_in-778"><span class="linenos">778</span></a><span class="sd">        This value is set at initialization and determines the expected feature dimension of input points.</span>
</span><span id="FSWEmbedding.d_in-779"><a href="#FSWEmbedding.d_in-779"><span class="linenos">779</span></a>
</span><span id="FSWEmbedding.d_in-780"><a href="#FSWEmbedding.d_in-780"><span class="linenos">780</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding.d_in-781"><a href="#FSWEmbedding.d_in-781"><span class="linenos">781</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding.d_in-782"><a href="#FSWEmbedding.d_in-782"><span class="linenos">782</span></a><span class="sd">        __init__ : The `d_in` argument specifies this value at initialization.</span>
</span><span id="FSWEmbedding.d_in-783"><a href="#FSWEmbedding.d_in-783"><span class="linenos">783</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.d_in-784"><a href="#FSWEmbedding.d_in-784"><span class="linenos">784</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span>
</span></pre></div>


            <div class="docstring"><p>int: Ambient dimension of the input elements.</p>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>int</strong>: The input dimensionality of the multiset elements (i.e., the last dimension of the input tensors).</li>
</ul>

<h6 id="notes">Notes</h6>

<p>This value is set at initialization and determines the expected feature dimension of input points.</p>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FSWEmbedding.__init__">__init__</a></code>:  The <code><a href="#FSWEmbedding.d_in">d_in</a></code> argument specifies this value at initialization.  </p>
</div>


                            </div>
                            <div id="FSWEmbedding.d_out" class="classattr">
                                        <input id="FSWEmbedding.d_out-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">d_out</span><span class="annotation">: int</span>

                <label class="view-source-button" for="FSWEmbedding.d_out-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.d_out"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.d_out-787"><a href="#FSWEmbedding.d_out-787"><span class="linenos">787</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.d_out-788"><a href="#FSWEmbedding.d_out-788"><span class="linenos">788</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">d_out</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
</span><span id="FSWEmbedding.d_out-789"><a href="#FSWEmbedding.d_out-789"><span class="linenos">789</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;int: Dimensionality of the embedding output.</span>
</span><span id="FSWEmbedding.d_out-790"><a href="#FSWEmbedding.d_out-790"><span class="linenos">790</span></a>
</span><span id="FSWEmbedding.d_out-791"><a href="#FSWEmbedding.d_out-791"><span class="linenos">791</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding.d_out-792"><a href="#FSWEmbedding.d_out-792"><span class="linenos">792</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding.d_out-793"><a href="#FSWEmbedding.d_out-793"><span class="linenos">793</span></a><span class="sd">        int</span>
</span><span id="FSWEmbedding.d_out-794"><a href="#FSWEmbedding.d_out-794"><span class="linenos">794</span></a><span class="sd">            The dimension of the vector produced by the embedding for each multiset or distribution.</span>
</span><span id="FSWEmbedding.d_out-795"><a href="#FSWEmbedding.d_out-795"><span class="linenos">795</span></a>
</span><span id="FSWEmbedding.d_out-796"><a href="#FSWEmbedding.d_out-796"><span class="linenos">796</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding.d_out-797"><a href="#FSWEmbedding.d_out-797"><span class="linenos">797</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding.d_out-798"><a href="#FSWEmbedding.d_out-798"><span class="linenos">798</span></a><span class="sd">        This value is set at initialization and governs the size of the embedding output.</span>
</span><span id="FSWEmbedding.d_out-799"><a href="#FSWEmbedding.d_out-799"><span class="linenos">799</span></a>
</span><span id="FSWEmbedding.d_out-800"><a href="#FSWEmbedding.d_out-800"><span class="linenos">800</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding.d_out-801"><a href="#FSWEmbedding.d_out-801"><span class="linenos">801</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding.d_out-802"><a href="#FSWEmbedding.d_out-802"><span class="linenos">802</span></a><span class="sd">        __init__ : The `d_out` argument specifies this value at initialization.</span>
</span><span id="FSWEmbedding.d_out-803"><a href="#FSWEmbedding.d_out-803"><span class="linenos">803</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.d_out-804"><a href="#FSWEmbedding.d_out-804"><span class="linenos">804</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span>
</span></pre></div>


            <div class="docstring"><p>int: Dimensionality of the embedding output.</p>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>int</strong>: The dimension of the vector produced by the embedding for each multiset or distribution.</li>
</ul>

<h6 id="notes">Notes</h6>

<p>This value is set at initialization and governs the size of the embedding output.</p>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FSWEmbedding.__init__">__init__</a></code>:  The <code><a href="#FSWEmbedding.d_out">d_out</a></code> argument specifies this value at initialization.  </p>
</div>


                            </div>
                            <div id="FSWEmbedding.device" class="classattr">
                                        <input id="FSWEmbedding.device-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">device</span>

                <label class="view-source-button" for="FSWEmbedding.device-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.device"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.device-806"><a href="#FSWEmbedding.device-806"><span class="linenos">806</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.device-807"><a href="#FSWEmbedding.device-807"><span class="linenos">807</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FSWEmbedding.device-808"><a href="#FSWEmbedding.device-808"><span class="linenos">808</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;torch.device: The device on which the module&#39;s parameters and buffers are stored.</span>
</span><span id="FSWEmbedding.device-809"><a href="#FSWEmbedding.device-809"><span class="linenos">809</span></a>
</span><span id="FSWEmbedding.device-810"><a href="#FSWEmbedding.device-810"><span class="linenos">810</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding.device-811"><a href="#FSWEmbedding.device-811"><span class="linenos">811</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding.device-812"><a href="#FSWEmbedding.device-812"><span class="linenos">812</span></a><span class="sd">        torch.device</span>
</span><span id="FSWEmbedding.device-813"><a href="#FSWEmbedding.device-813"><span class="linenos">813</span></a><span class="sd">            The PyTorch device (`&#39;cpu&#39;`, `&#39;cuda&#39;`, etc.) where the embedding computations will take place.</span>
</span><span id="FSWEmbedding.device-814"><a href="#FSWEmbedding.device-814"><span class="linenos">814</span></a>
</span><span id="FSWEmbedding.device-815"><a href="#FSWEmbedding.device-815"><span class="linenos">815</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding.device-816"><a href="#FSWEmbedding.device-816"><span class="linenos">816</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding.device-817"><a href="#FSWEmbedding.device-817"><span class="linenos">817</span></a><span class="sd">        This behaves like the `device` property in standard PyTorch modules.</span>
</span><span id="FSWEmbedding.device-818"><a href="#FSWEmbedding.device-818"><span class="linenos">818</span></a>
</span><span id="FSWEmbedding.device-819"><a href="#FSWEmbedding.device-819"><span class="linenos">819</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding.device-820"><a href="#FSWEmbedding.device-820"><span class="linenos">820</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding.device-821"><a href="#FSWEmbedding.device-821"><span class="linenos">821</span></a><span class="sd">        __init__ : The `device` can be specified at initialization.</span>
</span><span id="FSWEmbedding.device-822"><a href="#FSWEmbedding.device-822"><span class="linenos">822</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.device-823"><a href="#FSWEmbedding.device-823"><span class="linenos">823</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">device</span>
</span></pre></div>


            <div class="docstring"><p>torch.device: The device on which the module's parameters and buffers are stored.</p>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>torch.device</strong>: The PyTorch device (<code>'cpu'</code>, <code>'cuda'</code>, etc.) where the embedding computations will take place.</li>
</ul>

<h6 id="notes">Notes</h6>

<p>This behaves like the <code><a href="#FSWEmbedding.device">device</a></code> property in standard PyTorch modules.</p>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FSWEmbedding.__init__">__init__</a></code>:  The <code><a href="#FSWEmbedding.device">device</a></code> can be specified at initialization.  </p>
</div>


                            </div>
                            <div id="FSWEmbedding.dtype" class="classattr">
                                        <input id="FSWEmbedding.dtype-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">dtype</span>

                <label class="view-source-button" for="FSWEmbedding.dtype-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.dtype"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.dtype-826"><a href="#FSWEmbedding.dtype-826"><span class="linenos">826</span></a>    <span class="nd">@property</span>
</span><span id="FSWEmbedding.dtype-827"><a href="#FSWEmbedding.dtype-827"><span class="linenos">827</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FSWEmbedding.dtype-828"><a href="#FSWEmbedding.dtype-828"><span class="linenos">828</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;torch.dtype: The default data type used by the module.</span>
</span><span id="FSWEmbedding.dtype-829"><a href="#FSWEmbedding.dtype-829"><span class="linenos">829</span></a>
</span><span id="FSWEmbedding.dtype-830"><a href="#FSWEmbedding.dtype-830"><span class="linenos">830</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding.dtype-831"><a href="#FSWEmbedding.dtype-831"><span class="linenos">831</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding.dtype-832"><a href="#FSWEmbedding.dtype-832"><span class="linenos">832</span></a><span class="sd">        torch.dtype</span>
</span><span id="FSWEmbedding.dtype-833"><a href="#FSWEmbedding.dtype-833"><span class="linenos">833</span></a><span class="sd">            The data type (`torch.float32`, `torch.float64`, etc.) of the module‚Äôs parameters and buffers.</span>
</span><span id="FSWEmbedding.dtype-834"><a href="#FSWEmbedding.dtype-834"><span class="linenos">834</span></a>
</span><span id="FSWEmbedding.dtype-835"><a href="#FSWEmbedding.dtype-835"><span class="linenos">835</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding.dtype-836"><a href="#FSWEmbedding.dtype-836"><span class="linenos">836</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding.dtype-837"><a href="#FSWEmbedding.dtype-837"><span class="linenos">837</span></a><span class="sd">        This behaves like the `dtype` property in standard PyTorch modules.</span>
</span><span id="FSWEmbedding.dtype-838"><a href="#FSWEmbedding.dtype-838"><span class="linenos">838</span></a>
</span><span id="FSWEmbedding.dtype-839"><a href="#FSWEmbedding.dtype-839"><span class="linenos">839</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding.dtype-840"><a href="#FSWEmbedding.dtype-840"><span class="linenos">840</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding.dtype-841"><a href="#FSWEmbedding.dtype-841"><span class="linenos">841</span></a><span class="sd">        __init__ : The `dtype` can be specified at initialization.</span>
</span><span id="FSWEmbedding.dtype-842"><a href="#FSWEmbedding.dtype-842"><span class="linenos">842</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.dtype-843"><a href="#FSWEmbedding.dtype-843"><span class="linenos">843</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">dtype</span>
</span></pre></div>


            <div class="docstring"><p>torch.dtype: The default data type used by the module.</p>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>torch.dtype</strong>: The data type (<code>torch.float32</code>, <code>torch.float64</code>, etc.) of the module‚Äôs parameters and buffers.</li>
</ul>

<h6 id="notes">Notes</h6>

<p>This behaves like the <code><a href="#FSWEmbedding.dtype">dtype</a></code> property in standard PyTorch modules.</p>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FSWEmbedding.__init__">__init__</a></code>:  The <code><a href="#FSWEmbedding.dtype">dtype</a></code> can be specified at initialization.  </p>
</div>


                            </div>
                            <div id="FSWEmbedding.forward" class="classattr">
                                        <input id="FSWEmbedding.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">	<span class="n">W</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;unit&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;unit&#39;</span>,</span><span class="param">	<span class="n">X_edge</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">graph_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">max_parallel_slices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FSWEmbedding.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWEmbedding.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWEmbedding.forward-994"><a href="#FSWEmbedding.forward-994"><span class="linenos"> 994</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-995"><a href="#FSWEmbedding.forward-995"><span class="linenos"> 995</span></a>                <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-996"><a href="#FSWEmbedding.forward-996"><span class="linenos"> 996</span></a>                <span class="n">W</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;unit&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">]</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="s1">&#39;unit&#39;</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-997"><a href="#FSWEmbedding.forward-997"><span class="linenos"> 997</span></a>                <span class="n">X_edge</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-998"><a href="#FSWEmbedding.forward-998"><span class="linenos"> 998</span></a>                <span class="n">graph_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-999"><a href="#FSWEmbedding.forward-999"><span class="linenos"> 999</span></a>                <span class="n">max_parallel_slices</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
</span><span id="FSWEmbedding.forward-1000"><a href="#FSWEmbedding.forward-1000"><span class="linenos">1000</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.forward-1001"><a href="#FSWEmbedding.forward-1001"><span class="linenos">1001</span></a><span class="sd">        Compute the FSW embedding of an input multiset, measure, or graph.</span>
</span><span id="FSWEmbedding.forward-1002"><a href="#FSWEmbedding.forward-1002"><span class="linenos">1002</span></a>
</span><span id="FSWEmbedding.forward-1003"><a href="#FSWEmbedding.forward-1003"><span class="linenos">1003</span></a><span class="sd">        This method maps input sets of vectors (optionally weighted) to vectors in ‚Ñù^{d_out}</span>
</span><span id="FSWEmbedding.forward-1004"><a href="#FSWEmbedding.forward-1004"><span class="linenos">1004</span></a><span class="sd">        using the Fourier Sliced-Wasserstein (FSW) embedding. It supports batched inputs and</span>
</span><span id="FSWEmbedding.forward-1005"><a href="#FSWEmbedding.forward-1005"><span class="linenos">1005</span></a><span class="sd">        graph-based neighbor aggregation, with possibly sparse weight/adjacency matrices.</span>
</span><span id="FSWEmbedding.forward-1006"><a href="#FSWEmbedding.forward-1006"><span class="linenos">1006</span></a>
</span><span id="FSWEmbedding.forward-1007"><a href="#FSWEmbedding.forward-1007"><span class="linenos">1007</span></a><span class="sd">        Parameters</span>
</span><span id="FSWEmbedding.forward-1008"><a href="#FSWEmbedding.forward-1008"><span class="linenos">1008</span></a><span class="sd">        ----------</span>
</span><span id="FSWEmbedding.forward-1009"><a href="#FSWEmbedding.forward-1009"><span class="linenos">1009</span></a><span class="sd">        X : torch.Tensor</span>
</span><span id="FSWEmbedding.forward-1010"><a href="#FSWEmbedding.forward-1010"><span class="linenos">1010</span></a><span class="sd">            Input tensor of shape `(n, d_in)` or `(..., n, d_in)` for batched input.</span>
</span><span id="FSWEmbedding.forward-1011"><a href="#FSWEmbedding.forward-1011"><span class="linenos">1011</span></a><span class="sd">        W : torch.Tensor or {&#39;unit&#39;, &#39;uniform&#39;}, default=&#39;unit&#39;</span>
</span><span id="FSWEmbedding.forward-1012"><a href="#FSWEmbedding.forward-1012"><span class="linenos">1012</span></a><span class="sd">            Weights tensor of shape `(n,)` or `(..., n)` corresponding to point importance.</span>
</span><span id="FSWEmbedding.forward-1013"><a href="#FSWEmbedding.forward-1013"><span class="linenos">1013</span></a><span class="sd">            If set to `&#39;unit&#39;` or `&#39;uniform&#39;`, uniform weights of `1/n` are assumed.</span>
</span><span id="FSWEmbedding.forward-1014"><a href="#FSWEmbedding.forward-1014"><span class="linenos">1014</span></a><span class="sd">        X_edge : torch.Tensor, optional</span>
</span><span id="FSWEmbedding.forward-1015"><a href="#FSWEmbedding.forward-1015"><span class="linenos">1015</span></a><span class="sd">            Optional edge feature tensor. Required if `d_edge &gt; 0` was set at initialization.</span>
</span><span id="FSWEmbedding.forward-1016"><a href="#FSWEmbedding.forward-1016"><span class="linenos">1016</span></a><span class="sd">        graph_mode : bool, default=False</span>
</span><span id="FSWEmbedding.forward-1017"><a href="#FSWEmbedding.forward-1017"><span class="linenos">1017</span></a><span class="sd">            If True, interprets `W` as an adjacency matrix and computes a neighbor-aggregated</span>
</span><span id="FSWEmbedding.forward-1018"><a href="#FSWEmbedding.forward-1018"><span class="linenos">1018</span></a><span class="sd">            embedding.</span>
</span><span id="FSWEmbedding.forward-1019"><a href="#FSWEmbedding.forward-1019"><span class="linenos">1019</span></a><span class="sd">        max_parallel_slices : int, optional</span>
</span><span id="FSWEmbedding.forward-1020"><a href="#FSWEmbedding.forward-1020"><span class="linenos">1020</span></a><span class="sd">            Limits the number of slices processed in parallel. Reduces memory usage by computing</span>
</span><span id="FSWEmbedding.forward-1021"><a href="#FSWEmbedding.forward-1021"><span class="linenos">1021</span></a><span class="sd">            the embedding in smaller blocks without changing the result.</span>
</span><span id="FSWEmbedding.forward-1022"><a href="#FSWEmbedding.forward-1022"><span class="linenos">1022</span></a>
</span><span id="FSWEmbedding.forward-1023"><a href="#FSWEmbedding.forward-1023"><span class="linenos">1023</span></a><span class="sd">        Returns</span>
</span><span id="FSWEmbedding.forward-1024"><a href="#FSWEmbedding.forward-1024"><span class="linenos">1024</span></a><span class="sd">        -------</span>
</span><span id="FSWEmbedding.forward-1025"><a href="#FSWEmbedding.forward-1025"><span class="linenos">1025</span></a><span class="sd">        torch.Tensor</span>
</span><span id="FSWEmbedding.forward-1026"><a href="#FSWEmbedding.forward-1026"><span class="linenos">1026</span></a><span class="sd">            The embedding tensor. Shape depends on the mode:</span>
</span><span id="FSWEmbedding.forward-1027"><a href="#FSWEmbedding.forward-1027"><span class="linenos">1027</span></a><span class="sd">            - `(d_out,)` or `(..., d_out)` in standard mode.</span>
</span><span id="FSWEmbedding.forward-1028"><a href="#FSWEmbedding.forward-1028"><span class="linenos">1028</span></a><span class="sd">            - `(..., num_slices, num_frequencies)` in Cartesian mode if `flatten_cartesian_axes=False`.</span>
</span><span id="FSWEmbedding.forward-1029"><a href="#FSWEmbedding.forward-1029"><span class="linenos">1029</span></a><span class="sd">            - `(..., num_slices * num_frequencies)` in Cartesian mode if `flatten_cartesian_axes=True`.</span>
</span><span id="FSWEmbedding.forward-1030"><a href="#FSWEmbedding.forward-1030"><span class="linenos">1030</span></a>
</span><span id="FSWEmbedding.forward-1031"><a href="#FSWEmbedding.forward-1031"><span class="linenos">1031</span></a><span class="sd">        Notes</span>
</span><span id="FSWEmbedding.forward-1032"><a href="#FSWEmbedding.forward-1032"><span class="linenos">1032</span></a><span class="sd">        -----</span>
</span><span id="FSWEmbedding.forward-1033"><a href="#FSWEmbedding.forward-1033"><span class="linenos">1033</span></a><span class="sd">        Multisets and distributions:</span>
</span><span id="FSWEmbedding.forward-1034"><a href="#FSWEmbedding.forward-1034"><span class="linenos">1034</span></a><span class="sd">            If `X` is `(n, d_in)` and `W` is `(n,)`, the pair represents a weighted point cloud.</span>
</span><span id="FSWEmbedding.forward-1035"><a href="#FSWEmbedding.forward-1035"><span class="linenos">1035</span></a><span class="sd">            Weights must be non-negative with positive total mass.</span>
</span><span id="FSWEmbedding.forward-1036"><a href="#FSWEmbedding.forward-1036"><span class="linenos">1036</span></a><span class="sd">            If `W` is `&#39;unit&#39;` or `&#39;uniform&#39;`, uniform weights are used internally.</span>
</span><span id="FSWEmbedding.forward-1037"><a href="#FSWEmbedding.forward-1037"><span class="linenos">1037</span></a>
</span><span id="FSWEmbedding.forward-1038"><a href="#FSWEmbedding.forward-1038"><span class="linenos">1038</span></a><span class="sd">        Batching:</span>
</span><span id="FSWEmbedding.forward-1039"><a href="#FSWEmbedding.forward-1039"><span class="linenos">1039</span></a><span class="sd">            Input tensors may include leading batch dimensions. For `X` of shape `(..., n, d_in)`</span>
</span><span id="FSWEmbedding.forward-1040"><a href="#FSWEmbedding.forward-1040"><span class="linenos">1040</span></a><span class="sd">            and `W` of shape `(..., n)`, the output shape is `(..., d_out)`.</span>
</span><span id="FSWEmbedding.forward-1041"><a href="#FSWEmbedding.forward-1041"><span class="linenos">1041</span></a>
</span><span id="FSWEmbedding.forward-1042"><a href="#FSWEmbedding.forward-1042"><span class="linenos">1042</span></a><span class="sd">        Graph mode:</span>
</span><span id="FSWEmbedding.forward-1043"><a href="#FSWEmbedding.forward-1043"><span class="linenos">1043</span></a><span class="sd">            When `graph_mode=True`, `W` must be of shape `(..., n_recipients, n)` and `X` of</span>
</span><span id="FSWEmbedding.forward-1044"><a href="#FSWEmbedding.forward-1044"><span class="linenos">1044</span></a><span class="sd">            shape `(..., n, d_in)` or broadcastable to that. The output will be</span>
</span><span id="FSWEmbedding.forward-1045"><a href="#FSWEmbedding.forward-1045"><span class="linenos">1045</span></a><span class="sd">            `(..., n_recipients, d_out)`, where each vector represents a weighted embedding of</span>
</span><span id="FSWEmbedding.forward-1046"><a href="#FSWEmbedding.forward-1046"><span class="linenos">1046</span></a><span class="sd">            neighboring nodes. This avoids expanding `X` across `n_recipients` explicitly.</span>
</span><span id="FSWEmbedding.forward-1047"><a href="#FSWEmbedding.forward-1047"><span class="linenos">1047</span></a>
</span><span id="FSWEmbedding.forward-1048"><a href="#FSWEmbedding.forward-1048"><span class="linenos">1048</span></a><span class="sd">        Cartesian mode:</span>
</span><span id="FSWEmbedding.forward-1049"><a href="#FSWEmbedding.forward-1049"><span class="linenos">1049</span></a><span class="sd">            If `d_out` is not specified but `num_slices` and `num_frequencies` are, the embedding</span>
</span><span id="FSWEmbedding.forward-1050"><a href="#FSWEmbedding.forward-1050"><span class="linenos">1050</span></a><span class="sd">            is computed over a Cartesian product. The output shape is:</span>
</span><span id="FSWEmbedding.forward-1051"><a href="#FSWEmbedding.forward-1051"><span class="linenos">1051</span></a><span class="sd">                - `(..., num_slices, num_frequencies)` if `flatten_cartesian_axes=False`</span>
</span><span id="FSWEmbedding.forward-1052"><a href="#FSWEmbedding.forward-1052"><span class="linenos">1052</span></a><span class="sd">                - `(..., num_slices * num_frequencies)` if `flatten_cartesian_axes=True`</span>
</span><span id="FSWEmbedding.forward-1053"><a href="#FSWEmbedding.forward-1053"><span class="linenos">1053</span></a>
</span><span id="FSWEmbedding.forward-1054"><a href="#FSWEmbedding.forward-1054"><span class="linenos">1054</span></a><span class="sd">        Slice serialization:</span>
</span><span id="FSWEmbedding.forward-1055"><a href="#FSWEmbedding.forward-1055"><span class="linenos">1055</span></a><span class="sd">            If `max_parallel_slices=t` is set, the computation is performed in blocks of size `t`,</span>
</span><span id="FSWEmbedding.forward-1056"><a href="#FSWEmbedding.forward-1056"><span class="linenos">1056</span></a><span class="sd">            reducing memory complexity by a factor of `num_slices / t`. The output remains unchanged.</span>
</span><span id="FSWEmbedding.forward-1057"><a href="#FSWEmbedding.forward-1057"><span class="linenos">1057</span></a>
</span><span id="FSWEmbedding.forward-1058"><a href="#FSWEmbedding.forward-1058"><span class="linenos">1058</span></a><span class="sd">        See Also</span>
</span><span id="FSWEmbedding.forward-1059"><a href="#FSWEmbedding.forward-1059"><span class="linenos">1059</span></a><span class="sd">        --------</span>
</span><span id="FSWEmbedding.forward-1060"><a href="#FSWEmbedding.forward-1060"><span class="linenos">1060</span></a><span class="sd">        FSWEmbedding.__init__ : Constructor for model configuration options.</span>
</span><span id="FSWEmbedding.forward-1061"><a href="#FSWEmbedding.forward-1061"><span class="linenos">1061</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FSWEmbedding.forward-1062"><a href="#FSWEmbedding.forward-1062"><span class="linenos">1062</span></a>
</span><span id="FSWEmbedding.forward-1063"><a href="#FSWEmbedding.forward-1063"><span class="linenos">1063</span></a>
</span><span id="FSWEmbedding.forward-1064"><a href="#FSWEmbedding.forward-1064"><span class="linenos">1064</span></a>        <span class="c1"># Verify slices and frequencies at each forward pass if they are learnable</span>
</span><span id="FSWEmbedding.forward-1065"><a href="#FSWEmbedding.forward-1065"><span class="linenos">1065</span></a>        <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_slices</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1066"><a href="#FSWEmbedding.forward-1066"><span class="linenos">1066</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Slice vectors contain NaNs&#39;</span>
</span><span id="FSWEmbedding.forward-1067"><a href="#FSWEmbedding.forward-1067"><span class="linenos">1067</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Slice vectors contain infs&#39;</span>
</span><span id="FSWEmbedding.forward-1068"><a href="#FSWEmbedding.forward-1068"><span class="linenos">1068</span></a>            <span class="c1"># Note: We allow them to contain zero vectors when they are learnable, in case i.e. when sparsity is desired</span>
</span><span id="FSWEmbedding.forward-1069"><a href="#FSWEmbedding.forward-1069"><span class="linenos">1069</span></a>            <span class="c1"># assert not (self.slice_vectors == 0).all(dim=1).any(), &#39;Slice vectors contain a zero vector&#39;</span>
</span><span id="FSWEmbedding.forward-1070"><a href="#FSWEmbedding.forward-1070"><span class="linenos">1070</span></a>
</span><span id="FSWEmbedding.forward-1071"><a href="#FSWEmbedding.forward-1071"><span class="linenos">1071</span></a>        <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learnable_frequencies</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1072"><a href="#FSWEmbedding.forward-1072"><span class="linenos">1072</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Frequencies contain NaNs&#39;</span>
</span><span id="FSWEmbedding.forward-1073"><a href="#FSWEmbedding.forward-1073"><span class="linenos">1073</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s1">&#39;Frequencies contain infs&#39;</span>
</span><span id="FSWEmbedding.forward-1074"><a href="#FSWEmbedding.forward-1074"><span class="linenos">1074</span></a>
</span><span id="FSWEmbedding.forward-1075"><a href="#FSWEmbedding.forward-1075"><span class="linenos">1075</span></a>        <span class="c1">### A. Verify input types and content</span>
</span><span id="FSWEmbedding.forward-1076"><a href="#FSWEmbedding.forward-1076"><span class="linenos">1076</span></a>
</span><span id="FSWEmbedding.forward-1077"><a href="#FSWEmbedding.forward-1077"><span class="linenos">1077</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;total_mass_padding_thresh must be positive&#39;</span>
</span><span id="FSWEmbedding.forward-1078"><a href="#FSWEmbedding.forward-1078"><span class="linenos">1078</span></a>
</span><span id="FSWEmbedding.forward-1079"><a href="#FSWEmbedding.forward-1079"><span class="linenos">1079</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1080"><a href="#FSWEmbedding.forward-1080"><span class="linenos">1080</span></a>            <span class="k">assert</span> <span class="n">graph_mode</span><span class="p">,</span> <span class="s1">&#39;d_edge &gt; 0 (given at initialization) necessitates graph_mode=True on forward call&#39;</span>
</span><span id="FSWEmbedding.forward-1081"><a href="#FSWEmbedding.forward-1081"><span class="linenos">1081</span></a>            <span class="k">assert</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;X_edge must be provided since d_edge &gt; 0&#39;</span>
</span><span id="FSWEmbedding.forward-1082"><a href="#FSWEmbedding.forward-1082"><span class="linenos">1082</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1083"><a href="#FSWEmbedding.forward-1083"><span class="linenos">1083</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;X_edge should be None or empty since d_edge == 0&#39;</span>
</span><span id="FSWEmbedding.forward-1084"><a href="#FSWEmbedding.forward-1084"><span class="linenos">1084</span></a>            <span class="n">X_edge</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding.forward-1085"><a href="#FSWEmbedding.forward-1085"><span class="linenos">1085</span></a>
</span><span id="FSWEmbedding.forward-1086"><a href="#FSWEmbedding.forward-1086"><span class="linenos">1086</span></a>        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s1">&#39;X must be a pytorch tensor. Instead got type </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</span><span id="FSWEmbedding.forward-1087"><a href="#FSWEmbedding.forward-1087"><span class="linenos">1087</span></a>        <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">)</span> <span class="ow">or</span> <span class="n">W</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;unit&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">},</span> <span class="s1">&#39;W must be a pytorch tensor, </span><span class="se">\&#39;</span><span class="s1">unit</span><span class="se">\&#39;</span><span class="s1"> or </span><span class="se">\&#39;</span><span class="s1">uniform</span><span class="se">\&#39;</span><span class="s1">&#39;</span>
</span><span id="FSWEmbedding.forward-1088"><a href="#FSWEmbedding.forward-1088"><span class="linenos">1088</span></a>        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;X has the wrong dtype. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1089"><a href="#FSWEmbedding.forward-1089"><span class="linenos">1089</span></a>        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;X is on the wrong device. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1090"><a href="#FSWEmbedding.forward-1090"><span class="linenos">1090</span></a>
</span><span id="FSWEmbedding.forward-1091"><a href="#FSWEmbedding.forward-1091"><span class="linenos">1091</span></a>        <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1092"><a href="#FSWEmbedding.forward-1092"><span class="linenos">1092</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;The entries of X cannot contain NaNs&quot;</span>
</span><span id="FSWEmbedding.forward-1093"><a href="#FSWEmbedding.forward-1093"><span class="linenos">1093</span></a>            <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;All entries of X must be finite&quot;</span>
</span><span id="FSWEmbedding.forward-1094"><a href="#FSWEmbedding.forward-1094"><span class="linenos">1094</span></a>
</span><span id="FSWEmbedding.forward-1095"><a href="#FSWEmbedding.forward-1095"><span class="linenos">1095</span></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
</span><span id="FSWEmbedding.forward-1096"><a href="#FSWEmbedding.forward-1096"><span class="linenos">1096</span></a>            <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;W has the wrong dtype. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1097"><a href="#FSWEmbedding.forward-1097"><span class="linenos">1097</span></a>            <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;W is on the wrong device. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1098"><a href="#FSWEmbedding.forward-1098"><span class="linenos">1098</span></a>
</span><span id="FSWEmbedding.forward-1099"><a href="#FSWEmbedding.forward-1099"><span class="linenos">1099</span></a>            <span class="c1"># Check if W is sparse. If so, ensure that W is of the correct layout.</span>
</span><span id="FSWEmbedding.forward-1100"><a href="#FSWEmbedding.forward-1100"><span class="linenos">1100</span></a>            <span class="c1"># Note: Strangely enough, sparse tensors of layouts other than COO (e.g. CSR) may have is_sparse=False.</span>
</span><span id="FSWEmbedding.forward-1101"><a href="#FSWEmbedding.forward-1101"><span class="linenos">1101</span></a>            <span class="c1">#       This may lead us to mistakenly treat a, e.g. W that is sparse CSR as dense.</span>
</span><span id="FSWEmbedding.forward-1102"><a href="#FSWEmbedding.forward-1102"><span class="linenos">1102</span></a>            <span class="c1">#       Currently there is no is_dense() function in torch, so reading the layout string directly is the second best.</span>
</span><span id="FSWEmbedding.forward-1103"><a href="#FSWEmbedding.forward-1103"><span class="linenos">1103</span></a>            <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span> <span class="ow">or</span> <span class="n">W</span><span class="o">.</span><span class="n">layout</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1104"><a href="#FSWEmbedding.forward-1104"><span class="linenos">1104</span></a>                <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">layout</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;Sparse W has an unsupported sparsity layout &#39;</span><span class="si">%s</span><span class="s2">&#39;. Only the COO layout (torch.sparse_coo) is currently supported.&quot;</span> <span class="o">%</span> <span class="n">W</span><span class="o">.</span><span class="n">layout</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1105"><a href="#FSWEmbedding.forward-1105"><span class="linenos">1105</span></a>
</span><span id="FSWEmbedding.forward-1106"><a href="#FSWEmbedding.forward-1106"><span class="linenos">1106</span></a>                <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">is_coalesced</span><span class="p">(),</span> <span class="s1">&#39;Sparse W must be coalesced&#39;</span>
</span><span id="FSWEmbedding.forward-1107"><a href="#FSWEmbedding.forward-1107"><span class="linenos">1107</span></a>                <span class="k">assert</span> <span class="n">W</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;W.dense_dim() must be zero&#39;</span>
</span><span id="FSWEmbedding.forward-1108"><a href="#FSWEmbedding.forward-1108"><span class="linenos">1108</span></a>
</span><span id="FSWEmbedding.forward-1109"><a href="#FSWEmbedding.forward-1109"><span class="linenos">1109</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1110"><a href="#FSWEmbedding.forward-1110"><span class="linenos">1110</span></a>                    <span class="n">W_vals</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span><span id="FSWEmbedding.forward-1111"><a href="#FSWEmbedding.forward-1111"><span class="linenos">1111</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1112"><a href="#FSWEmbedding.forward-1112"><span class="linenos">1112</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1113"><a href="#FSWEmbedding.forward-1113"><span class="linenos">1113</span></a>                    <span class="n">W_vals</span> <span class="o">=</span> <span class="n">W</span>
</span><span id="FSWEmbedding.forward-1114"><a href="#FSWEmbedding.forward-1114"><span class="linenos">1114</span></a>
</span><span id="FSWEmbedding.forward-1115"><a href="#FSWEmbedding.forward-1115"><span class="linenos">1115</span></a>            <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1116"><a href="#FSWEmbedding.forward-1116"><span class="linenos">1116</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W_vals</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1117"><a href="#FSWEmbedding.forward-1117"><span class="linenos">1117</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">W_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;W cannot contain NaNs&quot;</span>
</span><span id="FSWEmbedding.forward-1118"><a href="#FSWEmbedding.forward-1118"><span class="linenos">1118</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">W_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;All entries of W must be finite&quot;</span>
</span><span id="FSWEmbedding.forward-1119"><a href="#FSWEmbedding.forward-1119"><span class="linenos">1119</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="n">W_vals</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s2">&quot;All entries of W must be nonnegative&quot;</span>
</span><span id="FSWEmbedding.forward-1120"><a href="#FSWEmbedding.forward-1120"><span class="linenos">1120</span></a>                <span class="k">del</span> <span class="n">W_vals</span>
</span><span id="FSWEmbedding.forward-1121"><a href="#FSWEmbedding.forward-1121"><span class="linenos">1121</span></a>
</span><span id="FSWEmbedding.forward-1122"><a href="#FSWEmbedding.forward-1122"><span class="linenos">1122</span></a>        <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1123"><a href="#FSWEmbedding.forward-1123"><span class="linenos">1123</span></a>            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="s1">&#39;When X_edge is provided, W must be provided explicitly&#39;</span>
</span><span id="FSWEmbedding.forward-1124"><a href="#FSWEmbedding.forward-1124"><span class="linenos">1124</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="p">(</span> <span class="s2">&quot;X_edge is on the wrong device. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1125"><a href="#FSWEmbedding.forward-1125"><span class="linenos">1125</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="p">(</span> <span class="s2">&quot;X_edge has the wrong dtype. Expected </span><span class="si">%s</span><span class="s2">, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1126"><a href="#FSWEmbedding.forward-1126"><span class="linenos">1126</span></a>
</span><span id="FSWEmbedding.forward-1127"><a href="#FSWEmbedding.forward-1127"><span class="linenos">1127</span></a>            <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_sparse</span> <span class="ow">or</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">layout</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1128"><a href="#FSWEmbedding.forward-1128"><span class="linenos">1128</span></a>                <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">layout</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo</span><span class="p">,</span> <span class="p">(</span> <span class="s2">&quot;Sparse X_edge has an unsupported sparsity layout &#39;</span><span class="si">%s</span><span class="s2">&#39;. Only the COO layout (torch.sparse_coo) is currently supported.&quot;</span> <span class="o">%</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">layout</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1129"><a href="#FSWEmbedding.forward-1129"><span class="linenos">1129</span></a>
</span><span id="FSWEmbedding.forward-1130"><a href="#FSWEmbedding.forward-1130"><span class="linenos">1130</span></a>                <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_coalesced</span><span class="p">(),</span> <span class="s1">&#39;Sparse X_edge must be coalesced&#39;</span>
</span><span id="FSWEmbedding.forward-1131"><a href="#FSWEmbedding.forward-1131"><span class="linenos">1131</span></a>                <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;X_edge.dense_dim() must be 1 or 0&#39;</span>
</span><span id="FSWEmbedding.forward-1132"><a href="#FSWEmbedding.forward-1132"><span class="linenos">1132</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;X_edge.dense_dim() must be 1 since d_edge &gt; 1&#39;</span>
</span><span id="FSWEmbedding.forward-1133"><a href="#FSWEmbedding.forward-1133"><span class="linenos">1133</span></a>
</span><span id="FSWEmbedding.forward-1134"><a href="#FSWEmbedding.forward-1134"><span class="linenos">1134</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1135"><a href="#FSWEmbedding.forward-1135"><span class="linenos">1135</span></a>                    <span class="n">X_edge_vals</span> <span class="o">=</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span><span id="FSWEmbedding.forward-1136"><a href="#FSWEmbedding.forward-1136"><span class="linenos">1136</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1137"><a href="#FSWEmbedding.forward-1137"><span class="linenos">1137</span></a>                <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1138"><a href="#FSWEmbedding.forward-1138"><span class="linenos">1138</span></a>                    <span class="n">X_edge_vals</span> <span class="o">=</span> <span class="n">X_edge</span>
</span><span id="FSWEmbedding.forward-1139"><a href="#FSWEmbedding.forward-1139"><span class="linenos">1139</span></a>
</span><span id="FSWEmbedding.forward-1140"><a href="#FSWEmbedding.forward-1140"><span class="linenos">1140</span></a>            <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1141"><a href="#FSWEmbedding.forward-1141"><span class="linenos">1141</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X_edge_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;X_edge_vals cannot contain NaNs&quot;</span>
</span><span id="FSWEmbedding.forward-1142"><a href="#FSWEmbedding.forward-1142"><span class="linenos">1142</span></a>                <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">X_edge_vals</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(),</span> <span class="s2">&quot;All entries of X_edge_vals must be finite&quot;</span>
</span><span id="FSWEmbedding.forward-1143"><a href="#FSWEmbedding.forward-1143"><span class="linenos">1143</span></a>                <span class="k">del</span> <span class="n">X_edge_vals</span>
</span><span id="FSWEmbedding.forward-1144"><a href="#FSWEmbedding.forward-1144"><span class="linenos">1144</span></a>
</span><span id="FSWEmbedding.forward-1145"><a href="#FSWEmbedding.forward-1145"><span class="linenos">1145</span></a>            <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_sparse</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">,</span> <span class="s1">&#39;X_edge and W must either both or neither be sparse&#39;</span>
</span><span id="FSWEmbedding.forward-1146"><a href="#FSWEmbedding.forward-1146"><span class="linenos">1146</span></a>
</span><span id="FSWEmbedding.forward-1147"><a href="#FSWEmbedding.forward-1147"><span class="linenos">1147</span></a>
</span><span id="FSWEmbedding.forward-1148"><a href="#FSWEmbedding.forward-1148"><span class="linenos">1148</span></a>        <span class="c1">### B. Verify input sizes</span>
</span><span id="FSWEmbedding.forward-1149"><a href="#FSWEmbedding.forward-1149"><span class="linenos">1149</span></a>
</span><span id="FSWEmbedding.forward-1150"><a href="#FSWEmbedding.forward-1150"><span class="linenos">1150</span></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;X must be a tensor of order at least 2&quot;</span>
</span><span id="FSWEmbedding.forward-1151"><a href="#FSWEmbedding.forward-1151"><span class="linenos">1151</span></a>        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">,</span> <span class="s2">&quot;The last dimension of X must equal d_in=</span><span class="si">%d</span><span class="s2">. Instead got </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_in</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="FSWEmbedding.forward-1152"><a href="#FSWEmbedding.forward-1152"><span class="linenos">1152</span></a>
</span><span id="FSWEmbedding.forward-1153"><a href="#FSWEmbedding.forward-1153"><span class="linenos">1153</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="n">graph_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1154"><a href="#FSWEmbedding.forward-1154"><span class="linenos">1154</span></a>            <span class="c1"># batch_dims contains everything that precedes (n,d_in) in X.shape</span>
</span><span id="FSWEmbedding.forward-1155"><a href="#FSWEmbedding.forward-1155"><span class="linenos">1155</span></a>            <span class="n">batch_dims</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="FSWEmbedding.forward-1156"><a href="#FSWEmbedding.forward-1156"><span class="linenos">1156</span></a>            <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)]</span>
</span><span id="FSWEmbedding.forward-1157"><a href="#FSWEmbedding.forward-1157"><span class="linenos">1157</span></a>
</span><span id="FSWEmbedding.forward-1158"><a href="#FSWEmbedding.forward-1158"><span class="linenos">1158</span></a>            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">):</span>
</span><span id="FSWEmbedding.forward-1159"><a href="#FSWEmbedding.forward-1159"><span class="linenos">1159</span></a>                <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]):</span>
</span><span id="FSWEmbedding.forward-1160"><a href="#FSWEmbedding.forward-1160"><span class="linenos">1160</span></a>                    <span class="n">err_str</span> <span class="o">=</span> <span class="s2">&quot;Shape mismatch between X and W: If X.shape = (b1,b2,...,bk,n,d_in) then W.shape should be (b1,b2,...,bk,n) (Perhaps missing argument graph_mode=True?)&quot;</span>
</span><span id="FSWEmbedding.forward-1161"><a href="#FSWEmbedding.forward-1161"><span class="linenos">1161</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1162"><a href="#FSWEmbedding.forward-1162"><span class="linenos">1162</span></a>                    <span class="n">err_str</span> <span class="o">=</span> <span class="s2">&quot;Shape mismatch between X and W: If X.shape = (b1,b2,...,bk,n,d_in) then W.shape should be (b1,b2,...,bk,n) (unless graph_mode=True)&quot;</span>
</span><span id="FSWEmbedding.forward-1163"><a href="#FSWEmbedding.forward-1163"><span class="linenos">1163</span></a>
</span><span id="FSWEmbedding.forward-1164"><a href="#FSWEmbedding.forward-1164"><span class="linenos">1164</span></a>                <span class="k">assert</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">err_str</span>
</span><span id="FSWEmbedding.forward-1165"><a href="#FSWEmbedding.forward-1165"><span class="linenos">1165</span></a>
</span><span id="FSWEmbedding.forward-1166"><a href="#FSWEmbedding.forward-1166"><span class="linenos">1166</span></a>            <span class="k">elif</span> <span class="n">W</span> <span class="o">==</span> <span class="s1">&#39;unit&#39;</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1167"><a href="#FSWEmbedding.forward-1167"><span class="linenos">1167</span></a>                <span class="c1"># Initialize with unit weights</span>
</span><span id="FSWEmbedding.forward-1168"><a href="#FSWEmbedding.forward-1168"><span class="linenos">1168</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1169"><a href="#FSWEmbedding.forward-1169"><span class="linenos">1169</span></a>
</span><span id="FSWEmbedding.forward-1170"><a href="#FSWEmbedding.forward-1170"><span class="linenos">1170</span></a>            <span class="k">elif</span> <span class="n">W</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1171"><a href="#FSWEmbedding.forward-1171"><span class="linenos">1171</span></a>                <span class="c1"># Initialize with uniform weights</span>
</span><span id="FSWEmbedding.forward-1172"><a href="#FSWEmbedding.forward-1172"><span class="linenos">1172</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="mf">1.0</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1173"><a href="#FSWEmbedding.forward-1173"><span class="linenos">1173</span></a>
</span><span id="FSWEmbedding.forward-1174"><a href="#FSWEmbedding.forward-1174"><span class="linenos">1174</span></a>        <span class="k">elif</span> <span class="n">graph_mode</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1175"><a href="#FSWEmbedding.forward-1175"><span class="linenos">1175</span></a>            <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="s1">&#39;W must be explicitly provided when graph_mode=True&#39;</span>
</span><span id="FSWEmbedding.forward-1176"><a href="#FSWEmbedding.forward-1176"><span class="linenos">1176</span></a>
</span><span id="FSWEmbedding.forward-1177"><a href="#FSWEmbedding.forward-1177"><span class="linenos">1177</span></a>            <span class="c1"># batch_dims contains everything that precedes (nRecipients, n) in W.shape</span>
</span><span id="FSWEmbedding.forward-1178"><a href="#FSWEmbedding.forward-1178"><span class="linenos">1178</span></a>            <span class="n">batch_dims</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
</span><span id="FSWEmbedding.forward-1179"><a href="#FSWEmbedding.forward-1179"><span class="linenos">1179</span></a>            <span class="n">nRecipients</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</span><span id="FSWEmbedding.forward-1180"><a href="#FSWEmbedding.forward-1180"><span class="linenos">1180</span></a>            <span class="c1">#n = W.shape[-1]</span>
</span><span id="FSWEmbedding.forward-1181"><a href="#FSWEmbedding.forward-1181"><span class="linenos">1181</span></a>
</span><span id="FSWEmbedding.forward-1182"><a href="#FSWEmbedding.forward-1182"><span class="linenos">1182</span></a>            <span class="k">assert</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="ow">and</span> <span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span> <span class="s2">&quot;Shape mismatch between X and W: When graph_mode=True, if W.shape = (b1,b2,...,bk,nRecipients,n) then X.shape should be (b1,b2,...,bk,n,d_in)&quot;</span>
</span><span id="FSWEmbedding.forward-1183"><a href="#FSWEmbedding.forward-1183"><span class="linenos">1183</span></a>
</span><span id="FSWEmbedding.forward-1184"><a href="#FSWEmbedding.forward-1184"><span class="linenos">1184</span></a>            <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1185"><a href="#FSWEmbedding.forward-1185"><span class="linenos">1185</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_edge</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="c1"># For PyCharm to know</span>
</span><span id="FSWEmbedding.forward-1186"><a href="#FSWEmbedding.forward-1186"><span class="linenos">1186</span></a>
</span><span id="FSWEmbedding.forward-1187"><a href="#FSWEmbedding.forward-1187"><span class="linenos">1187</span></a>                <span class="c1"># Verify that X_edge has the right shape and is compatible with W</span>
</span><span id="FSWEmbedding.forward-1188"><a href="#FSWEmbedding.forward-1188"><span class="linenos">1188</span></a>                <span class="k">assert</span> <span class="p">(((</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="ow">or</span>
</span><span id="FSWEmbedding.forward-1189"><a href="#FSWEmbedding.forward-1189"><span class="linenos">1189</span></a>                        <span class="p">((</span><span class="n">X_edge</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">))),</span> <span class="p">(</span>
</span><span id="FSWEmbedding.forward-1190"><a href="#FSWEmbedding.forward-1190"><span class="linenos">1190</span></a>                    <span class="s2">&quot;Shape mismatch between X_edge and W: if W.shape = (b1,b2,...,bk,nRecipients,n) then X.shape should be (b1,b2,...,bk,nRecipients,n,d_edge) (with the possible exception (b1,b2,...,bk,nRecipients,n) when d_edge=1&quot;</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1191"><a href="#FSWEmbedding.forward-1191"><span class="linenos">1191</span></a>
</span><span id="FSWEmbedding.forward-1192"><a href="#FSWEmbedding.forward-1192"><span class="linenos">1192</span></a>                <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1193"><a href="#FSWEmbedding.forward-1193"><span class="linenos">1193</span></a>                    <span class="k">assert</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">values</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">values</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;Sparse X_edge must have the same number of values() as W&#39;</span>
</span><span id="FSWEmbedding.forward-1194"><a href="#FSWEmbedding.forward-1194"><span class="linenos">1194</span></a>                    <span class="k">if</span> <span class="n">fsw_embedding_basic_safety_checks</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1195"><a href="#FSWEmbedding.forward-1195"><span class="linenos">1195</span></a>                        <span class="k">assert</span> <span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">indices</span><span class="p">()</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">indices</span><span class="p">())</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s1">&#39;Sparse X_edge must have the same nonzero pattern as W&#39;</span>
</span><span id="FSWEmbedding.forward-1196"><a href="#FSWEmbedding.forward-1196"><span class="linenos">1196</span></a>
</span><span id="FSWEmbedding.forward-1197"><a href="#FSWEmbedding.forward-1197"><span class="linenos">1197</span></a>                    <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">()</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1198"><a href="#FSWEmbedding.forward-1198"><span class="linenos">1198</span></a>                        <span class="n">X_edge</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">unsqueeze_dense_dim</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">X_edge</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1199"><a href="#FSWEmbedding.forward-1199"><span class="linenos">1199</span></a>
</span><span id="FSWEmbedding.forward-1200"><a href="#FSWEmbedding.forward-1200"><span class="linenos">1200</span></a>
</span><span id="FSWEmbedding.forward-1201"><a href="#FSWEmbedding.forward-1201"><span class="linenos">1201</span></a>        <span class="c1">### C. Precalculate axis indices and output shape</span>
</span><span id="FSWEmbedding.forward-1202"><a href="#FSWEmbedding.forward-1202"><span class="linenos">1202</span></a>
</span><span id="FSWEmbedding.forward-1203"><a href="#FSWEmbedding.forward-1203"><span class="linenos">1203</span></a>        <span class="c1"># These are the different axes we use to store data for processing. These definitions are repeated in forward_helper()</span>
</span><span id="FSWEmbedding.forward-1204"><a href="#FSWEmbedding.forward-1204"><span class="linenos">1204</span></a>        <span class="c1"># element_axis corresponds to the index of the multiset elements</span>
</span><span id="FSWEmbedding.forward-1205"><a href="#FSWEmbedding.forward-1205"><span class="linenos">1205</span></a>        <span class="c1"># ambspace_axis corresponds to the elements&#39; coordinate index in the ambient space R^d_in</span>
</span><span id="FSWEmbedding.forward-1206"><a href="#FSWEmbedding.forward-1206"><span class="linenos">1206</span></a>        <span class="c1"># After projection, the ambient space coordinates are replaced by the slice number; thus slice_axis=ambspace_axis</span>
</span><span id="FSWEmbedding.forward-1207"><a href="#FSWEmbedding.forward-1207"><span class="linenos">1207</span></a>        <span class="c1"># If we&#39;re in Cartesian mode, the frequencies have their own axis freq_axis, otherwise it is the same axis as slice_axis.</span>
</span><span id="FSWEmbedding.forward-1208"><a href="#FSWEmbedding.forward-1208"><span class="linenos">1208</span></a>        <span class="n">recipient_axis</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="kc">None</span>  <span class="c1"># Message-recipient vertices</span>
</span><span id="FSWEmbedding.forward-1209"><a href="#FSWEmbedding.forward-1209"><span class="linenos">1209</span></a>        <span class="n">element_axis</span>  <span class="o">=</span> <span class="n">recipient_axis</span><span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">)</span> <span class="c1"># In graph mode this axis denotes the message-sender vertices</span>
</span><span id="FSWEmbedding.forward-1210"><a href="#FSWEmbedding.forward-1210"><span class="linenos">1210</span></a>        <span class="n">ambspace_axis</span> <span class="o">=</span> <span class="n">element_axis</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="FSWEmbedding.forward-1211"><a href="#FSWEmbedding.forward-1211"><span class="linenos">1211</span></a>        <span class="n">slice_axis</span>     <span class="o">=</span> <span class="n">ambspace_axis</span>
</span><span id="FSWEmbedding.forward-1212"><a href="#FSWEmbedding.forward-1212"><span class="linenos">1212</span></a>        <span class="c1"># noinspection PyUnusedLocal</span>
</span><span id="FSWEmbedding.forward-1213"><a href="#FSWEmbedding.forward-1213"><span class="linenos">1213</span></a>        <span class="n">freq_axis</span>     <span class="o">=</span> <span class="n">slice_axis</span> <span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="k">else</span> <span class="n">slice_axis</span>
</span><span id="FSWEmbedding.forward-1214"><a href="#FSWEmbedding.forward-1214"><span class="linenos">1214</span></a>        <span class="n">output_slice_axis</span> <span class="o">=</span> <span class="n">element_axis</span> <span class="c1"># In the output, the element axis is replaced by the slice axis</span>
</span><span id="FSWEmbedding.forward-1215"><a href="#FSWEmbedding.forward-1215"><span class="linenos">1215</span></a>
</span><span id="FSWEmbedding.forward-1216"><a href="#FSWEmbedding.forward-1216"><span class="linenos">1216</span></a>        <span class="n">output_shape_before_collapse_and_totmass_augmentation</span> <span class="o">=</span>  <span class="n">batch_dims</span> <span class="o">+</span> <span class="p">(</span><span class="n">nRecipients</span><span class="p">,)</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="n">batch_dims</span>
</span><span id="FSWEmbedding.forward-1217"><a href="#FSWEmbedding.forward-1217"><span class="linenos">1217</span></a>        <span class="n">output_shape_before_collapse_and_totmass_augmentation</span> <span class="o">+=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_frequencies</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,)</span>
</span><span id="FSWEmbedding.forward-1218"><a href="#FSWEmbedding.forward-1218"><span class="linenos">1218</span></a>
</span><span id="FSWEmbedding.forward-1219"><a href="#FSWEmbedding.forward-1219"><span class="linenos">1219</span></a>        <span class="c1">### D. Input is ok. Start working.</span>
</span><span id="FSWEmbedding.forward-1220"><a href="#FSWEmbedding.forward-1220"><span class="linenos">1220</span></a>
</span><span id="FSWEmbedding.forward-1221"><a href="#FSWEmbedding.forward-1221"><span class="linenos">1221</span></a>        <span class="c1"># Calculate W_sum, which contains the total mass of the input measures</span>
</span><span id="FSWEmbedding.forward-1222"><a href="#FSWEmbedding.forward-1222"><span class="linenos">1222</span></a>        <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1223"><a href="#FSWEmbedding.forward-1223"><span class="linenos">1223</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1224"><a href="#FSWEmbedding.forward-1224"><span class="linenos">1224</span></a>            <span class="n">slice_info_W</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_slice_info</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">calc_nnz_per_slice</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1225"><a href="#FSWEmbedding.forward-1225"><span class="linenos">1225</span></a>                                             <span class="n">use_custom_cuda_extension_if_available</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span> <span class="n">fail_if_cuda_extension_load_fails</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1226"><a href="#FSWEmbedding.forward-1226"><span class="linenos">1226</span></a>            <span class="n">W_sum</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">sum_sparseToDense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">slice_info_W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1227"><a href="#FSWEmbedding.forward-1227"><span class="linenos">1227</span></a>
</span><span id="FSWEmbedding.forward-1228"><a href="#FSWEmbedding.forward-1228"><span class="linenos">1228</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1229"><a href="#FSWEmbedding.forward-1229"><span class="linenos">1229</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1230"><a href="#FSWEmbedding.forward-1230"><span class="linenos">1230</span></a>            <span class="n">W_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1231"><a href="#FSWEmbedding.forward-1231"><span class="linenos">1231</span></a>
</span><span id="FSWEmbedding.forward-1232"><a href="#FSWEmbedding.forward-1232"><span class="linenos">1232</span></a>        <span class="c1"># Total-mass deficit to be compensated for by padding</span>
</span><span id="FSWEmbedding.forward-1233"><a href="#FSWEmbedding.forward-1233"><span class="linenos">1233</span></a>        <span class="n">W_pad</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">custom_lowclamp</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span> <span class="o">-</span> <span class="n">W_sum</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1234"><a href="#FSWEmbedding.forward-1234"><span class="linenos">1234</span></a>
</span><span id="FSWEmbedding.forward-1235"><a href="#FSWEmbedding.forward-1235"><span class="linenos">1235</span></a>        <span class="c1"># Detect weight deficit and augment W and X accordingly</span>
</span><span id="FSWEmbedding.forward-1236"><a href="#FSWEmbedding.forward-1236"><span class="linenos">1236</span></a>        <span class="k">if</span> <span class="p">(</span><span class="n">W_pad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
</span><span id="FSWEmbedding.forward-1237"><a href="#FSWEmbedding.forward-1237"><span class="linenos">1237</span></a>            <span class="n">zshape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1238"><a href="#FSWEmbedding.forward-1238"><span class="linenos">1238</span></a>            <span class="n">zshape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="FSWEmbedding.forward-1239"><a href="#FSWEmbedding.forward-1239"><span class="linenos">1239</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zshape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1240"><a href="#FSWEmbedding.forward-1240"><span class="linenos">1240</span></a>
</span><span id="FSWEmbedding.forward-1241"><a href="#FSWEmbedding.forward-1241"><span class="linenos">1241</span></a>            <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1242"><a href="#FSWEmbedding.forward-1242"><span class="linenos">1242</span></a>                <span class="c1"># Make sure this works</span>
</span><span id="FSWEmbedding.forward-1243"><a href="#FSWEmbedding.forward-1243"><span class="linenos">1243</span></a>                <span class="n">W_pad</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">to_sparse_full</span><span class="p">(</span><span class="n">W_pad</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1244"><a href="#FSWEmbedding.forward-1244"><span class="linenos">1244</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">concat_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_pad</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1245"><a href="#FSWEmbedding.forward-1245"><span class="linenos">1245</span></a>                <span class="n">slice_info_W</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">get_slice_info</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">calc_nnz_per_slice</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1246"><a href="#FSWEmbedding.forward-1246"><span class="linenos">1246</span></a>                                                 <span class="n">use_custom_cuda_extension_if_available</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span> <span class="n">fail_if_cuda_extension_load_fails</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1247"><a href="#FSWEmbedding.forward-1247"><span class="linenos">1247</span></a>
</span><span id="FSWEmbedding.forward-1248"><a href="#FSWEmbedding.forward-1248"><span class="linenos">1248</span></a>                <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1249"><a href="#FSWEmbedding.forward-1249"><span class="linenos">1249</span></a>                    <span class="n">X_edge_pad_inds</span> <span class="o">=</span> <span class="n">W_pad</span><span class="o">.</span><span class="n">indices</span><span class="p">()</span>
</span><span id="FSWEmbedding.forward-1250"><a href="#FSWEmbedding.forward-1250"><span class="linenos">1250</span></a>                    <span class="n">X_edge_pad_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nRecipients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1251"><a href="#FSWEmbedding.forward-1251"><span class="linenos">1251</span></a>                    <span class="n">X_edge_pad_shape</span> <span class="o">=</span> <span class="n">replace_in_tuple</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">X_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1252"><a href="#FSWEmbedding.forward-1252"><span class="linenos">1252</span></a>
</span><span id="FSWEmbedding.forward-1253"><a href="#FSWEmbedding.forward-1253"><span class="linenos">1253</span></a>                    <span class="n">X_edge_pad</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">sparse_coo_tensor_coalesced</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">X_edge_pad_inds</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">X_edge_pad_vals</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">X_edge_pad_shape</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1254"><a href="#FSWEmbedding.forward-1254"><span class="linenos">1254</span></a>                    <span class="n">X_edge</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">concat_sparse</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">X_edge</span><span class="p">,</span> <span class="n">X_edge_pad</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1255"><a href="#FSWEmbedding.forward-1255"><span class="linenos">1255</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1256"><a href="#FSWEmbedding.forward-1256"><span class="linenos">1256</span></a>                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1257"><a href="#FSWEmbedding.forward-1257"><span class="linenos">1257</span></a>                <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_pad</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1258"><a href="#FSWEmbedding.forward-1258"><span class="linenos">1258</span></a>                <span class="k">if</span> <span class="n">X_edge</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1259"><a href="#FSWEmbedding.forward-1259"><span class="linenos">1259</span></a>                    <span class="n">zshape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">+</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_d_edge</span><span class="p">,</span> <span class="p">]</span>
</span><span id="FSWEmbedding.forward-1260"><a href="#FSWEmbedding.forward-1260"><span class="linenos">1260</span></a>                    <span class="n">zshape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="FSWEmbedding.forward-1261"><a href="#FSWEmbedding.forward-1261"><span class="linenos">1261</span></a>                    <span class="k">if</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">dim</span><span class="p">():</span>
</span><span id="FSWEmbedding.forward-1262"><a href="#FSWEmbedding.forward-1262"><span class="linenos">1262</span></a>                        <span class="n">X_edge</span> <span class="o">=</span> <span class="n">X_edge</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1263"><a href="#FSWEmbedding.forward-1263"><span class="linenos">1263</span></a>                    <span class="n">X_edge</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">X_edge</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">zshape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1264"><a href="#FSWEmbedding.forward-1264"><span class="linenos">1264</span></a>
</span><span id="FSWEmbedding.forward-1265"><a href="#FSWEmbedding.forward-1265"><span class="linenos">1265</span></a>            <span class="n">W_sum_padded</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">custom_lowclamp</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W_sum</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_padding_thresh</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1266"><a href="#FSWEmbedding.forward-1266"><span class="linenos">1266</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1267"><a href="#FSWEmbedding.forward-1267"><span class="linenos">1267</span></a>            <span class="n">W_sum_padded</span> <span class="o">=</span> <span class="n">W_sum</span>
</span><span id="FSWEmbedding.forward-1268"><a href="#FSWEmbedding.forward-1268"><span class="linenos">1268</span></a>
</span><span id="FSWEmbedding.forward-1269"><a href="#FSWEmbedding.forward-1269"><span class="linenos">1269</span></a>        <span class="k">del</span> <span class="n">W_pad</span>
</span><span id="FSWEmbedding.forward-1270"><a href="#FSWEmbedding.forward-1270"><span class="linenos">1270</span></a>
</span><span id="FSWEmbedding.forward-1271"><a href="#FSWEmbedding.forward-1271"><span class="linenos">1271</span></a>        <span class="c1"># Normalize W according to W_sum_padded</span>
</span><span id="FSWEmbedding.forward-1272"><a href="#FSWEmbedding.forward-1272"><span class="linenos">1272</span></a>        <span class="k">if</span> <span class="n">W</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1273"><a href="#FSWEmbedding.forward-1273"><span class="linenos">1273</span></a>            <span class="n">W</span> <span class="o">=</span> <span class="n">ag</span><span class="o">.</span><span class="n">div_sparse_dense</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_sum_padded</span><span class="p">,</span> <span class="n">slice_info_W</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1274"><a href="#FSWEmbedding.forward-1274"><span class="linenos">1274</span></a>                                          <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1275"><a href="#FSWEmbedding.forward-1275"><span class="linenos">1275</span></a>                                          <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1276"><a href="#FSWEmbedding.forward-1276"><span class="linenos">1276</span></a>            <span class="k">del</span> <span class="n">slice_info_W</span><span class="p">,</span> <span class="n">W_sum_padded</span>
</span><span id="FSWEmbedding.forward-1277"><a href="#FSWEmbedding.forward-1277"><span class="linenos">1277</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1278"><a href="#FSWEmbedding.forward-1278"><span class="linenos">1278</span></a>            <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">/</span> <span class="n">W_sum_padded</span>
</span><span id="FSWEmbedding.forward-1279"><a href="#FSWEmbedding.forward-1279"><span class="linenos">1279</span></a>            <span class="k">del</span> <span class="n">W_sum_padded</span>
</span><span id="FSWEmbedding.forward-1280"><a href="#FSWEmbedding.forward-1280"><span class="linenos">1280</span></a>
</span><span id="FSWEmbedding.forward-1281"><a href="#FSWEmbedding.forward-1281"><span class="linenos">1281</span></a>        <span class="c1"># For compatibility reasons, we support the case of zero-dimensional output tensor</span>
</span><span id="FSWEmbedding.forward-1282"><a href="#FSWEmbedding.forward-1282"><span class="linenos">1282</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_d_out</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1283"><a href="#FSWEmbedding.forward-1283"><span class="linenos">1283</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">output_shape_before_collapse_and_totmass_augmentation</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1284"><a href="#FSWEmbedding.forward-1284"><span class="linenos">1284</span></a>
</span><span id="FSWEmbedding.forward-1285"><a href="#FSWEmbedding.forward-1285"><span class="linenos">1285</span></a>        <span class="k">elif</span> <span class="p">(</span><span class="n">max_parallel_slices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">max_parallel_slices</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">):</span>
</span><span id="FSWEmbedding.forward-1286"><a href="#FSWEmbedding.forward-1286"><span class="linenos">1286</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_forward_helper</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">graph_mode</span><span class="p">,</span> <span class="n">X_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1287"><a href="#FSWEmbedding.forward-1287"><span class="linenos">1287</span></a>                                                 <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1288"><a href="#FSWEmbedding.forward-1288"><span class="linenos">1288</span></a>                                                 <span class="n">fail_if_cuda_extension_load_fails</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1289"><a href="#FSWEmbedding.forward-1289"><span class="linenos">1289</span></a>
</span><span id="FSWEmbedding.forward-1290"><a href="#FSWEmbedding.forward-1290"><span class="linenos">1290</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1291"><a href="#FSWEmbedding.forward-1291"><span class="linenos">1291</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">max_parallel_slices</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">max_parallel_slices</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;max_parallel_slices must be None or a positive integer&#39;</span>
</span><span id="FSWEmbedding.forward-1292"><a href="#FSWEmbedding.forward-1292"><span class="linenos">1292</span></a>
</span><span id="FSWEmbedding.forward-1293"><a href="#FSWEmbedding.forward-1293"><span class="linenos">1293</span></a>            <span class="n">nIter</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">//</span> <span class="n">max_parallel_slices</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">%</span> <span class="n">max_parallel_slices</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span> <span class="o">//</span> <span class="n">max_parallel_slices</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1294"><a href="#FSWEmbedding.forward-1294"><span class="linenos">1294</span></a>
</span><span id="FSWEmbedding.forward-1295"><a href="#FSWEmbedding.forward-1295"><span class="linenos">1295</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">output_shape_before_collapse_and_totmass_augmentation</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1296"><a href="#FSWEmbedding.forward-1296"><span class="linenos">1296</span></a>
</span><span id="FSWEmbedding.forward-1297"><a href="#FSWEmbedding.forward-1297"><span class="linenos">1297</span></a>            <span class="k">for</span> <span class="n">iIter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
</span><span id="FSWEmbedding.forward-1298"><a href="#FSWEmbedding.forward-1298"><span class="linenos">1298</span></a>                <span class="n">inds_curr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">iIter</span> <span class="o">*</span> <span class="n">max_parallel_slices</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_slices</span><span class="p">,</span> <span class="p">(</span><span class="n">iIter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_parallel_slices</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1299"><a href="#FSWEmbedding.forward-1299"><span class="linenos">1299</span></a>                <span class="n">slice_vecs_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slice_vectors</span><span class="p">[</span><span class="n">inds_curr</span><span class="p">,</span> <span class="p">:]</span>
</span><span id="FSWEmbedding.forward-1300"><a href="#FSWEmbedding.forward-1300"><span class="linenos">1300</span></a>                <span class="n">freqs_curr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">frequencies</span><span class="p">[</span><span class="n">inds_curr</span><span class="p">]</span>
</span><span id="FSWEmbedding.forward-1301"><a href="#FSWEmbedding.forward-1301"><span class="linenos">1301</span></a>
</span><span id="FSWEmbedding.forward-1302"><a href="#FSWEmbedding.forward-1302"><span class="linenos">1302</span></a>                <span class="n">out_curr</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_forward_helper</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">slice_vecs_curr</span><span class="p">,</span> <span class="n">freqs_curr</span><span class="p">,</span> <span class="n">graph_mode</span><span class="p">,</span> <span class="n">X_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1303"><a href="#FSWEmbedding.forward-1303"><span class="linenos">1303</span></a>                                                        <span class="n">use_custom_cuda_extension_if_available</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_custom_cuda_extension_if_available</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1304"><a href="#FSWEmbedding.forward-1304"><span class="linenos">1304</span></a>                                                        <span class="n">fail_if_cuda_extension_load_fails</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fail_if_cuda_extension_load_fails</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1305"><a href="#FSWEmbedding.forward-1305"><span class="linenos">1305</span></a>
</span><span id="FSWEmbedding.forward-1306"><a href="#FSWEmbedding.forward-1306"><span class="linenos">1306</span></a>                <span class="n">assign_at</span><span class="p">(</span><span class="n">X_emb</span><span class="p">,</span> <span class="n">out_curr</span><span class="p">,</span> <span class="n">output_slice_axis</span><span class="p">,</span> <span class="n">inds_curr</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1307"><a href="#FSWEmbedding.forward-1307"><span class="linenos">1307</span></a>
</span><span id="FSWEmbedding.forward-1308"><a href="#FSWEmbedding.forward-1308"><span class="linenos">1308</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cartesian_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_cartesian_axes</span> <span class="p">:</span>
</span><span id="FSWEmbedding.forward-1309"><a href="#FSWEmbedding.forward-1309"><span class="linenos">1309</span></a>            <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">X_emb</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="n">element_axis</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=</span><span class="n">element_axis</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1310"><a href="#FSWEmbedding.forward-1310"><span class="linenos">1310</span></a>
</span><span id="FSWEmbedding.forward-1311"><a href="#FSWEmbedding.forward-1311"><span class="linenos">1311</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode_total_mass</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1312"><a href="#FSWEmbedding.forward-1312"><span class="linenos">1312</span></a>            <span class="k">match</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1313"><a href="#FSWEmbedding.forward-1313"><span class="linenos">1313</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">IDENTITY</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1314"><a href="#FSWEmbedding.forward-1314"><span class="linenos">1314</span></a>                    <span class="n">encoded_total_mass</span> <span class="o">=</span> <span class="n">W_sum</span>
</span><span id="FSWEmbedding.forward-1315"><a href="#FSWEmbedding.forward-1315"><span class="linenos">1315</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">SQRT</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1316"><a href="#FSWEmbedding.forward-1316"><span class="linenos">1316</span></a>                    <span class="c1"># x/(sqrt(x+1)+1) is a numerically-safe formulation of sqrt(1+x)-1</span>
</span><span id="FSWEmbedding.forward-1317"><a href="#FSWEmbedding.forward-1317"><span class="linenos">1317</span></a>                    <span class="c1"># note that we don&#39;t use sqrt(1+x) since we need the function to vanish at x=0,</span>
</span><span id="FSWEmbedding.forward-1318"><a href="#FSWEmbedding.forward-1318"><span class="linenos">1318</span></a>                    <span class="c1"># and we don&#39;t use sqrt(x) since we need it to have a gradient at x=0.</span>
</span><span id="FSWEmbedding.forward-1319"><a href="#FSWEmbedding.forward-1319"><span class="linenos">1319</span></a>                    <span class="n">encoded_total_mass</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span> <span class="n">W_sum</span> <span class="o">/</span> <span class="p">(</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">W_sum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FSWEmbedding.forward-1320"><a href="#FSWEmbedding.forward-1320"><span class="linenos">1320</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingTransformation</span><span class="o">.</span><span class="n">LOG</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1321"><a href="#FSWEmbedding.forward-1321"><span class="linenos">1321</span></a>                    <span class="n">encoded_total_mass</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">W_sum</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1322"><a href="#FSWEmbedding.forward-1322"><span class="linenos">1322</span></a>                <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1323"><a href="#FSWEmbedding.forward-1323"><span class="linenos">1323</span></a>                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported encoding function: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_transformation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1324"><a href="#FSWEmbedding.forward-1324"><span class="linenos">1324</span></a>
</span><span id="FSWEmbedding.forward-1325"><a href="#FSWEmbedding.forward-1325"><span class="linenos">1325</span></a>            <span class="n">encoded_total_mass</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_scale</span>
</span><span id="FSWEmbedding.forward-1326"><a href="#FSWEmbedding.forward-1326"><span class="linenos">1326</span></a>
</span><span id="FSWEmbedding.forward-1327"><a href="#FSWEmbedding.forward-1327"><span class="linenos">1327</span></a>            <span class="k">del</span> <span class="n">W_sum</span>
</span><span id="FSWEmbedding.forward-1328"><a href="#FSWEmbedding.forward-1328"><span class="linenos">1328</span></a>
</span><span id="FSWEmbedding.forward-1329"><a href="#FSWEmbedding.forward-1329"><span class="linenos">1329</span></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="c1"># to silence PyCharm</span>
</span><span id="FSWEmbedding.forward-1330"><a href="#FSWEmbedding.forward-1330"><span class="linenos">1330</span></a>
</span><span id="FSWEmbedding.forward-1331"><a href="#FSWEmbedding.forward-1331"><span class="linenos">1331</span></a>            <span class="n">needs_emb_norm</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span> <span class="ow">in</span>
</span><span id="FSWEmbedding.forward-1332"><a href="#FSWEmbedding.forward-1332"><span class="linenos">1332</span></a>                              <span class="p">{</span><span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1333"><a href="#FSWEmbedding.forward-1333"><span class="linenos">1333</span></a>                               <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_SCALED</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1334"><a href="#FSWEmbedding.forward-1334"><span class="linenos">1334</span></a>                               <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_LEGACY</span><span class="p">})</span>
</span><span id="FSWEmbedding.forward-1335"><a href="#FSWEmbedding.forward-1335"><span class="linenos">1335</span></a>
</span><span id="FSWEmbedding.forward-1336"><a href="#FSWEmbedding.forward-1336"><span class="linenos">1336</span></a>            <span class="k">if</span> <span class="n">needs_emb_norm</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1337"><a href="#FSWEmbedding.forward-1337"><span class="linenos">1337</span></a>                <span class="n">X_emb_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X_emb</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">X_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1338"><a href="#FSWEmbedding.forward-1338"><span class="linenos">1338</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1339"><a href="#FSWEmbedding.forward-1339"><span class="linenos">1339</span></a>                <span class="n">X_emb_norm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="FSWEmbedding.forward-1340"><a href="#FSWEmbedding.forward-1340"><span class="linenos">1340</span></a>
</span><span id="FSWEmbedding.forward-1341"><a href="#FSWEmbedding.forward-1341"><span class="linenos">1341</span></a>            <span class="k">match</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1342"><a href="#FSWEmbedding.forward-1342"><span class="linenos">1342</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">DECOUPLED</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1343"><a href="#FSWEmbedding.forward-1343"><span class="linenos">1343</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">,</span> <span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1344"><a href="#FSWEmbedding.forward-1344"><span class="linenos">1344</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">SCALED</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1345"><a href="#FSWEmbedding.forward-1345"><span class="linenos">1345</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">,</span> <span class="n">encoded_total_mass</span><span class="o">*</span><span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1346"><a href="#FSWEmbedding.forward-1346"><span class="linenos">1346</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1347"><a href="#FSWEmbedding.forward-1347"><span class="linenos">1347</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">encoded_total_mass</span> <span class="o">*</span> <span class="n">X_emb_norm</span><span class="p">,</span> <span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1348"><a href="#FSWEmbedding.forward-1348"><span class="linenos">1348</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_SCALED</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1349"><a href="#FSWEmbedding.forward-1349"><span class="linenos">1349</span></a>                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_emb_norm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="c1"># to silence PyCharm</span>
</span><span id="FSWEmbedding.forward-1350"><a href="#FSWEmbedding.forward-1350"><span class="linenos">1350</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">X_emb_norm</span><span class="p">,</span> <span class="n">encoded_total_mass</span><span class="o">*</span><span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1351"><a href="#FSWEmbedding.forward-1351"><span class="linenos">1351</span></a>                <span class="k">case</span> <span class="n">TotalMassEncodingMethod</span><span class="o">.</span><span class="n">HOMOGENEOUS_LEGACY</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1352"><a href="#FSWEmbedding.forward-1352"><span class="linenos">1352</span></a>                    <span class="n">X_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_total_mass_homogeneous_legacy_encoding_part1</span><span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">)</span> <span class="o">*</span> <span class="n">X_emb_norm</span><span class="p">,</span>
</span><span id="FSWEmbedding.forward-1353"><a href="#FSWEmbedding.forward-1353"><span class="linenos">1353</span></a>                                       <span class="n">FSWEmbedding</span><span class="o">.</span><span class="n">_total_mass_homogeneous_legacy_encoding_part2</span><span class="p">(</span><span class="n">encoded_total_mass</span><span class="p">)</span> <span class="o">*</span> <span class="n">X_emb</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1354"><a href="#FSWEmbedding.forward-1354"><span class="linenos">1354</span></a>                <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>  <span class="c1"># fallback</span>
</span><span id="FSWEmbedding.forward-1355"><a href="#FSWEmbedding.forward-1355"><span class="linenos">1355</span></a>                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported encoding method: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_mass_encoding_method</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="FSWEmbedding.forward-1356"><a href="#FSWEmbedding.forward-1356"><span class="linenos">1356</span></a>
</span><span id="FSWEmbedding.forward-1357"><a href="#FSWEmbedding.forward-1357"><span class="linenos">1357</span></a>            <span class="k">del</span> <span class="n">X_emb_norm</span>
</span><span id="FSWEmbedding.forward-1358"><a href="#FSWEmbedding.forward-1358"><span class="linenos">1358</span></a>
</span><span id="FSWEmbedding.forward-1359"><a href="#FSWEmbedding.forward-1359"><span class="linenos">1359</span></a>        <span class="c1"># Add bias</span>
</span><span id="FSWEmbedding.forward-1360"><a href="#FSWEmbedding.forward-1360"><span class="linenos">1360</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_bias</span><span class="p">:</span>
</span><span id="FSWEmbedding.forward-1361"><a href="#FSWEmbedding.forward-1361"><span class="linenos">1361</span></a>            <span class="n">X_emb</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</span><span id="FSWEmbedding.forward-1362"><a href="#FSWEmbedding.forward-1362"><span class="linenos">1362</span></a>
</span><span id="FSWEmbedding.forward-1363"><a href="#FSWEmbedding.forward-1363"><span class="linenos">1363</span></a>        <span class="k">return</span> <span class="n">X_emb</span>
</span></pre></div>


            <div class="docstring"><p>Compute the FSW embedding of an input multiset, measure, or graph.</p>

<p>This method maps input sets of vectors (optionally weighted) to vectors in ‚Ñù^{d_out}
using the Fourier Sliced-Wasserstein (FSW) embedding. It supports batched inputs and
graph-based neighbor aggregation, with possibly sparse weight/adjacency matrices.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>X</strong> (torch.Tensor):
Input tensor of shape <code>(n, d_in)</code> or <code>(..., n, d_in)</code> for batched input.</li>
<li><strong>W</strong> (torch.Tensor or {'unit', 'uniform'}, default='unit'):
Weights tensor of shape <code>(n,)</code> or <code>(..., n)</code> corresponding to point importance.
If set to <code>'unit'</code> or <code>'uniform'</code>, uniform weights of <code>1/n</code> are assumed.</li>
<li><strong>X_edge</strong> (torch.Tensor, optional):
Optional edge feature tensor. Required if <code>d_edge &gt; 0</code> was set at initialization.</li>
<li><strong>graph_mode</strong> (bool, default=False):
If True, interprets <code>W</code> as an adjacency matrix and computes a neighbor-aggregated
embedding.</li>
<li><strong>max_parallel_slices</strong> (int, optional):
Limits the number of slices processed in parallel. Reduces memory usage by computing
the embedding in smaller blocks without changing the result.</li>
</ul>

<h6 id="returns">Returns</h6>

<ul>
<li><strong>torch.Tensor</strong>: The embedding tensor. Shape depends on the mode:
<ul>
<li><code>(d_out,)</code> or <code>(..., d_out)</code> in standard mode.</li>
<li><code>(..., num_slices, num_frequencies)</code> in Cartesian mode if <code>flatten_cartesian_axes=False</code>.</li>
<li><code>(..., num_slices * num_frequencies)</code> in Cartesian mode if <code>flatten_cartesian_axes=True</code>.</li>
</ul></li>
</ul>

<h6 id="notes">Notes</h6>

<p>Multisets and distributions:
    If <code>X</code> is <code>(n, d_in)</code> and <code>W</code> is <code>(n,)</code>, the pair represents a weighted point cloud.
    Weights must be non-negative with positive total mass.
    If <code>W</code> is <code>'unit'</code> or <code>'uniform'</code>, uniform weights are used internally.</p>

<p>Batching:
    Input tensors may include leading batch dimensions. For <code>X</code> of shape <code>(..., n, d_in)</code>
    and <code>W</code> of shape <code>(..., n)</code>, the output shape is <code>(..., d_out)</code>.</p>

<p>Graph mode:
    When <code>graph_mode=True</code>, <code>W</code> must be of shape <code>(..., n_recipients, n)</code> and <code>X</code> of
    shape <code>(..., n, d_in)</code> or broadcastable to that. The output will be
    <code>(..., n_recipients, d_out)</code>, where each vector represents a weighted embedding of
    neighboring nodes. This avoids expanding <code>X</code> across <code>n_recipients</code> explicitly.</p>

<p>Cartesian mode:
    If <code><a href="#FSWEmbedding.d_out">d_out</a></code> is not specified but <code><a href="#FSWEmbedding.num_slices">num_slices</a></code> and <code><a href="#FSWEmbedding.num_frequencies">num_frequencies</a></code> are, the embedding
    is computed over a Cartesian product. The output shape is:
        - <code>(..., num_slices, num_frequencies)</code> if <code>flatten_cartesian_axes=False</code>
        - <code>(..., num_slices * num_frequencies)</code> if <code>flatten_cartesian_axes=True</code></p>

<p>Slice serialization:
    If <code>max_parallel_slices=t</code> is set, the computation is performed in blocks of size <code>t</code>,
    reducing memory complexity by a factor of <code>num_slices / t</code>. The output remains unchanged.</p>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FSWEmbedding.__init__">FSWEmbedding.__init__</a></code>:  Constructor for model configuration options.  </p>
</div>


                            </div>
                </section>
                <section id="FSWCustomCudaExtensionLoadWarning">
                            <input id="FSWCustomCudaExtensionLoadWarning-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">FSWCustomCudaExtensionLoadWarning</span><wbr>(<span class="base">builtins.UserWarning</span>):

                <label class="view-source-button" for="FSWCustomCudaExtensionLoadWarning-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWCustomCudaExtensionLoadWarning"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWCustomCudaExtensionLoadWarning-3379"><a href="#FSWCustomCudaExtensionLoadWarning-3379"><span class="linenos">3379</span></a><span class="k">class</span><span class="w"> </span><span class="nc">FSWCustomCudaExtensionLoadWarning</span><span class="p">(</span><span class="ne">UserWarning</span><span class="p">):</span>
</span><span id="FSWCustomCudaExtensionLoadWarning-3380"><a href="#FSWCustomCudaExtensionLoadWarning-3380"><span class="linenos">3380</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Raised when the custom CUDA extension could not be loaded and the fallback torch code is used.&quot;&quot;&quot;</span>
</span><span id="FSWCustomCudaExtensionLoadWarning-3381"><a href="#FSWCustomCudaExtensionLoadWarning-3381"><span class="linenos">3381</span></a>    <span class="k">pass</span>
</span></pre></div>


            <div class="docstring"><p>Raised when the custom CUDA extension could not be loaded and the fallback torch code is used.</p>
</div>


                </section>
                <section id="FSWCustomCudaExtensionLoadError">
                            <input id="FSWCustomCudaExtensionLoadError-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">FSWCustomCudaExtensionLoadError</span><wbr>(<span class="base">builtins.RuntimeError</span>):

                <label class="view-source-button" for="FSWCustomCudaExtensionLoadError-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FSWCustomCudaExtensionLoadError"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FSWCustomCudaExtensionLoadError-3383"><a href="#FSWCustomCudaExtensionLoadError-3383"><span class="linenos">3383</span></a><span class="k">class</span><span class="w"> </span><span class="nc">FSWCustomCudaExtensionLoadError</span><span class="p">(</span><span class="ne">RuntimeError</span><span class="p">):</span>
</span><span id="FSWCustomCudaExtensionLoadError-3384"><a href="#FSWCustomCudaExtensionLoadError-3384"><span class="linenos">3384</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Raised when the custom CUDA extension could not be loaded and fallback behavior is disabled.&quot;&quot;&quot;</span>
</span><span id="FSWCustomCudaExtensionLoadError-3385"><a href="#FSWCustomCudaExtensionLoadError-3385"><span class="linenos">3385</span></a>    <span class="k">pass</span>
</span></pre></div>


            <div class="docstring"><p>Raised when the custom CUDA extension could not be loaded and fallback behavior is disabled.</p>
</div>


                </section>
                <section id="EnumWithResolve">
                            <input id="EnumWithResolve-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">EnumWithResolve</span><wbr>(<span class="base">enum.Enum</span>):

                <label class="view-source-button" for="EnumWithResolve-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#EnumWithResolve"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="EnumWithResolve-146"><a href="#EnumWithResolve-146"><span class="linenos">146</span></a><span class="k">class</span><span class="w"> </span><span class="nc">EnumWithResolve</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
</span><span id="EnumWithResolve-147"><a href="#EnumWithResolve-147"><span class="linenos">147</span></a>    <span class="nd">@classmethod</span>
</span><span id="EnumWithResolve-148"><a href="#EnumWithResolve-148"><span class="linenos">148</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">resolve</span><span class="p">(</span><span class="bp">cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">_E</span><span class="p">],</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_E</span><span class="p">:</span>
</span><span id="EnumWithResolve-149"><a href="#EnumWithResolve-149"><span class="linenos">149</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="bp">cls</span><span class="p">):</span>
</span><span id="EnumWithResolve-150"><a href="#EnumWithResolve-150"><span class="linenos">150</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="EnumWithResolve-151"><a href="#EnumWithResolve-151"><span class="linenos">151</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="EnumWithResolve-152"><a href="#EnumWithResolve-152"><span class="linenos">152</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="EnumWithResolve-153"><a href="#EnumWithResolve-153"><span class="linenos">153</span></a>                <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span><span id="EnumWithResolve-154"><a href="#EnumWithResolve-154"><span class="linenos">154</span></a>            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="EnumWithResolve-155"><a href="#EnumWithResolve-155"><span class="linenos">155</span></a>                <span class="n">valid</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">cls</span><span class="p">]</span>
</span><span id="EnumWithResolve-156"><a href="#EnumWithResolve-156"><span class="linenos">156</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="EnumWithResolve-157"><a href="#EnumWithResolve-157"><span class="linenos">157</span></a>                    <span class="sa">f</span><span class="s2">&quot;Invalid string &#39;</span><span class="si">{</span><span class="n">obj</span><span class="si">}</span><span class="s2">&#39; for </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. Valid options: </span><span class="si">{</span><span class="n">valid</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="EnumWithResolve-158"><a href="#EnumWithResolve-158"><span class="linenos">158</span></a>                <span class="p">)</span>
</span><span id="EnumWithResolve-159"><a href="#EnumWithResolve-159"><span class="linenos">159</span></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
</span><span id="EnumWithResolve-160"><a href="#EnumWithResolve-160"><span class="linenos">160</span></a>            <span class="sa">f</span><span class="s2">&quot;Expected a string or </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> instance, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
</span><span id="EnumWithResolve-161"><a href="#EnumWithResolve-161"><span class="linenos">161</span></a>        <span class="p">)</span>
</span><span id="EnumWithResolve-162"><a href="#EnumWithResolve-162"><span class="linenos">162</span></a>
</span><span id="EnumWithResolve-163"><a href="#EnumWithResolve-163"><span class="linenos">163</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="EnumWithResolve-164"><a href="#EnumWithResolve-164"><span class="linenos">164</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the string value of the enum member.&quot;&quot;&quot;</span>
</span><span id="EnumWithResolve-165"><a href="#EnumWithResolve-165"><span class="linenos">165</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span>
</span></pre></div>


    

                            <div id="EnumWithResolve.resolve" class="classattr">
                                        <input id="EnumWithResolve.resolve-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-classmethod">@classmethod</div>

        <span class="def">def</span>
        <span class="name">resolve</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="o">~</span><span class="n">_E</span><span class="p">]</span>, </span><span class="param"><span class="n">obj</span><span class="p">:</span> <span class="n">Any</span></span><span class="return-annotation">) -> <span class="o">~</span><span class="n">_E</span>:</span></span>

                <label class="view-source-button" for="EnumWithResolve.resolve-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#EnumWithResolve.resolve"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="EnumWithResolve.resolve-147"><a href="#EnumWithResolve.resolve-147"><span class="linenos">147</span></a>    <span class="nd">@classmethod</span>
</span><span id="EnumWithResolve.resolve-148"><a href="#EnumWithResolve.resolve-148"><span class="linenos">148</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">resolve</span><span class="p">(</span><span class="bp">cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">_E</span><span class="p">],</span> <span class="n">obj</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_E</span><span class="p">:</span>
</span><span id="EnumWithResolve.resolve-149"><a href="#EnumWithResolve.resolve-149"><span class="linenos">149</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="bp">cls</span><span class="p">):</span>
</span><span id="EnumWithResolve.resolve-150"><a href="#EnumWithResolve.resolve-150"><span class="linenos">150</span></a>            <span class="k">return</span> <span class="n">obj</span>
</span><span id="EnumWithResolve.resolve-151"><a href="#EnumWithResolve.resolve-151"><span class="linenos">151</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span><span id="EnumWithResolve.resolve-152"><a href="#EnumWithResolve.resolve-152"><span class="linenos">152</span></a>            <span class="k">try</span><span class="p">:</span>
</span><span id="EnumWithResolve.resolve-153"><a href="#EnumWithResolve.resolve-153"><span class="linenos">153</span></a>                <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span><span id="EnumWithResolve.resolve-154"><a href="#EnumWithResolve.resolve-154"><span class="linenos">154</span></a>            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span id="EnumWithResolve.resolve-155"><a href="#EnumWithResolve.resolve-155"><span class="linenos">155</span></a>                <span class="n">valid</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">value</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">cls</span><span class="p">]</span>
</span><span id="EnumWithResolve.resolve-156"><a href="#EnumWithResolve.resolve-156"><span class="linenos">156</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="EnumWithResolve.resolve-157"><a href="#EnumWithResolve.resolve-157"><span class="linenos">157</span></a>                    <span class="sa">f</span><span class="s2">&quot;Invalid string &#39;</span><span class="si">{</span><span class="n">obj</span><span class="si">}</span><span class="s2">&#39; for </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. Valid options: </span><span class="si">{</span><span class="n">valid</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="EnumWithResolve.resolve-158"><a href="#EnumWithResolve.resolve-158"><span class="linenos">158</span></a>                <span class="p">)</span>
</span><span id="EnumWithResolve.resolve-159"><a href="#EnumWithResolve.resolve-159"><span class="linenos">159</span></a>        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
</span><span id="EnumWithResolve.resolve-160"><a href="#EnumWithResolve.resolve-160"><span class="linenos">160</span></a>            <span class="sa">f</span><span class="s2">&quot;Expected a string or </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> instance, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span>
</span><span id="EnumWithResolve.resolve-161"><a href="#EnumWithResolve.resolve-161"><span class="linenos">161</span></a>        <span class="p">)</span>
</span></pre></div>


    

                            </div>
                </section>
                <section id="TotalMassEncodingTransformation">
                            <input id="TotalMassEncodingTransformation-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">TotalMassEncodingTransformation</span><wbr>(<span class="base"><a href="#EnumWithResolve">fswlib.EnumWithResolve</a></span>):

                <label class="view-source-button" for="TotalMassEncodingTransformation-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TotalMassEncodingTransformation"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TotalMassEncodingTransformation-168"><a href="#TotalMassEncodingTransformation-168"><span class="linenos">168</span></a><span class="k">class</span><span class="w"> </span><span class="nc">TotalMassEncodingTransformation</span><span class="p">(</span><span class="n">EnumWithResolve</span><span class="p">):</span>
</span><span id="TotalMassEncodingTransformation-169"><a href="#TotalMassEncodingTransformation-169"><span class="linenos">169</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Transformation applied to the total mass before incorporating into the embedding.</span>
</span><span id="TotalMassEncodingTransformation-170"><a href="#TotalMassEncodingTransformation-170"><span class="linenos">170</span></a>
</span><span id="TotalMassEncodingTransformation-171"><a href="#TotalMassEncodingTransformation-171"><span class="linenos">171</span></a><span class="sd">    Each option defines a different transformation applied to the total mass of an input measure/multiset</span>
</span><span id="TotalMassEncodingTransformation-172"><a href="#TotalMassEncodingTransformation-172"><span class="linenos">172</span></a><span class="sd">    before it is incorporated into the embedding vector.</span>
</span><span id="TotalMassEncodingTransformation-173"><a href="#TotalMassEncodingTransformation-173"><span class="linenos">173</span></a>
</span><span id="TotalMassEncodingTransformation-174"><a href="#TotalMassEncodingTransformation-174"><span class="linenos">174</span></a><span class="sd">    Attributes</span>
</span><span id="TotalMassEncodingTransformation-175"><a href="#TotalMassEncodingTransformation-175"><span class="linenos">175</span></a><span class="sd">    ----------</span>
</span><span id="TotalMassEncodingTransformation-176"><a href="#TotalMassEncodingTransformation-176"><span class="linenos">176</span></a><span class="sd">    IDENTITY : str</span>
</span><span id="TotalMassEncodingTransformation-177"><a href="#TotalMassEncodingTransformation-177"><span class="linenos">177</span></a><span class="sd">        $f(x) = x$; no transformation.</span>
</span><span id="TotalMassEncodingTransformation-178"><a href="#TotalMassEncodingTransformation-178"><span class="linenos">178</span></a><span class="sd">    SQRT : str</span>
</span><span id="TotalMassEncodingTransformation-179"><a href="#TotalMassEncodingTransformation-179"><span class="linenos">179</span></a><span class="sd">        $f(x) = \\sqrt{1 + x} - 1$; mild nonlinearity.</span>
</span><span id="TotalMassEncodingTransformation-180"><a href="#TotalMassEncodingTransformation-180"><span class="linenos">180</span></a><span class="sd">    LOG : str</span>
</span><span id="TotalMassEncodingTransformation-181"><a href="#TotalMassEncodingTransformation-181"><span class="linenos">181</span></a><span class="sd">        $f(x) = \\log(1 + x)$; stronger compression of large values.</span>
</span><span id="TotalMassEncodingTransformation-182"><a href="#TotalMassEncodingTransformation-182"><span class="linenos">182</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="TotalMassEncodingTransformation-183"><a href="#TotalMassEncodingTransformation-183"><span class="linenos">183</span></a>    <span class="n">IDENTITY</span> <span class="o">=</span> <span class="s1">&#39;identity&#39;</span>
</span><span id="TotalMassEncodingTransformation-184"><a href="#TotalMassEncodingTransformation-184"><span class="linenos">184</span></a>    <span class="n">SQRT</span> <span class="o">=</span> <span class="s1">&#39;sqrt&#39;</span>
</span><span id="TotalMassEncodingTransformation-185"><a href="#TotalMassEncodingTransformation-185"><span class="linenos">185</span></a>    <span class="n">LOG</span> <span class="o">=</span> <span class="s1">&#39;log&#39;</span>
</span></pre></div>


            <div class="docstring"><p>Transformation applied to the total mass before incorporating into the embedding.</p>

<p>Each option defines a different transformation applied to the total mass of an input measure/multiset
before it is incorporated into the embedding vector.</p>

<h6 id="attributes">Attributes</h6>

<ul>
<li><strong>IDENTITY</strong> (str):
$f(x) = x$; no transformation.</li>
<li><strong>SQRT</strong> (str):
$f(x) = \sqrt{1 + x} - 1$; mild nonlinearity.</li>
<li><strong>LOG</strong> (str):
$f(x) = \log(1 + x)$; stronger compression of large values.</li>
</ul>
</div>


                            <div id="TotalMassEncodingTransformation.IDENTITY" class="classattr">
                                <div class="attr variable">
            <span class="name">IDENTITY</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingTransformation.IDENTITY">TotalMassEncodingTransformation.IDENTITY</a>: &#39;identity&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingTransformation.IDENTITY"></a>
    
    

                            </div>
                            <div id="TotalMassEncodingTransformation.SQRT" class="classattr">
                                <div class="attr variable">
            <span class="name">SQRT</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingTransformation.SQRT">TotalMassEncodingTransformation.SQRT</a>: &#39;sqrt&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingTransformation.SQRT"></a>
    
    

                            </div>
                            <div id="TotalMassEncodingTransformation.LOG" class="classattr">
                                <div class="attr variable">
            <span class="name">LOG</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingTransformation.LOG">TotalMassEncodingTransformation.LOG</a>: &#39;log&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingTransformation.LOG"></a>
    
    

                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#EnumWithResolve">EnumWithResolve</a></dt>
                                <dd id="TotalMassEncodingTransformation.resolve" class="function"><a href="#EnumWithResolve.resolve">resolve</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="TotalMassEncodingMethod">
                            <input id="TotalMassEncodingMethod-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">TotalMassEncodingMethod</span><wbr>(<span class="base"><a href="#EnumWithResolve">fswlib.EnumWithResolve</a></span>):

                <label class="view-source-button" for="TotalMassEncodingMethod-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#TotalMassEncodingMethod"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="TotalMassEncodingMethod-189"><a href="#TotalMassEncodingMethod-189"><span class="linenos">189</span></a><span class="k">class</span><span class="w"> </span><span class="nc">TotalMassEncodingMethod</span><span class="p">(</span><span class="n">EnumWithResolve</span><span class="p">):</span>
</span><span id="TotalMassEncodingMethod-190"><a href="#TotalMassEncodingMethod-190"><span class="linenos">190</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="TotalMassEncodingMethod-191"><a href="#TotalMassEncodingMethod-191"><span class="linenos">191</span></a><span class="sd">    Strategies for incorporating total mass into the embedding.</span>
</span><span id="TotalMassEncodingMethod-192"><a href="#TotalMassEncodingMethod-192"><span class="linenos">192</span></a>
</span><span id="TotalMassEncodingMethod-193"><a href="#TotalMassEncodingMethod-193"><span class="linenos">193</span></a><span class="sd">    Each method defines a different way of incorporating the total mass $\\mu\\left(\\Omega\\right) = \\sum_{i=1}^n w_i$ of an input measure</span>
</span><span id="TotalMassEncodingMethod-194"><a href="#TotalMassEncodingMethod-194"><span class="linenos">194</span></a><span class="sd">    $\\mu = \\sum_{i=1}^n w_i \\delta_{\\mathbf{x}^{(i)}}$ (i.e. the multiset size if $\\mu$ is a multiset) with the FSW embedding of the normalized input $\\mu_{\\rho}$ into a single output vector.</span>
</span><span id="TotalMassEncodingMethod-195"><a href="#TotalMassEncodingMethod-195"><span class="linenos">195</span></a><span class="sd">    For further discussion, see Appendix A.1 of the reference below.</span>
</span><span id="TotalMassEncodingMethod-196"><a href="#TotalMassEncodingMethod-196"><span class="linenos">196</span></a>
</span><span id="TotalMassEncodingMethod-197"><a href="#TotalMassEncodingMethod-197"><span class="linenos">197</span></a><span class="sd">    Attributes</span>
</span><span id="TotalMassEncodingMethod-198"><a href="#TotalMassEncodingMethod-198"><span class="linenos">198</span></a><span class="sd">    ----------</span>
</span><span id="TotalMassEncodingMethod-199"><a href="#TotalMassEncodingMethod-199"><span class="linenos">199</span></a><span class="sd">    DECOUPLED : str</span>
</span><span id="TotalMassEncodingMethod-200"><a href="#TotalMassEncodingMethod-200"><span class="linenos">200</span></a><span class="sd">        The total mass is appended as a separate component to the embedding vector,</span>
</span><span id="TotalMassEncodingMethod-201"><a href="#TotalMassEncodingMethod-201"><span class="linenos">201</span></a><span class="sd">        which is computed from the normalized input measure, as in Equation (18)</span>
</span><span id="TotalMassEncodingMethod-202"><a href="#TotalMassEncodingMethod-202"><span class="linenos">202</span></a><span class="sd">        in our paper:</span>
</span><span id="TotalMassEncodingMethod-203"><a href="#TotalMassEncodingMethod-203"><span class="linenos">203</span></a><span class="sd">        $$ \\hat{E}^{\\textup{FSW}}_{m}\\left(\\mu\\right) = \\left[ \\mu\\left(\\Omega\\right), \\;  E^{\\textup{FSW}}_{m-1}\\left(\\mu_{\\rho}\\right) \\right] $$</span>
</span><span id="TotalMassEncodingMethod-204"><a href="#TotalMassEncodingMethod-204"><span class="linenos">204</span></a>
</span><span id="TotalMassEncodingMethod-205"><a href="#TotalMassEncodingMethod-205"><span class="linenos">205</span></a><span class="sd">    SCALED : str</span>
</span><span id="TotalMassEncodingMethod-206"><a href="#TotalMassEncodingMethod-206"><span class="linenos">206</span></a><span class="sd">        Similar to `DECOUPLED`, but the embedding of the normalized input is scaled</span>
</span><span id="TotalMassEncodingMethod-207"><a href="#TotalMassEncodingMethod-207"><span class="linenos">207</span></a><span class="sd">        by the total mass. Using the notation of Equation (18), this yields:</span>
</span><span id="TotalMassEncodingMethod-208"><a href="#TotalMassEncodingMethod-208"><span class="linenos">208</span></a><span class="sd">        $$ \\hat{E}^{\\textup{FSW}}_{m}\\left(\\mu\\right) = \\left[ \\mu\\left(\\Omega\\right), \\;  \\mu\\left(\\Omega\\right) \\cdot E^{\\textup{FSW}}_{m-1}\\left(\\mu_{\\rho}\\right) \\right] $$</span>
</span><span id="TotalMassEncodingMethod-209"><a href="#TotalMassEncodingMethod-209"><span class="linenos">209</span></a>
</span><span id="TotalMassEncodingMethod-210"><a href="#TotalMassEncodingMethod-210"><span class="linenos">210</span></a><span class="sd">    HOMOGENEOUS : str</span>
</span><span id="TotalMassEncodingMethod-211"><a href="#TotalMassEncodingMethod-211"><span class="linenos">211</span></a><span class="sd">        A method that encodes the total mass while preserving homogeneity</span>
</span><span id="TotalMassEncodingMethod-212"><a href="#TotalMassEncodingMethod-212"><span class="linenos">212</span></a><span class="sd">        with respect to the elements of the input multiset. See Equation (19).</span>
</span><span id="TotalMassEncodingMethod-213"><a href="#TotalMassEncodingMethod-213"><span class="linenos">213</span></a><span class="sd">        $$ \\hat{E}^{\\textup{FSW}}_{m}\\left(\\mu\\right) = \\left[ \\lVert E^{\\textup{FSW}}_{m-1}\\left(\\mu_{\\rho}\\right) \\rVert \\cdot \\mu\\left(\\Omega\\right), \\;  E^{\\textup{FSW}}_{m-1}\\left(\\mu_{\\rho}\\right) \\right] $$</span>
</span><span id="TotalMassEncodingMethod-214"><a href="#TotalMassEncodingMethod-214"><span class="linenos">214</span></a>
</span><span id="TotalMassEncodingMethod-215"><a href="#TotalMassEncodingMethod-215"><span class="linenos">215</span></a><span class="sd">    HOMOGENEOUS_SCALED : str</span>
</span><span id="TotalMassEncodingMethod-216"><a href="#TotalMassEncodingMethod-216"><span class="linenos">216</span></a><span class="sd">        Similar to `SCALED`, but preserves homogeneity.</span>
</span><span id="TotalMassEncodingMethod-217"><a href="#TotalMassEncodingMethod-217"><span class="linenos">217</span></a><span class="sd">        $$ \\hat{E}^{\\textup{FSW}}_{m}\\left(\\mu\\right) = \\left[ \\lVert E^{\\textup{FSW}}_{m-1}\\left(\\mu_{\\rho}\\right) \\rVert, \\;  \\mu\\left(\\Omega\\right) \\cdot E^{\\textup{FSW}}_{m-1}\\left(\\mu_{\\rho}\\right) \\right] $$</span>
</span><span id="TotalMassEncodingMethod-218"><a href="#TotalMassEncodingMethod-218"><span class="linenos">218</span></a>
</span><span id="TotalMassEncodingMethod-219"><a href="#TotalMassEncodingMethod-219"><span class="linenos">219</span></a><span class="sd">    HOMOGENEOUS_LEGACY : str</span>
</span><span id="TotalMassEncodingMethod-220"><a href="#TotalMassEncodingMethod-220"><span class="linenos">220</span></a><span class="sd">        An alternative, legacy version of the homogeneous method, retained</span>
</span><span id="TotalMassEncodingMethod-221"><a href="#TotalMassEncodingMethod-221"><span class="linenos">221</span></a><span class="sd">        for reference and compatibility.</span>
</span><span id="TotalMassEncodingMethod-222"><a href="#TotalMassEncodingMethod-222"><span class="linenos">222</span></a>
</span><span id="TotalMassEncodingMethod-223"><a href="#TotalMassEncodingMethod-223"><span class="linenos">223</span></a><span class="sd">    Notes</span>
</span><span id="TotalMassEncodingMethod-224"><a href="#TotalMassEncodingMethod-224"><span class="linenos">224</span></a><span class="sd">    -----</span>
</span><span id="TotalMassEncodingMethod-225"><a href="#TotalMassEncodingMethod-225"><span class="linenos">225</span></a><span class="sd">    In practice, $\\mu\\left(\\Omega\\right)$ in the above expressions is replaced by $\\alpha \\cdot f \\left( \\mu\\left(\\Omega\\right) \\right)$,</span>
</span><span id="TotalMassEncodingMethod-226"><a href="#TotalMassEncodingMethod-226"><span class="linenos">226</span></a><span class="sd">    where $f$ is the function defined by `TotalMassEncodingTransformation` and $\\alpha$ is a scale factor given in `total_mass_encoding_scale`.</span>
</span><span id="TotalMassEncodingMethod-227"><a href="#TotalMassEncodingMethod-227"><span class="linenos">227</span></a><span class="sd">    Additionally, $\\lVert E^{\\textup{FSW}}_{m-1}\\left(\\mu_{\\rho}\\right) \\rVert$ is multiplied by a normalizing factor $\\sqrt{m-1}^{-1}$.</span>
</span><span id="TotalMassEncodingMethod-228"><a href="#TotalMassEncodingMethod-228"><span class="linenos">228</span></a>
</span><span id="TotalMassEncodingMethod-229"><a href="#TotalMassEncodingMethod-229"><span class="linenos">229</span></a><span class="sd">    Reference</span>
</span><span id="TotalMassEncodingMethod-230"><a href="#TotalMassEncodingMethod-230"><span class="linenos">230</span></a><span class="sd">    ---------</span>
</span><span id="TotalMassEncodingMethod-231"><a href="#TotalMassEncodingMethod-231"><span class="linenos">231</span></a><span class="sd">    Tal Amir, Nadav Dym.</span>
</span><span id="TotalMassEncodingMethod-232"><a href="#TotalMassEncodingMethod-232"><span class="linenos">232</span></a><span class="sd">    &quot;Fourier Sliced-Wasserstein Embedding for Multisets and Measures.&quot;</span>
</span><span id="TotalMassEncodingMethod-233"><a href="#TotalMassEncodingMethod-233"><span class="linenos">233</span></a><span class="sd">    International Conference on Learning Representations (ICLR), 2025.</span>
</span><span id="TotalMassEncodingMethod-234"><a href="#TotalMassEncodingMethod-234"><span class="linenos">234</span></a><span class="sd">    https://iclr.cc/virtual/2025/poster/30562</span>
</span><span id="TotalMassEncodingMethod-235"><a href="#TotalMassEncodingMethod-235"><span class="linenos">235</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="TotalMassEncodingMethod-236"><a href="#TotalMassEncodingMethod-236"><span class="linenos">236</span></a>    <span class="n">DECOUPLED</span> <span class="o">=</span> <span class="s1">&#39;decoupled&#39;</span>
</span><span id="TotalMassEncodingMethod-237"><a href="#TotalMassEncodingMethod-237"><span class="linenos">237</span></a>    <span class="n">SCALED</span> <span class="o">=</span> <span class="s1">&#39;scaled&#39;</span>
</span><span id="TotalMassEncodingMethod-238"><a href="#TotalMassEncodingMethod-238"><span class="linenos">238</span></a>    <span class="n">HOMOGENEOUS</span> <span class="o">=</span> <span class="s1">&#39;homogeneous&#39;</span>
</span><span id="TotalMassEncodingMethod-239"><a href="#TotalMassEncodingMethod-239"><span class="linenos">239</span></a>    <span class="n">HOMOGENEOUS_SCALED</span> <span class="o">=</span> <span class="s1">&#39;homogeneous_scaled&#39;</span>
</span><span id="TotalMassEncodingMethod-240"><a href="#TotalMassEncodingMethod-240"><span class="linenos">240</span></a>    <span class="n">HOMOGENEOUS_LEGACY</span> <span class="o">=</span> <span class="s1">&#39;homogeneous_legacy&#39;</span>
</span></pre></div>


            <div class="docstring"><p>Strategies for incorporating total mass into the embedding.</p>

<p>Each method defines a different way of incorporating the total mass $\mu\left(\Omega\right) = \sum_{i=1}^n w_i$ of an input measure
$\mu = \sum_{i=1}^n w_i \delta_{\mathbf{x}^{(i)}}$ (i.e. the multiset size if $\mu$ is a multiset) with the FSW embedding of the normalized input $\mu_{\rho}$ into a single output vector.
For further discussion, see Appendix A.1 of the reference below.</p>

<h6 id="attributes">Attributes</h6>

<ul>
<li><strong>DECOUPLED</strong> (str):
The total mass is appended as a separate component to the embedding vector,
which is computed from the normalized input measure, as in Equation (18)
in our paper:
$$ \hat{E}^{\textup{FSW}}_{m}\left(\mu\right) = \left[ \mu\left(\Omega\right), \;  E^{\textup{FSW}}_{m-1}\left(\mu_{\rho}\right) \right] $$</li>
<li><strong>SCALED</strong> (str):
Similar to <code><a href="#TotalMassEncodingMethod.DECOUPLED">DECOUPLED</a></code>, but the embedding of the normalized input is scaled
by the total mass. Using the notation of Equation (18), this yields:
$$ \hat{E}^{\textup{FSW}}_{m}\left(\mu\right) = \left[ \mu\left(\Omega\right), \;  \mu\left(\Omega\right) \cdot E^{\textup{FSW}}_{m-1}\left(\mu_{\rho}\right) \right] $$</li>
<li><strong>HOMOGENEOUS</strong> (str):
A method that encodes the total mass while preserving homogeneity
with respect to the elements of the input multiset. See Equation (19).
$$ \hat{E}^{\textup{FSW}}_{m}\left(\mu\right) = \left[ \lVert E^{\textup{FSW}}_{m-1}\left(\mu_{\rho}\right) \rVert \cdot \mu\left(\Omega\right), \;  E^{\textup{FSW}}_{m-1}\left(\mu_{\rho}\right) \right] $$</li>
<li><strong>HOMOGENEOUS_SCALED</strong> (str):
Similar to <code><a href="#TotalMassEncodingMethod.SCALED">SCALED</a></code>, but preserves homogeneity.
$$ \hat{E}^{\textup{FSW}}_{m}\left(\mu\right) = \left[ \lVert E^{\textup{FSW}}_{m-1}\left(\mu_{\rho}\right) \rVert, \;  \mu\left(\Omega\right) \cdot E^{\textup{FSW}}_{m-1}\left(\mu_{\rho}\right) \right] $$</li>
<li><strong>HOMOGENEOUS_LEGACY</strong> (str):
An alternative, legacy version of the homogeneous method, retained
for reference and compatibility.</li>
</ul>

<h6 id="notes">Notes</h6>

<p>In practice, $\mu\left(\Omega\right)$ in the above expressions is replaced by $\alpha \cdot f \left( \mu\left(\Omega\right) \right)$,
where $f$ is the function defined by <code><a href="#TotalMassEncodingTransformation">TotalMassEncodingTransformation</a></code> and $\alpha$ is a scale factor given in <code>total_mass_encoding_scale</code>.
Additionally, $\lVert E^{\textup{FSW}}_{m-1}\left(\mu_{\rho}\right) \rVert$ is multiplied by a normalizing factor $\sqrt{m-1}^{-1}$.</p>

<h6 id="reference">Reference</h6>

<p>Tal Amir, Nadav Dym.
"Fourier Sliced-Wasserstein Embedding for Multisets and Measures."
International Conference on Learning Representations (ICLR), 2025.
<a href="https://iclr.cc/virtual/2025/poster/30562">https://iclr.cc/virtual/2025/poster/30562</a></p>
</div>


                            <div id="TotalMassEncodingMethod.DECOUPLED" class="classattr">
                                <div class="attr variable">
            <span class="name">DECOUPLED</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingMethod.DECOUPLED">TotalMassEncodingMethod.DECOUPLED</a>: &#39;decoupled&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingMethod.DECOUPLED"></a>
    
    

                            </div>
                            <div id="TotalMassEncodingMethod.SCALED" class="classattr">
                                <div class="attr variable">
            <span class="name">SCALED</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingMethod.SCALED">TotalMassEncodingMethod.SCALED</a>: &#39;scaled&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingMethod.SCALED"></a>
    
    

                            </div>
                            <div id="TotalMassEncodingMethod.HOMOGENEOUS" class="classattr">
                                <div class="attr variable">
            <span class="name">HOMOGENEOUS</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingMethod.HOMOGENEOUS">TotalMassEncodingMethod.HOMOGENEOUS</a>: &#39;homogeneous&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingMethod.HOMOGENEOUS"></a>
    
    

                            </div>
                            <div id="TotalMassEncodingMethod.HOMOGENEOUS_SCALED" class="classattr">
                                <div class="attr variable">
            <span class="name">HOMOGENEOUS_SCALED</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingMethod.HOMOGENEOUS_SCALED">TotalMassEncodingMethod.HOMOGENEOUS_SCALED</a>: &#39;homogeneous_scaled&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingMethod.HOMOGENEOUS_SCALED"></a>
    
    

                            </div>
                            <div id="TotalMassEncodingMethod.HOMOGENEOUS_LEGACY" class="classattr">
                                <div class="attr variable">
            <span class="name">HOMOGENEOUS_LEGACY</span>        =
<span class="default_value">&lt;<a href="#TotalMassEncodingMethod.HOMOGENEOUS_LEGACY">TotalMassEncodingMethod.HOMOGENEOUS_LEGACY</a>: &#39;homogeneous_legacy&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#TotalMassEncodingMethod.HOMOGENEOUS_LEGACY"></a>
    
    

                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#EnumWithResolve">EnumWithResolve</a></dt>
                                <dd id="TotalMassEncodingMethod.resolve" class="function"><a href="#EnumWithResolve.resolve">resolve</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="FrequencyInitMethod">
                            <input id="FrequencyInitMethod-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">FrequencyInitMethod</span><wbr>(<span class="base"><a href="#EnumWithResolve">fswlib.EnumWithResolve</a></span>):

                <label class="view-source-button" for="FrequencyInitMethod-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FrequencyInitMethod"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FrequencyInitMethod-244"><a href="#FrequencyInitMethod-244"><span class="linenos">244</span></a><span class="k">class</span><span class="w"> </span><span class="nc">FrequencyInitMethod</span><span class="p">(</span><span class="n">EnumWithResolve</span><span class="p">):</span>
</span><span id="FrequencyInitMethod-245"><a href="#FrequencyInitMethod-245"><span class="linenos">245</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FrequencyInitMethod-246"><a href="#FrequencyInitMethod-246"><span class="linenos">246</span></a><span class="sd">    Method for initializing frequencies in the FSW embedding.</span>
</span><span id="FrequencyInitMethod-247"><a href="#FrequencyInitMethod-247"><span class="linenos">247</span></a>
</span><span id="FrequencyInitMethod-248"><a href="#FrequencyInitMethod-248"><span class="linenos">248</span></a><span class="sd">    This enumeration specifies how the frequencies in the FSW embedding are</span>
</span><span id="FrequencyInitMethod-249"><a href="#FrequencyInitMethod-249"><span class="linenos">249</span></a><span class="sd">    initialized.</span>
</span><span id="FrequencyInitMethod-250"><a href="#FrequencyInitMethod-250"><span class="linenos">250</span></a>
</span><span id="FrequencyInitMethod-251"><a href="#FrequencyInitMethod-251"><span class="linenos">251</span></a><span class="sd">    Attributes</span>
</span><span id="FrequencyInitMethod-252"><a href="#FrequencyInitMethod-252"><span class="linenos">252</span></a><span class="sd">    ----------</span>
</span><span id="FrequencyInitMethod-253"><a href="#FrequencyInitMethod-253"><span class="linenos">253</span></a><span class="sd">    RANDOM : str</span>
</span><span id="FrequencyInitMethod-254"><a href="#FrequencyInitMethod-254"><span class="linenos">254</span></a><span class="sd">        Frequencies are sampled independently at random from the distribution</span>
</span><span id="FrequencyInitMethod-255"><a href="#FrequencyInitMethod-255"><span class="linenos">255</span></a><span class="sd">        D_Œæ, as defined in Section 3 of our paper.</span>
</span><span id="FrequencyInitMethod-256"><a href="#FrequencyInitMethod-256"><span class="linenos">256</span></a><span class="sd">    EVEN : str</span>
</span><span id="FrequencyInitMethod-257"><a href="#FrequencyInitMethod-257"><span class="linenos">257</span></a><span class="sd">        Frequencies are spaced deterministically for efficient coverage of the frequency domain,</span>
</span><span id="FrequencyInitMethod-258"><a href="#FrequencyInitMethod-258"><span class="linenos">258</span></a><span class="sd">        with spacing inversely proportional to the density function f_Œæ.</span>
</span><span id="FrequencyInitMethod-259"><a href="#FrequencyInitMethod-259"><span class="linenos">259</span></a>
</span><span id="FrequencyInitMethod-260"><a href="#FrequencyInitMethod-260"><span class="linenos">260</span></a><span class="sd">    See Also</span>
</span><span id="FrequencyInitMethod-261"><a href="#FrequencyInitMethod-261"><span class="linenos">261</span></a><span class="sd">    --------</span>
</span><span id="FrequencyInitMethod-262"><a href="#FrequencyInitMethod-262"><span class="linenos">262</span></a><span class="sd">    FSWEmbedding.__init__ : Where this method is selected and used.</span>
</span><span id="FrequencyInitMethod-263"><a href="#FrequencyInitMethod-263"><span class="linenos">263</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="FrequencyInitMethod-264"><a href="#FrequencyInitMethod-264"><span class="linenos">264</span></a>
</span><span id="FrequencyInitMethod-265"><a href="#FrequencyInitMethod-265"><span class="linenos">265</span></a>    <span class="n">RANDOM</span> <span class="o">=</span> <span class="s2">&quot;random&quot;</span>
</span><span id="FrequencyInitMethod-266"><a href="#FrequencyInitMethod-266"><span class="linenos">266</span></a>    <span class="n">EVEN</span> <span class="o">=</span> <span class="s2">&quot;even&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Method for initializing frequencies in the FSW embedding.</p>

<p>This enumeration specifies how the frequencies in the FSW embedding are
initialized.</p>

<h6 id="attributes">Attributes</h6>

<ul>
<li><strong>RANDOM</strong> (str):
Frequencies are sampled independently at random from the distribution
D_Œæ, as defined in Section 3 of our paper.</li>
<li><strong>EVEN</strong> (str):
Frequencies are spaced deterministically for efficient coverage of the frequency domain,
with spacing inversely proportional to the density function f_Œæ.</li>
</ul>

<h6 id="see-also">See Also</h6>

<p><code><a href="#FSWEmbedding.__init__">FSWEmbedding.__init__</a></code>:  Where this method is selected and used.  </p>
</div>


                            <div id="FrequencyInitMethod.RANDOM" class="classattr">
                                <div class="attr variable">
            <span class="name">RANDOM</span>        =
<span class="default_value">&lt;<a href="#FrequencyInitMethod.RANDOM">FrequencyInitMethod.RANDOM</a>: &#39;random&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#FrequencyInitMethod.RANDOM"></a>
    
    

                            </div>
                            <div id="FrequencyInitMethod.EVEN" class="classattr">
                                <div class="attr variable">
            <span class="name">EVEN</span>        =
<span class="default_value">&lt;<a href="#FrequencyInitMethod.EVEN">FrequencyInitMethod.EVEN</a>: &#39;even&#39;&gt;</span>

        
    </div>
    <a class="headerlink" href="#FrequencyInitMethod.EVEN"></a>
    
    

                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#EnumWithResolve">EnumWithResolve</a></dt>
                                <dd id="FrequencyInitMethod.resolve" class="function"><a href="#EnumWithResolve.resolve">resolve</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="test_fsw_embedding">
                            <input id="test_fsw_embedding-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">test_fsw_embedding</span><span class="signature pdoc-code condensed">(<span class="return-annotation">):</span></span>

                <label class="view-source-button" for="test_fsw_embedding-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#test_fsw_embedding"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="test_fsw_embedding-5"><a href="#test_fsw_embedding-5"><span class="linenos">  5</span></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="test_fsw_embedding-6"><a href="#test_fsw_embedding-6"><span class="linenos">  6</span></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="test_fsw_embedding-7"><a href="#test_fsw_embedding-7"><span class="linenos">  7</span></a>
</span><span id="test_fsw_embedding-8"><a href="#test_fsw_embedding-8"><span class="linenos">  8</span></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="test_fsw_embedding-9"><a href="#test_fsw_embedding-9"><span class="linenos">  9</span></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
</span><span id="test_fsw_embedding-10"><a href="#test_fsw_embedding-10"><span class="linenos"> 10</span></a>
</span><span id="test_fsw_embedding-11"><a href="#test_fsw_embedding-11"><span class="linenos"> 11</span></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">fswlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">FSWEmbedding</span>
</span><span id="test_fsw_embedding-12"><a href="#test_fsw_embedding-12"><span class="linenos"> 12</span></a>
</span><span id="test_fsw_embedding-13"><a href="#test_fsw_embedding-13"><span class="linenos"> 13</span></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="test_fsw_embedding-14"><a href="#test_fsw_embedding-14"><span class="linenos"> 14</span></a>
</span><span id="test_fsw_embedding-15"><a href="#test_fsw_embedding-15"><span class="linenos"> 15</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">reldiff</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
</span><span id="test_fsw_embedding-16"><a href="#test_fsw_embedding-16"><span class="linenos"> 16</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="test_fsw_embedding-17"><a href="#test_fsw_embedding-17"><span class="linenos"> 17</span></a>
</span><span id="test_fsw_embedding-18"><a href="#test_fsw_embedding-18"><span class="linenos"> 18</span></a>    <span class="k">def</span><span class="w"> </span><span class="nf">relerr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
</span><span id="test_fsw_embedding-19"><a href="#test_fsw_embedding-19"><span class="linenos"> 19</span></a>        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="test_fsw_embedding-20"><a href="#test_fsw_embedding-20"><span class="linenos"> 20</span></a>
</span><span id="test_fsw_embedding-21"><a href="#test_fsw_embedding-21"><span class="linenos"> 21</span></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-22"><a href="#test_fsw_embedding-22"><span class="linenos"> 22</span></a>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float64</span>
</span><span id="test_fsw_embedding-23"><a href="#test_fsw_embedding-23"><span class="linenos"> 23</span></a>
</span><span id="test_fsw_embedding-24"><a href="#test_fsw_embedding-24"><span class="linenos"> 24</span></a>    <span class="c1"># Note: This estimation is much slower than the rest of the code when n is large, and is not always accurate.</span>
</span><span id="test_fsw_embedding-25"><a href="#test_fsw_embedding-25"><span class="linenos"> 25</span></a>    <span class="c1">#       I just used it as a sanity check.</span>
</span><span id="test_fsw_embedding-26"><a href="#test_fsw_embedding-26"><span class="linenos"> 26</span></a>    <span class="n">do_monte_carlo</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="test_fsw_embedding-27"><a href="#test_fsw_embedding-27"><span class="linenos"> 27</span></a>
</span><span id="test_fsw_embedding-28"><a href="#test_fsw_embedding-28"><span class="linenos"> 28</span></a>    <span class="n">do_compile</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="test_fsw_embedding-29"><a href="#test_fsw_embedding-29"><span class="linenos"> 29</span></a>    <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-30"><a href="#test_fsw_embedding-30"><span class="linenos"> 30</span></a>
</span><span id="test_fsw_embedding-31"><a href="#test_fsw_embedding-31"><span class="linenos"> 31</span></a>    <span class="c1"># d: ambient dimension</span>
</span><span id="test_fsw_embedding-32"><a href="#test_fsw_embedding-32"><span class="linenos"> 32</span></a>    <span class="c1"># n: maximal multiset size</span>
</span><span id="test_fsw_embedding-33"><a href="#test_fsw_embedding-33"><span class="linenos"> 33</span></a>    <span class="c1"># m: embedding dimension</span>
</span><span id="test_fsw_embedding-34"><a href="#test_fsw_embedding-34"><span class="linenos"> 34</span></a>
</span><span id="test_fsw_embedding-35"><a href="#test_fsw_embedding-35"><span class="linenos"> 35</span></a>    <span class="c1">## Interesting test settings:</span>
</span><span id="test_fsw_embedding-36"><a href="#test_fsw_embedding-36"><span class="linenos"> 36</span></a>
</span><span id="test_fsw_embedding-37"><a href="#test_fsw_embedding-37"><span class="linenos"> 37</span></a>    <span class="n">setting</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="test_fsw_embedding-38"><a href="#test_fsw_embedding-38"><span class="linenos"> 38</span></a>
</span><span id="test_fsw_embedding-39"><a href="#test_fsw_embedding-39"><span class="linenos"> 39</span></a>    <span class="k">if</span> <span class="n">setting</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="test_fsw_embedding-40"><a href="#test_fsw_embedding-40"><span class="linenos"> 40</span></a>        <span class="c1"># super fast</span>
</span><span id="test_fsw_embedding-41"><a href="#test_fsw_embedding-41"><span class="linenos"> 41</span></a>        <span class="n">d</span> <span class="o">=</span> <span class="mi">20</span>
</span><span id="test_fsw_embedding-42"><a href="#test_fsw_embedding-42"><span class="linenos"> 42</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
</span><span id="test_fsw_embedding-43"><a href="#test_fsw_embedding-43"><span class="linenos"> 43</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="mi">1000</span>
</span><span id="test_fsw_embedding-44"><a href="#test_fsw_embedding-44"><span class="linenos"> 44</span></a>        <span class="c1">#do_monte_carlo = True</span>
</span><span id="test_fsw_embedding-45"><a href="#test_fsw_embedding-45"><span class="linenos"> 45</span></a>    <span class="k">elif</span> <span class="n">setting</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="test_fsw_embedding-46"><a href="#test_fsw_embedding-46"><span class="linenos"> 46</span></a>        <span class="c1"># takes ~40 s</span>
</span><span id="test_fsw_embedding-47"><a href="#test_fsw_embedding-47"><span class="linenos"> 47</span></a>        <span class="n">d</span> <span class="o">=</span> <span class="mi">100</span>
</span><span id="test_fsw_embedding-48"><a href="#test_fsw_embedding-48"><span class="linenos"> 48</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">50000</span>
</span><span id="test_fsw_embedding-49"><a href="#test_fsw_embedding-49"><span class="linenos"> 49</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="mi">1000</span>
</span><span id="test_fsw_embedding-50"><a href="#test_fsw_embedding-50"><span class="linenos"> 50</span></a>    <span class="k">elif</span> <span class="n">setting</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="test_fsw_embedding-51"><a href="#test_fsw_embedding-51"><span class="linenos"> 51</span></a>        <span class="c1"># takes 20-30s to calculate four embeddings</span>
</span><span id="test_fsw_embedding-52"><a href="#test_fsw_embedding-52"><span class="linenos"> 52</span></a>        <span class="n">d</span> <span class="o">=</span> <span class="mi">3</span>
</span><span id="test_fsw_embedding-53"><a href="#test_fsw_embedding-53"><span class="linenos"> 53</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span>
</span><span id="test_fsw_embedding-54"><a href="#test_fsw_embedding-54"><span class="linenos"> 54</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="mi">300</span>
</span><span id="test_fsw_embedding-55"><a href="#test_fsw_embedding-55"><span class="linenos"> 55</span></a>    <span class="k">elif</span> <span class="n">setting</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="test_fsw_embedding-56"><a href="#test_fsw_embedding-56"><span class="linenos"> 56</span></a>        <span class="c1"># takes ~2.5 minutes. sometimes yields up to 10% error due to low embedding dimension</span>
</span><span id="test_fsw_embedding-57"><a href="#test_fsw_embedding-57"><span class="linenos"> 57</span></a>        <span class="n">d</span> <span class="o">=</span> <span class="mi">3</span>
</span><span id="test_fsw_embedding-58"><a href="#test_fsw_embedding-58"><span class="linenos"> 58</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">1000000</span>
</span><span id="test_fsw_embedding-59"><a href="#test_fsw_embedding-59"><span class="linenos"> 59</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="mi">150</span>
</span><span id="test_fsw_embedding-60"><a href="#test_fsw_embedding-60"><span class="linenos"> 60</span></a>        <span class="c1">#max_parallel_slices = 15</span>
</span><span id="test_fsw_embedding-61"><a href="#test_fsw_embedding-61"><span class="linenos"> 61</span></a>    <span class="k">elif</span> <span class="n">setting</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span> <span class="c1"># Could take 10 minutes</span>
</span><span id="test_fsw_embedding-62"><a href="#test_fsw_embedding-62"><span class="linenos"> 62</span></a>        <span class="n">d</span> <span class="o">=</span> <span class="mi">3</span>
</span><span id="test_fsw_embedding-63"><a href="#test_fsw_embedding-63"><span class="linenos"> 63</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">1000000</span>
</span><span id="test_fsw_embedding-64"><a href="#test_fsw_embedding-64"><span class="linenos"> 64</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="mi">400</span>
</span><span id="test_fsw_embedding-65"><a href="#test_fsw_embedding-65"><span class="linenos"> 65</span></a>
</span><span id="test_fsw_embedding-66"><a href="#test_fsw_embedding-66"><span class="linenos"> 66</span></a>
</span><span id="test_fsw_embedding-67"><a href="#test_fsw_embedding-67"><span class="linenos"> 67</span></a>
</span><span id="test_fsw_embedding-68"><a href="#test_fsw_embedding-68"><span class="linenos"> 68</span></a>    <span class="c1"># deterministic_freqs spreads the frequencies in a way that better approximates their distribution than random sampling</span>
</span><span id="test_fsw_embedding-69"><a href="#test_fsw_embedding-69"><span class="linenos"> 69</span></a>    <span class="c1"># optimize_slices uses mutual coherence minimization to make the slices better spread</span>
</span><span id="test_fsw_embedding-70"><a href="#test_fsw_embedding-70"><span class="linenos"> 70</span></a>    <span class="c1"># so far most settings both techniques did not yield dramatic improvement of performance</span>
</span><span id="test_fsw_embedding-71"><a href="#test_fsw_embedding-71"><span class="linenos"> 71</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-72"><a href="#test_fsw_embedding-72"><span class="linenos"> 72</span></a>    <span class="n">embed2</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-73"><a href="#test_fsw_embedding-73"><span class="linenos"> 73</span></a>
</span><span id="test_fsw_embedding-74"><a href="#test_fsw_embedding-74"><span class="linenos"> 74</span></a>    <span class="c1"># embed.to(&#39;cpu&#39;, torch.float32)</span>
</span><span id="test_fsw_embedding-75"><a href="#test_fsw_embedding-75"><span class="linenos"> 75</span></a>    <span class="c1"># print(&#39;Embed type: &#39;, embed.dtype, &#39;device: &#39;, embed.device)</span>
</span><span id="test_fsw_embedding-76"><a href="#test_fsw_embedding-76"><span class="linenos"> 76</span></a>    <span class="c1"># embed.to(&#39;cpu&#39;, dtype=torch.float64)</span>
</span><span id="test_fsw_embedding-77"><a href="#test_fsw_embedding-77"><span class="linenos"> 77</span></a>    <span class="c1"># print(&#39;Embed type: &#39;, embed.dtype, &#39;device: &#39;, embed.device)</span>
</span><span id="test_fsw_embedding-78"><a href="#test_fsw_embedding-78"><span class="linenos"> 78</span></a>    <span class="c1"># embed.to(device = &#39;cuda&#39;, dtype=torch.float32)</span>
</span><span id="test_fsw_embedding-79"><a href="#test_fsw_embedding-79"><span class="linenos"> 79</span></a>    <span class="c1"># print(&#39;Embed type: &#39;, embed.dtype, &#39;device: &#39;, embed.device)</span>
</span><span id="test_fsw_embedding-80"><a href="#test_fsw_embedding-80"><span class="linenos"> 80</span></a>    <span class="c1"># embed.to(torch.float64)</span>
</span><span id="test_fsw_embedding-81"><a href="#test_fsw_embedding-81"><span class="linenos"> 81</span></a>    <span class="c1"># print(&#39;Embed type: &#39;, embed.dtype, &#39;device: &#39;, embed.device)</span>
</span><span id="test_fsw_embedding-82"><a href="#test_fsw_embedding-82"><span class="linenos"> 82</span></a>
</span><span id="test_fsw_embedding-83"><a href="#test_fsw_embedding-83"><span class="linenos"> 83</span></a>
</span><span id="test_fsw_embedding-84"><a href="#test_fsw_embedding-84"><span class="linenos"> 84</span></a>    <span class="k">if</span> <span class="n">do_compile</span><span class="p">:</span>
</span><span id="test_fsw_embedding-85"><a href="#test_fsw_embedding-85"><span class="linenos"> 85</span></a>        <span class="n">embed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">embed</span><span class="p">)</span>
</span><span id="test_fsw_embedding-86"><a href="#test_fsw_embedding-86"><span class="linenos"> 86</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;compile 1&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-87"><a href="#test_fsw_embedding-87"><span class="linenos"> 87</span></a>        <span class="n">embed2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">embed2</span><span class="p">)</span>
</span><span id="test_fsw_embedding-88"><a href="#test_fsw_embedding-88"><span class="linenos"> 88</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;compile 2&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-89"><a href="#test_fsw_embedding-89"><span class="linenos"> 89</span></a>
</span><span id="test_fsw_embedding-90"><a href="#test_fsw_embedding-90"><span class="linenos"> 90</span></a>
</span><span id="test_fsw_embedding-91"><a href="#test_fsw_embedding-91"><span class="linenos"> 91</span></a>    <span class="n">X1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-92"><a href="#test_fsw_embedding-92"><span class="linenos"> 92</span></a>    <span class="n">X2</span> <span class="o">=</span> <span class="mf">1.1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-93"><a href="#test_fsw_embedding-93"><span class="linenos"> 93</span></a>
</span><span id="test_fsw_embedding-94"><a href="#test_fsw_embedding-94"><span class="linenos"> 94</span></a>    <span class="c1"># Approx. 20% of the weights will be zero.</span>
</span><span id="test_fsw_embedding-95"><a href="#test_fsw_embedding-95"><span class="linenos"> 95</span></a>    <span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">-</span><span class="mf">0.2</span><span class="p">)</span>
</span><span id="test_fsw_embedding-96"><a href="#test_fsw_embedding-96"><span class="linenos"> 96</span></a>    <span class="n">W2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">-</span><span class="mf">0.2</span><span class="p">)</span>
</span><span id="test_fsw_embedding-97"><a href="#test_fsw_embedding-97"><span class="linenos"> 97</span></a>
</span><span id="test_fsw_embedding-98"><a href="#test_fsw_embedding-98"><span class="linenos"> 98</span></a>    <span class="c1"># The weights do not have to be normalized, as they are normalized in the forward call.</span>
</span><span id="test_fsw_embedding-99"><a href="#test_fsw_embedding-99"><span class="linenos"> 99</span></a>    <span class="c1"># I normalized them here for convenience.</span>
</span><span id="test_fsw_embedding-100"><a href="#test_fsw_embedding-100"><span class="linenos">100</span></a>    <span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="test_fsw_embedding-101"><a href="#test_fsw_embedding-101"><span class="linenos">101</span></a>    <span class="n">W2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="test_fsw_embedding-102"><a href="#test_fsw_embedding-102"><span class="linenos">102</span></a>
</span><span id="test_fsw_embedding-103"><a href="#test_fsw_embedding-103"><span class="linenos">103</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-104"><a href="#test_fsw_embedding-104"><span class="linenos">104</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;d=</span><span class="si">%d</span><span class="s1">  n=</span><span class="si">%d</span><span class="s1">  m=</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span> <span class="p">)</span>
</span><span id="test_fsw_embedding-105"><a href="#test_fsw_embedding-105"><span class="linenos">105</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-106"><a href="#test_fsw_embedding-106"><span class="linenos">106</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Device: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</span><span id="test_fsw_embedding-107"><a href="#test_fsw_embedding-107"><span class="linenos">107</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Calculating SW embeddings... &#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-108"><a href="#test_fsw_embedding-108"><span class="linenos">108</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-109"><a href="#test_fsw_embedding-109"><span class="linenos">109</span></a>
</span><span id="test_fsw_embedding-110"><a href="#test_fsw_embedding-110"><span class="linenos">110</span></a>    <span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">();</span>
</span><span id="test_fsw_embedding-111"><a href="#test_fsw_embedding-111"><span class="linenos">111</span></a>
</span><span id="test_fsw_embedding-112"><a href="#test_fsw_embedding-112"><span class="linenos">112</span></a>    <span class="n">X1_emb</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="n">max_parallel_slices</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-113"><a href="#test_fsw_embedding-113"><span class="linenos">113</span></a>    <span class="n">X2_emb</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="n">max_parallel_slices</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-114"><a href="#test_fsw_embedding-114"><span class="linenos">114</span></a>
</span><span id="test_fsw_embedding-115"><a href="#test_fsw_embedding-115"><span class="linenos">115</span></a>    <span class="n">X1_emb2</span> <span class="o">=</span> <span class="n">embed2</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="n">max_parallel_slices</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-116"><a href="#test_fsw_embedding-116"><span class="linenos">116</span></a>    <span class="n">X2_emb2</span> <span class="o">=</span> <span class="n">embed2</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="n">max_parallel_slices</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-117"><a href="#test_fsw_embedding-117"><span class="linenos">117</span></a>
</span><span id="test_fsw_embedding-118"><a href="#test_fsw_embedding-118"><span class="linenos">118</span></a>    <span class="nb">print</span><span class="p">(</span><span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-119"><a href="#test_fsw_embedding-119"><span class="linenos">119</span></a>
</span><span id="test_fsw_embedding-120"><a href="#test_fsw_embedding-120"><span class="linenos">120</span></a>    <span class="n">t_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">();</span>
</span><span id="test_fsw_embedding-121"><a href="#test_fsw_embedding-121"><span class="linenos">121</span></a>
</span><span id="test_fsw_embedding-122"><a href="#test_fsw_embedding-122"><span class="linenos">122</span></a>
</span><span id="test_fsw_embedding-123"><a href="#test_fsw_embedding-123"><span class="linenos">123</span></a>    <span class="c1">## Monte-carlo estimation of the SW distance.</span>
</span><span id="test_fsw_embedding-124"><a href="#test_fsw_embedding-124"><span class="linenos">124</span></a>    <span class="k">if</span> <span class="n">do_monte_carlo</span><span class="p">:</span>
</span><span id="test_fsw_embedding-125"><a href="#test_fsw_embedding-125"><span class="linenos">125</span></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">ot</span>
</span><span id="test_fsw_embedding-126"><a href="#test_fsw_embedding-126"><span class="linenos">126</span></a>
</span><span id="test_fsw_embedding-127"><a href="#test_fsw_embedding-127"><span class="linenos">127</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Calculating Monte-Carlo estimation...&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-128"><a href="#test_fsw_embedding-128"><span class="linenos">128</span></a>
</span><span id="test_fsw_embedding-129"><a href="#test_fsw_embedding-129"><span class="linenos">129</span></a>        <span class="c1"># Monte-carlo estimation of the SW distance.</span>
</span><span id="test_fsw_embedding-130"><a href="#test_fsw_embedding-130"><span class="linenos">130</span></a>        <span class="n">est1</span> <span class="o">=</span> <span class="n">ot</span><span class="o">.</span><span class="n">sliced</span><span class="o">.</span><span class="n">sliced_wasserstein_distance</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">W1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">W2</span><span class="p">,</span> <span class="n">n_projections</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">projections</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="test_fsw_embedding-131"><a href="#test_fsw_embedding-131"><span class="linenos">131</span></a>        <span class="n">est2</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X1_emb</span><span class="o">-</span><span class="n">X2_emb</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">embed</span><span class="o">.</span><span class="n">_d_out</span><span class="p">)))</span>
</span><span id="test_fsw_embedding-132"><a href="#test_fsw_embedding-132"><span class="linenos">132</span></a>
</span><span id="test_fsw_embedding-133"><a href="#test_fsw_embedding-133"><span class="linenos">133</span></a>        <span class="n">rel_diff</span> <span class="o">=</span> <span class="n">reldiff</span><span class="p">(</span><span class="n">est1</span><span class="p">,</span> <span class="n">est2</span><span class="p">)</span>
</span><span id="test_fsw_embedding-134"><a href="#test_fsw_embedding-134"><span class="linenos">134</span></a>        <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-135"><a href="#test_fsw_embedding-135"><span class="linenos">135</span></a>
</span><span id="test_fsw_embedding-136"><a href="#test_fsw_embedding-136"><span class="linenos">136</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sliced Wasserstein of (X1,W1), (X2,W2) estimates:  Embedding: </span><span class="si">%.5g</span><span class="se">\t</span><span class="s1"> Sampling: </span><span class="si">%.5g</span><span class="se">\t</span><span class="s1"> Rel. diff.: </span><span class="si">%g</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">est1</span><span class="p">,</span> <span class="n">est2</span><span class="p">,</span> <span class="n">rel_diff</span><span class="p">),</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-137"><a href="#test_fsw_embedding-137"><span class="linenos">137</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="test_fsw_embedding-138"><a href="#test_fsw_embedding-138"><span class="linenos">138</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Skipping Monte-Carlo estimation&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-139"><a href="#test_fsw_embedding-139"><span class="linenos">139</span></a>        <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-140"><a href="#test_fsw_embedding-140"><span class="linenos">140</span></a>
</span><span id="test_fsw_embedding-141"><a href="#test_fsw_embedding-141"><span class="linenos">141</span></a>    <span class="c1">## Comparison between two independent embeddings</span>
</span><span id="test_fsw_embedding-142"><a href="#test_fsw_embedding-142"><span class="linenos">142</span></a>
</span><span id="test_fsw_embedding-143"><a href="#test_fsw_embedding-143"><span class="linenos">143</span></a>    <span class="n">est1</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X1_emb</span><span class="o">-</span><span class="n">X2_emb</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">embed</span><span class="o">.</span><span class="n">_d_out</span><span class="p">)))</span>
</span><span id="test_fsw_embedding-144"><a href="#test_fsw_embedding-144"><span class="linenos">144</span></a>    <span class="n">est2</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X1_emb2</span><span class="o">-</span><span class="n">X2_emb2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">embed</span><span class="o">.</span><span class="n">_d_out</span><span class="p">)))</span>
</span><span id="test_fsw_embedding-145"><a href="#test_fsw_embedding-145"><span class="linenos">145</span></a>
</span><span id="test_fsw_embedding-146"><a href="#test_fsw_embedding-146"><span class="linenos">146</span></a>    <span class="n">rel_diff</span> <span class="o">=</span> <span class="n">reldiff</span><span class="p">(</span><span class="n">est1</span><span class="p">,</span> <span class="n">est2</span><span class="p">)</span>
</span><span id="test_fsw_embedding-147"><a href="#test_fsw_embedding-147"><span class="linenos">147</span></a>
</span><span id="test_fsw_embedding-148"><a href="#test_fsw_embedding-148"><span class="linenos">148</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sliced Wasserstein of (X1,W1), (X2,W2) estimates:  Embedding 1: </span><span class="si">%.5g</span><span class="se">\t</span><span class="s1"> Embedding 2: </span><span class="si">%.5g</span><span class="se">\t</span><span class="s1"> Rel. diff.: </span><span class="si">%g</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">est1</span><span class="p">,</span> <span class="n">est2</span><span class="p">,</span> <span class="n">rel_diff</span><span class="p">))</span>
</span><span id="test_fsw_embedding-149"><a href="#test_fsw_embedding-149"><span class="linenos">149</span></a>
</span><span id="test_fsw_embedding-150"><a href="#test_fsw_embedding-150"><span class="linenos">150</span></a>
</span><span id="test_fsw_embedding-151"><a href="#test_fsw_embedding-151"><span class="linenos">151</span></a>    <span class="c1">## Comparison with ground truth</span>
</span><span id="test_fsw_embedding-152"><a href="#test_fsw_embedding-152"><span class="linenos">152</span></a>
</span><span id="test_fsw_embedding-153"><a href="#test_fsw_embedding-153"><span class="linenos">153</span></a>    <span class="n">SWass_est</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X1_emb</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">embed</span><span class="o">.</span><span class="n">_d_out</span><span class="p">))</span>
</span><span id="test_fsw_embedding-154"><a href="#test_fsw_embedding-154"><span class="linenos">154</span></a>    <span class="n">SWass_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">W1</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">))))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</span><span id="test_fsw_embedding-155"><a href="#test_fsw_embedding-155"><span class="linenos">155</span></a>    <span class="n">rel_err</span> <span class="o">=</span> <span class="n">rel_diff</span> <span class="o">=</span> <span class="n">reldiff</span><span class="p">(</span><span class="n">SWass_est</span><span class="p">,</span> <span class="n">SWass_true</span><span class="p">)</span>
</span><span id="test_fsw_embedding-156"><a href="#test_fsw_embedding-156"><span class="linenos">156</span></a>
</span><span id="test_fsw_embedding-157"><a href="#test_fsw_embedding-157"><span class="linenos">157</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sliced Wasserstein of (X1,W1) to delta_0:          Embedding: </span><span class="si">%.5g</span><span class="se">\t</span><span class="s1"> Ground truth: </span><span class="si">%.5g</span><span class="se">\t</span><span class="s1"> Rel. error: </span><span class="si">%g</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">SWass_est</span><span class="p">,</span> <span class="n">SWass_true</span><span class="p">,</span> <span class="n">rel_err</span><span class="p">))</span>
</span><span id="test_fsw_embedding-158"><a href="#test_fsw_embedding-158"><span class="linenos">158</span></a>
</span><span id="test_fsw_embedding-159"><a href="#test_fsw_embedding-159"><span class="linenos">159</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-160"><a href="#test_fsw_embedding-160"><span class="linenos">160</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Avg. embedding calculation time: </span><span class="si">%.2f</span><span class="s1"> s&#39;</span> <span class="o">%</span> <span class="p">((</span><span class="n">t_end</span><span class="o">-</span><span class="n">t_start</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span><span class="p">))</span>
</span><span id="test_fsw_embedding-161"><a href="#test_fsw_embedding-161"><span class="linenos">161</span></a>
</span><span id="test_fsw_embedding-162"><a href="#test_fsw_embedding-162"><span class="linenos">162</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-163"><a href="#test_fsw_embedding-163"><span class="linenos">163</span></a>
</span><span id="test_fsw_embedding-164"><a href="#test_fsw_embedding-164"><span class="linenos">164</span></a>
</span><span id="test_fsw_embedding-165"><a href="#test_fsw_embedding-165"><span class="linenos">165</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d_out</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">collapse_output_axes</span> <span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="test_fsw_embedding-166"><a href="#test_fsw_embedding-166"><span class="linenos">166</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-167"><a href="#test_fsw_embedding-167"><span class="linenos">167</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-168"><a href="#test_fsw_embedding-168"><span class="linenos">168</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-169"><a href="#test_fsw_embedding-169"><span class="linenos">169</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-170"><a href="#test_fsw_embedding-170"><span class="linenos">170</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-171"><a href="#test_fsw_embedding-171"><span class="linenos">171</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-172"><a href="#test_fsw_embedding-172"><span class="linenos">172</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-173"><a href="#test_fsw_embedding-173"><span class="linenos">173</span></a>
</span><span id="test_fsw_embedding-174"><a href="#test_fsw_embedding-174"><span class="linenos">174</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">num_slices</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="o">=</span><span class="mi">37</span><span class="p">,</span> <span class="n">collapse_output_axes</span> <span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="test_fsw_embedding-175"><a href="#test_fsw_embedding-175"><span class="linenos">175</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-176"><a href="#test_fsw_embedding-176"><span class="linenos">176</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-177"><a href="#test_fsw_embedding-177"><span class="linenos">177</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-178"><a href="#test_fsw_embedding-178"><span class="linenos">178</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-179"><a href="#test_fsw_embedding-179"><span class="linenos">179</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-180"><a href="#test_fsw_embedding-180"><span class="linenos">180</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-181"><a href="#test_fsw_embedding-181"><span class="linenos">181</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-182"><a href="#test_fsw_embedding-182"><span class="linenos">182</span></a>
</span><span id="test_fsw_embedding-183"><a href="#test_fsw_embedding-183"><span class="linenos">183</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">num_slices</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="o">=</span><span class="mi">37</span><span class="p">,</span> <span class="n">collapse_output_axes</span> <span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="test_fsw_embedding-184"><a href="#test_fsw_embedding-184"><span class="linenos">184</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-185"><a href="#test_fsw_embedding-185"><span class="linenos">185</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-186"><a href="#test_fsw_embedding-186"><span class="linenos">186</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-187"><a href="#test_fsw_embedding-187"><span class="linenos">187</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-188"><a href="#test_fsw_embedding-188"><span class="linenos">188</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-189"><a href="#test_fsw_embedding-189"><span class="linenos">189</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-190"><a href="#test_fsw_embedding-190"><span class="linenos">190</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Serialization err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">),</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">max_parallel_slices</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>  <span class="p">))</span>
</span><span id="test_fsw_embedding-191"><a href="#test_fsw_embedding-191"><span class="linenos">191</span></a>
</span><span id="test_fsw_embedding-192"><a href="#test_fsw_embedding-192"><span class="linenos">192</span></a>
</span><span id="test_fsw_embedding-193"><a href="#test_fsw_embedding-193"><span class="linenos">193</span></a>
</span><span id="test_fsw_embedding-194"><a href="#test_fsw_embedding-194"><span class="linenos">194</span></a>    <span class="c1"># x = torch.tensor([4.0, 2.0, 1.5, 0.5], requires_grad=True)</span>
</span><span id="test_fsw_embedding-195"><a href="#test_fsw_embedding-195"><span class="linenos">195</span></a>    <span class="c1"># out = torch.sin(x) * torch.cos(x) + x.pow(2)</span>
</span><span id="test_fsw_embedding-196"><a href="#test_fsw_embedding-196"><span class="linenos">196</span></a>    <span class="c1"># # Pass tensor of ones, each for each item in x</span>
</span><span id="test_fsw_embedding-197"><a href="#test_fsw_embedding-197"><span class="linenos">197</span></a>    <span class="c1"># out.backward(torch.ones_like(x))</span>
</span><span id="test_fsw_embedding-198"><a href="#test_fsw_embedding-198"><span class="linenos">198</span></a>    <span class="c1"># print(&#39;aaaaa&#39;, x.grad)</span>
</span><span id="test_fsw_embedding-199"><a href="#test_fsw_embedding-199"><span class="linenos">199</span></a>
</span><span id="test_fsw_embedding-200"><a href="#test_fsw_embedding-200"><span class="linenos">200</span></a>
</span><span id="test_fsw_embedding-201"><a href="#test_fsw_embedding-201"><span class="linenos">201</span></a>    <span class="c1"># Test graph mode:</span>
</span><span id="test_fsw_embedding-202"><a href="#test_fsw_embedding-202"><span class="linenos">202</span></a>
</span><span id="test_fsw_embedding-203"><a href="#test_fsw_embedding-203"><span class="linenos">203</span></a>    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
</span><span id="test_fsw_embedding-204"><a href="#test_fsw_embedding-204"><span class="linenos">204</span></a>    <span class="n">d</span> <span class="o">=</span> <span class="mi">15</span>
</span><span id="test_fsw_embedding-205"><a href="#test_fsw_embedding-205"><span class="linenos">205</span></a>
</span><span id="test_fsw_embedding-206"><a href="#test_fsw_embedding-206"><span class="linenos">206</span></a>    <span class="k">if</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="test_fsw_embedding-207"><a href="#test_fsw_embedding-207"><span class="linenos">207</span></a>        <span class="n">m</span><span class="o">=</span><span class="mi">23</span>
</span><span id="test_fsw_embedding-208"><a href="#test_fsw_embedding-208"><span class="linenos">208</span></a>        <span class="n">num_slices</span><span class="o">=</span><span class="kc">None</span>
</span><span id="test_fsw_embedding-209"><a href="#test_fsw_embedding-209"><span class="linenos">209</span></a>        <span class="n">num_frequencies</span><span class="o">=</span><span class="kc">None</span>
</span><span id="test_fsw_embedding-210"><a href="#test_fsw_embedding-210"><span class="linenos">210</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="test_fsw_embedding-211"><a href="#test_fsw_embedding-211"><span class="linenos">211</span></a>        <span class="n">m</span><span class="o">=</span><span class="kc">None</span>
</span><span id="test_fsw_embedding-212"><a href="#test_fsw_embedding-212"><span class="linenos">212</span></a>        <span class="n">num_slices</span><span class="o">=</span><span class="mi">19</span>
</span><span id="test_fsw_embedding-213"><a href="#test_fsw_embedding-213"><span class="linenos">213</span></a>        <span class="n">num_frequencies</span><span class="o">=</span><span class="mi">17</span>
</span><span id="test_fsw_embedding-214"><a href="#test_fsw_embedding-214"><span class="linenos">214</span></a>
</span><span id="test_fsw_embedding-215"><a href="#test_fsw_embedding-215"><span class="linenos">215</span></a>    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-216"><a href="#test_fsw_embedding-216"><span class="linenos">216</span></a>    <span class="n">Wx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">-</span><span class="mf">0.2</span><span class="p">)</span>
</span><span id="test_fsw_embedding-217"><a href="#test_fsw_embedding-217"><span class="linenos">217</span></a>
</span><span id="test_fsw_embedding-218"><a href="#test_fsw_embedding-218"><span class="linenos">218</span></a>    <span class="c1">#X.requires_grad = True</span>
</span><span id="test_fsw_embedding-219"><a href="#test_fsw_embedding-219"><span class="linenos">219</span></a>    <span class="c1">#Wx.requires_grad = True</span>
</span><span id="test_fsw_embedding-220"><a href="#test_fsw_embedding-220"><span class="linenos">220</span></a>
</span><span id="test_fsw_embedding-221"><a href="#test_fsw_embedding-221"><span class="linenos">221</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d_out</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">num_slices</span><span class="o">=</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span><span class="o">=</span><span class="n">num_frequencies</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="test_fsw_embedding-222"><a href="#test_fsw_embedding-222"><span class="linenos">222</span></a>    <span class="c1">#embed = FSWEmbedding(d, num_slices=15, num_frequencies=7, collapse_output_axes =False, device=device, dtype=dtype)</span>
</span><span id="test_fsw_embedding-223"><a href="#test_fsw_embedding-223"><span class="linenos">223</span></a>
</span><span id="test_fsw_embedding-224"><a href="#test_fsw_embedding-224"><span class="linenos">224</span></a>    <span class="n">Xx</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Wx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],))</span>
</span><span id="test_fsw_embedding-225"><a href="#test_fsw_embedding-225"><span class="linenos">225</span></a>
</span><span id="test_fsw_embedding-226"><a href="#test_fsw_embedding-226"><span class="linenos">226</span></a>    <span class="n">emb1</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span> <span class="n">Wx</span><span class="p">)</span>
</span><span id="test_fsw_embedding-227"><a href="#test_fsw_embedding-227"><span class="linenos">227</span></a>
</span><span id="test_fsw_embedding-228"><a href="#test_fsw_embedding-228"><span class="linenos">228</span></a>    <span class="n">emb1a</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span><span class="n">Wx</span><span class="p">)</span>
</span><span id="test_fsw_embedding-229"><a href="#test_fsw_embedding-229"><span class="linenos">229</span></a>    <span class="n">emb1b</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">())</span>
</span><span id="test_fsw_embedding-230"><a href="#test_fsw_embedding-230"><span class="linenos">230</span></a>    <span class="n">emb1c</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">(),</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="test_fsw_embedding-231"><a href="#test_fsw_embedding-231"><span class="linenos">231</span></a>    <span class="n">emb1d</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span><span class="n">Wx</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="test_fsw_embedding-232"><a href="#test_fsw_embedding-232"><span class="linenos">232</span></a>
</span><span id="test_fsw_embedding-233"><a href="#test_fsw_embedding-233"><span class="linenos">233</span></a>    <span class="n">emb2a</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">(),</span> <span class="n">graph_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="test_fsw_embedding-234"><a href="#test_fsw_embedding-234"><span class="linenos">234</span></a>
</span><span id="test_fsw_embedding-235"><a href="#test_fsw_embedding-235"><span class="linenos">235</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=========================================&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-236"><a href="#test_fsw_embedding-236"><span class="linenos">236</span></a>    <span class="n">emb2b</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">(),</span> <span class="n">graph_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-237"><a href="#test_fsw_embedding-237"><span class="linenos">237</span></a>    <span class="c1">#emb2c = embed(X,Wx, graph_mode=True)</span>
</span><span id="test_fsw_embedding-238"><a href="#test_fsw_embedding-238"><span class="linenos">238</span></a>
</span><span id="test_fsw_embedding-239"><a href="#test_fsw_embedding-239"><span class="linenos">239</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 1a: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1</span><span class="p">,</span><span class="n">emb1a</span><span class="p">))</span>
</span><span id="test_fsw_embedding-240"><a href="#test_fsw_embedding-240"><span class="linenos">240</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 1b: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1</span><span class="p">,</span><span class="n">emb1b</span><span class="p">))</span>
</span><span id="test_fsw_embedding-241"><a href="#test_fsw_embedding-241"><span class="linenos">241</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 1c: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1</span><span class="p">,</span><span class="n">emb1c</span><span class="p">))</span>
</span><span id="test_fsw_embedding-242"><a href="#test_fsw_embedding-242"><span class="linenos">242</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 1d: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1</span><span class="p">,</span><span class="n">emb1d</span><span class="p">))</span>
</span><span id="test_fsw_embedding-243"><a href="#test_fsw_embedding-243"><span class="linenos">243</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 2a: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1</span><span class="p">,</span><span class="n">emb2a</span><span class="p">))</span>
</span><span id="test_fsw_embedding-244"><a href="#test_fsw_embedding-244"><span class="linenos">244</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 2b: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1</span><span class="p">,</span><span class="n">emb2b</span><span class="p">))</span>
</span><span id="test_fsw_embedding-245"><a href="#test_fsw_embedding-245"><span class="linenos">245</span></a>    <span class="c1">#print(&#39;Graph mode error 2c: &#39;, relerr(emb1,emb2c))</span>
</span><span id="test_fsw_embedding-246"><a href="#test_fsw_embedding-246"><span class="linenos">246</span></a>
</span><span id="test_fsw_embedding-247"><a href="#test_fsw_embedding-247"><span class="linenos">247</span></a>    <span class="k">if</span> <span class="kc">False</span><span class="p">:</span>
</span><span id="test_fsw_embedding-248"><a href="#test_fsw_embedding-248"><span class="linenos">248</span></a>        <span class="kn">from</span><span class="w"> </span><span class="nn">swe_works</span><span class="w"> </span><span class="kn">import</span> <span class="n">SW_embed</span> <span class="k">as</span> <span class="n">SWE</span>
</span><span id="test_fsw_embedding-249"><a href="#test_fsw_embedding-249"><span class="linenos">249</span></a>        <span class="n">embedw</span> <span class="o">=</span> <span class="n">SWE</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="test_fsw_embedding-250"><a href="#test_fsw_embedding-250"><span class="linenos">250</span></a>
</span><span id="test_fsw_embedding-251"><a href="#test_fsw_embedding-251"><span class="linenos">251</span></a>        <span class="n">sd</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</span><span id="test_fsw_embedding-252"><a href="#test_fsw_embedding-252"><span class="linenos">252</span></a>        <span class="n">embedw</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">sd</span><span class="p">)</span> <span class="c1"># your error</span>
</span><span id="test_fsw_embedding-253"><a href="#test_fsw_embedding-253"><span class="linenos">253</span></a>
</span><span id="test_fsw_embedding-254"><a href="#test_fsw_embedding-254"><span class="linenos">254</span></a>        <span class="n">emb1aw</span> <span class="o">=</span> <span class="n">embedw</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">())</span>
</span><span id="test_fsw_embedding-255"><a href="#test_fsw_embedding-255"><span class="linenos">255</span></a>        <span class="n">emb1bw</span> <span class="o">=</span> <span class="n">embedw</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">(),</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</span><span id="test_fsw_embedding-256"><a href="#test_fsw_embedding-256"><span class="linenos">256</span></a>        <span class="n">emb1cw</span> <span class="o">=</span> <span class="n">embedw</span><span class="p">(</span><span class="n">Xx</span><span class="p">,</span><span class="n">Wx</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</span><span id="test_fsw_embedding-257"><a href="#test_fsw_embedding-257"><span class="linenos">257</span></a>
</span><span id="test_fsw_embedding-258"><a href="#test_fsw_embedding-258"><span class="linenos">258</span></a>        <span class="n">emb2aw</span> <span class="o">=</span> <span class="n">embedw</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">(),</span> <span class="n">graph_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</span><span id="test_fsw_embedding-259"><a href="#test_fsw_embedding-259"><span class="linenos">259</span></a>        <span class="n">emb2bw</span> <span class="o">=</span> <span class="n">embedw</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Wx</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">(),</span> <span class="n">graph_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-260"><a href="#test_fsw_embedding-260"><span class="linenos">260</span></a>        <span class="n">emb2cw</span> <span class="o">=</span> <span class="n">embedw</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Wx</span><span class="p">,</span> <span class="n">graph_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-261"><a href="#test_fsw_embedding-261"><span class="linenos">261</span></a>
</span><span id="test_fsw_embedding-262"><a href="#test_fsw_embedding-262"><span class="linenos">262</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Graph mode error 1a: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1aw</span><span class="p">,</span><span class="n">emb1a</span><span class="p">))</span>
</span><span id="test_fsw_embedding-263"><a href="#test_fsw_embedding-263"><span class="linenos">263</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 1b: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1bw</span><span class="p">,</span><span class="n">emb1b</span><span class="p">))</span>
</span><span id="test_fsw_embedding-264"><a href="#test_fsw_embedding-264"><span class="linenos">264</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 1c: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1cw</span><span class="p">,</span><span class="n">emb1c</span><span class="p">))</span>
</span><span id="test_fsw_embedding-265"><a href="#test_fsw_embedding-265"><span class="linenos">265</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 2a: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb2aw</span><span class="p">,</span><span class="n">emb2a</span><span class="p">))</span>
</span><span id="test_fsw_embedding-266"><a href="#test_fsw_embedding-266"><span class="linenos">266</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 2b: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb2bw</span><span class="p">,</span><span class="n">emb2b</span><span class="p">))</span>
</span><span id="test_fsw_embedding-267"><a href="#test_fsw_embedding-267"><span class="linenos">267</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Graph mode error 2c: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb2cw</span><span class="p">,</span><span class="n">emb2c</span><span class="p">))</span>
</span><span id="test_fsw_embedding-268"><a href="#test_fsw_embedding-268"><span class="linenos">268</span></a>
</span><span id="test_fsw_embedding-269"><a href="#test_fsw_embedding-269"><span class="linenos">269</span></a>    <span class="c1"># exit()</span>
</span><span id="test_fsw_embedding-270"><a href="#test_fsw_embedding-270"><span class="linenos">270</span></a>
</span><span id="test_fsw_embedding-271"><a href="#test_fsw_embedding-271"><span class="linenos">271</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=========================================&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-272"><a href="#test_fsw_embedding-272"><span class="linenos">272</span></a>
</span><span id="test_fsw_embedding-273"><a href="#test_fsw_embedding-273"><span class="linenos">273</span></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-274"><a href="#test_fsw_embedding-274"><span class="linenos">274</span></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sinc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="test_fsw_embedding-275"><a href="#test_fsw_embedding-275"><span class="linenos">275</span></a>    <span class="n">dy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="test_fsw_embedding-276"><a href="#test_fsw_embedding-276"><span class="linenos">276</span></a>    <span class="c1">#y, dy = sw_embedding.sinc_dsinc(x)</span>
</span><span id="test_fsw_embedding-277"><a href="#test_fsw_embedding-277"><span class="linenos">277</span></a>
</span><span id="test_fsw_embedding-278"><a href="#test_fsw_embedding-278"><span class="linenos">278</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dsinc err: &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">sinc</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">x</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="p">)</span>
</span><span id="test_fsw_embedding-279"><a href="#test_fsw_embedding-279"><span class="linenos">279</span></a>
</span><span id="test_fsw_embedding-280"><a href="#test_fsw_embedding-280"><span class="linenos">280</span></a>
</span><span id="test_fsw_embedding-281"><a href="#test_fsw_embedding-281"><span class="linenos">281</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=========================================&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-282"><a href="#test_fsw_embedding-282"><span class="linenos">282</span></a>
</span><span id="test_fsw_embedding-283"><a href="#test_fsw_embedding-283"><span class="linenos">283</span></a>    <span class="c1"># Testing gradient</span>
</span><span id="test_fsw_embedding-284"><a href="#test_fsw_embedding-284"><span class="linenos">284</span></a>    <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
</span><span id="test_fsw_embedding-285"><a href="#test_fsw_embedding-285"><span class="linenos">285</span></a>    <span class="n">d</span> <span class="o">=</span> <span class="mi">64</span>
</span><span id="test_fsw_embedding-286"><a href="#test_fsw_embedding-286"><span class="linenos">286</span></a>
</span><span id="test_fsw_embedding-287"><a href="#test_fsw_embedding-287"><span class="linenos">287</span></a>    <span class="n">m</span> <span class="o">=</span> <span class="mi">100</span>
</span><span id="test_fsw_embedding-288"><a href="#test_fsw_embedding-288"><span class="linenos">288</span></a>
</span><span id="test_fsw_embedding-289"><a href="#test_fsw_embedding-289"><span class="linenos">289</span></a>    <span class="n">num_slices</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-290"><a href="#test_fsw_embedding-290"><span class="linenos">290</span></a>    <span class="n">nFreq</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-291"><a href="#test_fsw_embedding-291"><span class="linenos">291</span></a>
</span><span id="test_fsw_embedding-292"><a href="#test_fsw_embedding-292"><span class="linenos">292</span></a>    <span class="c1"># m = None</span>
</span><span id="test_fsw_embedding-293"><a href="#test_fsw_embedding-293"><span class="linenos">293</span></a>    <span class="c1"># num_slices = 20</span>
</span><span id="test_fsw_embedding-294"><a href="#test_fsw_embedding-294"><span class="linenos">294</span></a>    <span class="c1"># num_frequencies =  50</span>
</span><span id="test_fsw_embedding-295"><a href="#test_fsw_embedding-295"><span class="linenos">295</span></a>
</span><span id="test_fsw_embedding-296"><a href="#test_fsw_embedding-296"><span class="linenos">296</span></a>    <span class="n">graph_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="test_fsw_embedding-297"><a href="#test_fsw_embedding-297"><span class="linenos">297</span></a>
</span><span id="test_fsw_embedding-298"><a href="#test_fsw_embedding-298"><span class="linenos">298</span></a>    <span class="n">test_grad_X</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-299"><a href="#test_fsw_embedding-299"><span class="linenos">299</span></a>    <span class="n">test_grad_W</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-300"><a href="#test_fsw_embedding-300"><span class="linenos">300</span></a>    <span class="n">test_grad_slices</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-301"><a href="#test_fsw_embedding-301"><span class="linenos">301</span></a>    <span class="n">test_grad_freqs</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-302"><a href="#test_fsw_embedding-302"><span class="linenos">302</span></a>    <span class="n">test_grad_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-303"><a href="#test_fsw_embedding-303"><span class="linenos">303</span></a>
</span><span id="test_fsw_embedding-304"><a href="#test_fsw_embedding-304"><span class="linenos">304</span></a>    <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">graph_mode</span> <span class="k">else</span> <span class="p">(</span><span class="n">n</span><span class="p">,)</span>
</span><span id="test_fsw_embedding-305"><a href="#test_fsw_embedding-305"><span class="linenos">305</span></a>
</span><span id="test_fsw_embedding-306"><a href="#test_fsw_embedding-306"><span class="linenos">306</span></a>    <span class="n">X1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-307"><a href="#test_fsw_embedding-307"><span class="linenos">307</span></a>    <span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">-</span><span class="mf">0.2</span><span class="p">)</span>
</span><span id="test_fsw_embedding-308"><a href="#test_fsw_embedding-308"><span class="linenos">308</span></a>
</span><span id="test_fsw_embedding-309"><a href="#test_fsw_embedding-309"><span class="linenos">309</span></a>    <span class="n">X2</span> <span class="o">=</span> <span class="n">X1</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="test_fsw_embedding-310"><a href="#test_fsw_embedding-310"><span class="linenos">310</span></a>    <span class="n">W2</span> <span class="o">=</span> <span class="n">W1</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
</span><span id="test_fsw_embedding-311"><a href="#test_fsw_embedding-311"><span class="linenos">311</span></a>
</span><span id="test_fsw_embedding-312"><a href="#test_fsw_embedding-312"><span class="linenos">312</span></a>    <span class="n">W2</span><span class="o">.</span><span class="n">values</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="test_fsw_embedding-313"><a href="#test_fsw_embedding-313"><span class="linenos">313</span></a>    <span class="n">W1</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">indices</span><span class="p">()[:,</span><span class="mi">0</span><span class="p">])]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="test_fsw_embedding-314"><a href="#test_fsw_embedding-314"><span class="linenos">314</span></a>
</span><span id="test_fsw_embedding-315"><a href="#test_fsw_embedding-315"><span class="linenos">315</span></a>    <span class="n">X1</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">test_grad_X</span>
</span><span id="test_fsw_embedding-316"><a href="#test_fsw_embedding-316"><span class="linenos">316</span></a>    <span class="n">X2</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">test_grad_X</span>
</span><span id="test_fsw_embedding-317"><a href="#test_fsw_embedding-317"><span class="linenos">317</span></a>
</span><span id="test_fsw_embedding-318"><a href="#test_fsw_embedding-318"><span class="linenos">318</span></a>    <span class="n">W1</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">test_grad_W</span>
</span><span id="test_fsw_embedding-319"><a href="#test_fsw_embedding-319"><span class="linenos">319</span></a>    <span class="n">W2</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">test_grad_W</span>
</span><span id="test_fsw_embedding-320"><a href="#test_fsw_embedding-320"><span class="linenos">320</span></a>
</span><span id="test_fsw_embedding-321"><a href="#test_fsw_embedding-321"><span class="linenos">321</span></a>    <span class="c1"># Embed 1</span>
</span><span id="test_fsw_embedding-322"><a href="#test_fsw_embedding-322"><span class="linenos">322</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d_in</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">d_out</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">num_slices</span><span class="o">=</span><span class="n">num_slices</span><span class="p">,</span> <span class="n">num_frequencies</span> <span class="o">=</span> <span class="n">num_frequencies</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">learnable_slices</span><span class="o">=</span><span class="n">test_grad_slices</span><span class="p">,</span> <span class="n">learnable_frequencies</span><span class="o">=</span><span class="n">test_grad_freqs</span><span class="p">,</span> <span class="n">minimize_slice_coherence</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">frequency_init</span><span class="o">=</span><span class="s1">&#39;even&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-323"><a href="#test_fsw_embedding-323"><span class="linenos">323</span></a>
</span><span id="test_fsw_embedding-324"><a href="#test_fsw_embedding-324"><span class="linenos">324</span></a>    <span class="n">emb1</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">graph_mode</span><span class="o">=</span><span class="n">graph_mode</span><span class="p">)</span>
</span><span id="test_fsw_embedding-325"><a href="#test_fsw_embedding-325"><span class="linenos">325</span></a>    <span class="n">S1</span> <span class="o">=</span> <span class="n">emb1</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="test_fsw_embedding-326"><a href="#test_fsw_embedding-326"><span class="linenos">326</span></a>    <span class="n">S1</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="test_fsw_embedding-327"><a href="#test_fsw_embedding-327"><span class="linenos">327</span></a>
</span><span id="test_fsw_embedding-328"><a href="#test_fsw_embedding-328"><span class="linenos">328</span></a>    <span class="n">proj_grad1</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">test_grad_slices</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-329"><a href="#test_fsw_embedding-329"><span class="linenos">329</span></a>    <span class="n">freqs_grad1</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">frequencies</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">test_grad_freqs</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-330"><a href="#test_fsw_embedding-330"><span class="linenos">330</span></a>    <span class="n">bias_grad1</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">test_grad_bias</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-331"><a href="#test_fsw_embedding-331"><span class="linenos">331</span></a>
</span><span id="test_fsw_embedding-332"><a href="#test_fsw_embedding-332"><span class="linenos">332</span></a>    <span class="c1"># Embed 2</span>
</span><span id="test_fsw_embedding-333"><a href="#test_fsw_embedding-333"><span class="linenos">333</span></a>    <span class="n">embed</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="test_fsw_embedding-334"><a href="#test_fsw_embedding-334"><span class="linenos">334</span></a>
</span><span id="test_fsw_embedding-335"><a href="#test_fsw_embedding-335"><span class="linenos">335</span></a>    <span class="n">emb2</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">graph_mode</span><span class="o">=</span><span class="n">graph_mode</span><span class="p">)</span>
</span><span id="test_fsw_embedding-336"><a href="#test_fsw_embedding-336"><span class="linenos">336</span></a>    <span class="n">S2</span> <span class="o">=</span> <span class="n">emb2</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="test_fsw_embedding-337"><a href="#test_fsw_embedding-337"><span class="linenos">337</span></a>    <span class="n">S2</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="test_fsw_embedding-338"><a href="#test_fsw_embedding-338"><span class="linenos">338</span></a>
</span><span id="test_fsw_embedding-339"><a href="#test_fsw_embedding-339"><span class="linenos">339</span></a>    <span class="n">proj_grad2</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">slice_vectors</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">test_grad_slices</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-340"><a href="#test_fsw_embedding-340"><span class="linenos">340</span></a>    <span class="n">freqs_grad2</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">frequencies</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">test_grad_freqs</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-341"><a href="#test_fsw_embedding-341"><span class="linenos">341</span></a>    <span class="n">bias_grad2</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">test_grad_bias</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="test_fsw_embedding-342"><a href="#test_fsw_embedding-342"><span class="linenos">342</span></a>
</span><span id="test_fsw_embedding-343"><a href="#test_fsw_embedding-343"><span class="linenos">343</span></a>    <span class="c1"># Compare gradients</span>
</span><span id="test_fsw_embedding-344"><a href="#test_fsw_embedding-344"><span class="linenos">344</span></a>
</span><span id="test_fsw_embedding-345"><a href="#test_fsw_embedding-345"><span class="linenos">345</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-346"><a href="#test_fsw_embedding-346"><span class="linenos">346</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sparsity error:   &#39;</span><span class="p">,</span> <span class="n">relerr</span><span class="p">(</span><span class="n">emb1</span><span class="p">,</span><span class="n">emb2</span><span class="p">))</span>
</span><span id="test_fsw_embedding-347"><a href="#test_fsw_embedding-347"><span class="linenos">347</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-348"><a href="#test_fsw_embedding-348"><span class="linenos">348</span></a>
</span><span id="test_fsw_embedding-349"><a href="#test_fsw_embedding-349"><span class="linenos">349</span></a>    <span class="k">if</span> <span class="n">test_grad_X</span><span class="p">:</span>
</span><span id="test_fsw_embedding-350"><a href="#test_fsw_embedding-350"><span class="linenos">350</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Grad X error:     &#39;</span><span class="p">,</span> <span class="n">reldiff</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">X2</span><span class="o">.</span><span class="n">grad</span><span class="p">))</span>
</span><span id="test_fsw_embedding-351"><a href="#test_fsw_embedding-351"><span class="linenos">351</span></a>
</span><span id="test_fsw_embedding-352"><a href="#test_fsw_embedding-352"><span class="linenos">352</span></a>    <span class="k">if</span> <span class="n">test_grad_W</span><span class="p">:</span>
</span><span id="test_fsw_embedding-353"><a href="#test_fsw_embedding-353"><span class="linenos">353</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Grad W error:     &#39;</span><span class="p">,</span> <span class="n">reldiff</span><span class="p">(</span>   <span class="n">W2</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()[</span><span class="n">W2</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">],</span> <span class="n">W1</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()[</span><span class="n">W2</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>    <span class="p">))</span>
</span><span id="test_fsw_embedding-354"><a href="#test_fsw_embedding-354"><span class="linenos">354</span></a>
</span><span id="test_fsw_embedding-355"><a href="#test_fsw_embedding-355"><span class="linenos">355</span></a>    <span class="k">if</span> <span class="n">test_grad_slices</span><span class="p">:</span>
</span><span id="test_fsw_embedding-356"><a href="#test_fsw_embedding-356"><span class="linenos">356</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Grad projs error: &#39;</span><span class="p">,</span> <span class="n">reldiff</span><span class="p">(</span><span class="n">proj_grad1</span><span class="p">,</span> <span class="n">proj_grad2</span><span class="p">))</span>
</span><span id="test_fsw_embedding-357"><a href="#test_fsw_embedding-357"><span class="linenos">357</span></a>
</span><span id="test_fsw_embedding-358"><a href="#test_fsw_embedding-358"><span class="linenos">358</span></a>    <span class="k">if</span> <span class="n">test_grad_freqs</span><span class="p">:</span>
</span><span id="test_fsw_embedding-359"><a href="#test_fsw_embedding-359"><span class="linenos">359</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Grad frequencies error: &#39;</span><span class="p">,</span> <span class="n">reldiff</span><span class="p">(</span><span class="n">freqs_grad1</span><span class="p">,</span> <span class="n">freqs_grad2</span><span class="p">))</span>
</span><span id="test_fsw_embedding-360"><a href="#test_fsw_embedding-360"><span class="linenos">360</span></a>
</span><span id="test_fsw_embedding-361"><a href="#test_fsw_embedding-361"><span class="linenos">361</span></a>    <span class="k">if</span> <span class="n">test_grad_bias</span><span class="p">:</span>
</span><span id="test_fsw_embedding-362"><a href="#test_fsw_embedding-362"><span class="linenos">362</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Grad bias error: &#39;</span><span class="p">,</span> <span class="n">reldiff</span><span class="p">(</span><span class="n">bias_grad1</span><span class="p">,</span> <span class="n">bias_grad2</span><span class="p">))</span>
</span><span id="test_fsw_embedding-363"><a href="#test_fsw_embedding-363"><span class="linenos">363</span></a>
</span><span id="test_fsw_embedding-364"><a href="#test_fsw_embedding-364"><span class="linenos">364</span></a>    <span class="c1"># W1 = FSWEmbedding.project_W(W1, 1e-8)</span>
</span><span id="test_fsw_embedding-365"><a href="#test_fsw_embedding-365"><span class="linenos">365</span></a>    <span class="c1"># W2 = FSWEmbedding.project_W(W2, 1e-8)</span>
</span><span id="test_fsw_embedding-366"><a href="#test_fsw_embedding-366"><span class="linenos">366</span></a>
</span><span id="test_fsw_embedding-367"><a href="#test_fsw_embedding-367"><span class="linenos">367</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-368"><a href="#test_fsw_embedding-368"><span class="linenos">368</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=========================================&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-369"><a href="#test_fsw_embedding-369"><span class="linenos">369</span></a>
</span><span id="test_fsw_embedding-370"><a href="#test_fsw_embedding-370"><span class="linenos">370</span></a>
</span><span id="test_fsw_embedding-371"><a href="#test_fsw_embedding-371"><span class="linenos">371</span></a>    <span class="kn">from</span><span class="w"> </span><span class="nn">torch.autograd</span><span class="w"> </span><span class="kn">import</span> <span class="n">gradcheck</span>
</span><span id="test_fsw_embedding-372"><a href="#test_fsw_embedding-372"><span class="linenos">372</span></a>
</span><span id="test_fsw_embedding-373"><a href="#test_fsw_embedding-373"><span class="linenos">373</span></a>    <span class="c1"># gradcheck takes a tuple of tensors as input, check if your gradient</span>
</span><span id="test_fsw_embedding-374"><a href="#test_fsw_embedding-374"><span class="linenos">374</span></a>    <span class="c1"># evaluated with these tensors are close enough to numerical</span>
</span><span id="test_fsw_embedding-375"><a href="#test_fsw_embedding-375"><span class="linenos">375</span></a>    <span class="c1"># approximations and returns True if they all verify this condition.</span>
</span><span id="test_fsw_embedding-376"><a href="#test_fsw_embedding-376"><span class="linenos">376</span></a>    <span class="nb">input</span> <span class="o">=</span> <span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">W1</span><span class="o">+</span><span class="mf">1e-5</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">graph_mode</span><span class="p">)</span>
</span><span id="test_fsw_embedding-377"><a href="#test_fsw_embedding-377"><span class="linenos">377</span></a>    <span class="n">test</span> <span class="o">=</span> <span class="n">gradcheck</span><span class="p">(</span><span class="n">embed</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
</span><span id="test_fsw_embedding-378"><a href="#test_fsw_embedding-378"><span class="linenos">378</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Gradcheck test result: &#39;</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
</span><span id="test_fsw_embedding-379"><a href="#test_fsw_embedding-379"><span class="linenos">379</span></a>
</span><span id="test_fsw_embedding-380"><a href="#test_fsw_embedding-380"><span class="linenos">380</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=========================================&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-381"><a href="#test_fsw_embedding-381"><span class="linenos">381</span></a>
</span><span id="test_fsw_embedding-382"><a href="#test_fsw_embedding-382"><span class="linenos">382</span></a>
</span><span id="test_fsw_embedding-383"><a href="#test_fsw_embedding-383"><span class="linenos">383</span></a>    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</span><span id="test_fsw_embedding-384"><a href="#test_fsw_embedding-384"><span class="linenos">384</span></a>    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
</span><span id="test_fsw_embedding-385"><a href="#test_fsw_embedding-385"><span class="linenos">385</span></a>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Name: &#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s1">&#39; Shape: &#39;</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="test_fsw_embedding-386"><a href="#test_fsw_embedding-386"><span class="linenos">386</span></a>
</span><span id="test_fsw_embedding-387"><a href="#test_fsw_embedding-387"><span class="linenos">387</span></a>    <span class="nb">print</span><span class="p">()</span>
</span><span id="test_fsw_embedding-388"><a href="#test_fsw_embedding-388"><span class="linenos">388</span></a>
</span><span id="test_fsw_embedding-389"><a href="#test_fsw_embedding-389"><span class="linenos">389</span></a>
</span><span id="test_fsw_embedding-390"><a href="#test_fsw_embedding-390"><span class="linenos">390</span></a>    <span class="n">exit</span><span class="p">()</span>
</span><span id="test_fsw_embedding-391"><a href="#test_fsw_embedding-391"><span class="linenos">391</span></a>
</span><span id="test_fsw_embedding-392"><a href="#test_fsw_embedding-392"><span class="linenos">392</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;=========================================&#39;</span><span class="p">)</span>
</span><span id="test_fsw_embedding-393"><a href="#test_fsw_embedding-393"><span class="linenos">393</span></a>
</span><span id="test_fsw_embedding-394"><a href="#test_fsw_embedding-394"><span class="linenos">394</span></a>
</span><span id="test_fsw_embedding-395"><a href="#test_fsw_embedding-395"><span class="linenos">395</span></a>
</span><span id="test_fsw_embedding-396"><a href="#test_fsw_embedding-396"><span class="linenos">396</span></a>    <span class="c1"># Stress-testing graph mode</span>
</span><span id="test_fsw_embedding-397"><a href="#test_fsw_embedding-397"><span class="linenos">397</span></a>
</span><span id="test_fsw_embedding-398"><a href="#test_fsw_embedding-398"><span class="linenos">398</span></a>
</span><span id="test_fsw_embedding-399"><a href="#test_fsw_embedding-399"><span class="linenos">399</span></a>    <span class="c1"># print(state_dict)</span>
</span><span id="test_fsw_embedding-400"><a href="#test_fsw_embedding-400"><span class="linenos">400</span></a>
</span><span id="test_fsw_embedding-401"><a href="#test_fsw_embedding-401"><span class="linenos">401</span></a>    <span class="c1"># print(&#39;slice_vectors shape: &#39;, state_dict[&#39;slice_vectors&#39;].shape)</span>
</span><span id="test_fsw_embedding-402"><a href="#test_fsw_embedding-402"><span class="linenos">402</span></a>    <span class="c1"># state_dict[&#39;slice_vectors&#39;][:] = 0</span>
</span><span id="test_fsw_embedding-403"><a href="#test_fsw_embedding-403"><span class="linenos">403</span></a>
</span><span id="test_fsw_embedding-404"><a href="#test_fsw_embedding-404"><span class="linenos">404</span></a>    <span class="n">bs</span> <span class="o">=</span> <span class="mi">20</span>
</span><span id="test_fsw_embedding-405"><a href="#test_fsw_embedding-405"><span class="linenos">405</span></a>    <span class="n">n</span> <span class="o">=</span> <span class="mi">3000</span>
</span><span id="test_fsw_embedding-406"><a href="#test_fsw_embedding-406"><span class="linenos">406</span></a>    <span class="n">deg</span> <span class="o">=</span> <span class="mi">20</span>
</span><span id="test_fsw_embedding-407"><a href="#test_fsw_embedding-407"><span class="linenos">407</span></a>    <span class="n">d</span> <span class="o">=</span> <span class="mi">64</span>
</span><span id="test_fsw_embedding-408"><a href="#test_fsw_embedding-408"><span class="linenos">408</span></a>    <span class="n">m</span> <span class="o">=</span> <span class="mi">64</span>
</span><span id="test_fsw_embedding-409"><a href="#test_fsw_embedding-409"><span class="linenos">409</span></a>
</span><span id="test_fsw_embedding-410"><a href="#test_fsw_embedding-410"><span class="linenos">410</span></a>    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-411"><a href="#test_fsw_embedding-411"><span class="linenos">411</span></a>
</span><span id="test_fsw_embedding-412"><a href="#test_fsw_embedding-412"><span class="linenos">412</span></a>    <span class="n">diags</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">deg</span><span class="p">,</span><span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</span><span id="test_fsw_embedding-413"><a href="#test_fsw_embedding-413"><span class="linenos">413</span></a>    <span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">deg</span><span class="p">))</span>
</span><span id="test_fsw_embedding-414"><a href="#test_fsw_embedding-414"><span class="linenos">414</span></a>    <span class="n">pattern</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">spdiags</span><span class="p">(</span><span class="n">diags</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-415"><a href="#test_fsw_embedding-415"><span class="linenos">415</span></a>
</span><span id="test_fsw_embedding-416"><a href="#test_fsw_embedding-416"><span class="linenos">416</span></a>    <span class="n">pattern</span> <span class="o">=</span> <span class="n">pattern</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="test_fsw_embedding-417"><a href="#test_fsw_embedding-417"><span class="linenos">417</span></a>    <span class="n">pattern</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">pattern</span><span class="p">,)</span><span class="o">*</span><span class="n">bs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span>
</span><span id="test_fsw_embedding-418"><a href="#test_fsw_embedding-418"><span class="linenos">418</span></a>    <span class="n">pattern</span><span class="o">.</span><span class="n">values</span><span class="p">()[:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">pattern</span><span class="o">.</span><span class="n">values</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-419"><a href="#test_fsw_embedding-419"><span class="linenos">419</span></a>
</span><span id="test_fsw_embedding-420"><a href="#test_fsw_embedding-420"><span class="linenos">420</span></a>    <span class="n">W</span> <span class="o">=</span> <span class="n">pattern</span>
</span><span id="test_fsw_embedding-421"><a href="#test_fsw_embedding-421"><span class="linenos">421</span></a>
</span><span id="test_fsw_embedding-422"><a href="#test_fsw_embedding-422"><span class="linenos">422</span></a>    <span class="n">X</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-423"><a href="#test_fsw_embedding-423"><span class="linenos">423</span></a>    <span class="n">W</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-424"><a href="#test_fsw_embedding-424"><span class="linenos">424</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">learnable_slices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">learnable_frequencies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-425"><a href="#test_fsw_embedding-425"><span class="linenos">425</span></a>
</span><span id="test_fsw_embedding-426"><a href="#test_fsw_embedding-426"><span class="linenos">426</span></a>    <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span><span id="test_fsw_embedding-427"><a href="#test_fsw_embedding-427"><span class="linenos">427</span></a>    <span class="n">emb</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">W</span><span class="p">,</span> <span class="n">graph_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_parallel_slices</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="test_fsw_embedding-428"><a href="#test_fsw_embedding-428"><span class="linenos">428</span></a>
</span><span id="test_fsw_embedding-429"><a href="#test_fsw_embedding-429"><span class="linenos">429</span></a>    <span class="n">S</span> <span class="o">=</span> <span class="n">emb</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
</span><span id="test_fsw_embedding-430"><a href="#test_fsw_embedding-430"><span class="linenos">430</span></a>    <span class="n">S</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="test_fsw_embedding-431"><a href="#test_fsw_embedding-431"><span class="linenos">431</span></a>    <span class="n">tElapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">t</span>
</span><span id="test_fsw_embedding-432"><a href="#test_fsw_embedding-432"><span class="linenos">432</span></a>
</span><span id="test_fsw_embedding-433"><a href="#test_fsw_embedding-433"><span class="linenos">433</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Grad X shape: &#39;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="test_fsw_embedding-434"><a href="#test_fsw_embedding-434"><span class="linenos">434</span></a>    <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">isnan</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="o">==</span> <span class="kc">False</span>
</span><span id="test_fsw_embedding-435"><a href="#test_fsw_embedding-435"><span class="linenos">435</span></a>
</span><span id="test_fsw_embedding-436"><a href="#test_fsw_embedding-436"><span class="linenos">436</span></a>
</span><span id="test_fsw_embedding-437"><a href="#test_fsw_embedding-437"><span class="linenos">437</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="si">%d</span><span class="s1"> graphs, each with </span><span class="si">%d</span><span class="s1"> nodes of degree </span><span class="si">%g</span><span class="s1">. Vertex feature dimension: </span><span class="si">%d</span><span class="s1">. Embedding dimension: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">deg</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>
</span><span id="test_fsw_embedding-438"><a href="#test_fsw_embedding-438"><span class="linenos">438</span></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Time elapsed: </span><span class="si">%g</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tElapsed</span><span class="p">))</span>
</span><span id="test_fsw_embedding-439"><a href="#test_fsw_embedding-439"><span class="linenos">439</span></a>
</span><span id="test_fsw_embedding-440"><a href="#test_fsw_embedding-440"><span class="linenos">440</span></a>    <span class="c1">########################################################</span>
</span><span id="test_fsw_embedding-441"><a href="#test_fsw_embedding-441"><span class="linenos">441</span></a>
</span><span id="test_fsw_embedding-442"><a href="#test_fsw_embedding-442"><span class="linenos">442</span></a>
</span><span id="test_fsw_embedding-443"><a href="#test_fsw_embedding-443"><span class="linenos">443</span></a>    <span class="c1">########################################################</span>
</span><span id="test_fsw_embedding-444"><a href="#test_fsw_embedding-444"><span class="linenos">444</span></a>    <span class="c1"># n = 1000</span>
</span><span id="test_fsw_embedding-445"><a href="#test_fsw_embedding-445"><span class="linenos">445</span></a>
</span><span id="test_fsw_embedding-446"><a href="#test_fsw_embedding-446"><span class="linenos">446</span></a>    <span class="c1"># W = torch.nn.functional.relu(torch.rand(size=(n,n), dtype=dtype)-0.2)</span>
</span><span id="test_fsw_embedding-447"><a href="#test_fsw_embedding-447"><span class="linenos">447</span></a>    <span class="c1"># W = W.to_sparse()</span>
</span><span id="test_fsw_embedding-448"><a href="#test_fsw_embedding-448"><span class="linenos">448</span></a>
</span><span id="test_fsw_embedding-449"><a href="#test_fsw_embedding-449"><span class="linenos">449</span></a>    <span class="c1"># S = sw_embedding.sparse_expand_as(W.sum(dim=-1).unsqueeze(-1), W)</span>
</span><span id="test_fsw_embedding-450"><a href="#test_fsw_embedding-450"><span class="linenos">450</span></a>    <span class="c1"># print(&#39;S shape: &#39;, S.shape)</span>
</span><span id="test_fsw_embedding-451"><a href="#test_fsw_embedding-451"><span class="linenos">451</span></a>
</span><span id="test_fsw_embedding-452"><a href="#test_fsw_embedding-452"><span class="linenos">452</span></a>    <span class="c1"># print(W.to_dense())</span>
</span><span id="test_fsw_embedding-453"><a href="#test_fsw_embedding-453"><span class="linenos">453</span></a>    <span class="c1"># print(&#39;W sum: &#39;, W.sum(dim=-1).to_dense())</span>
</span><span id="test_fsw_embedding-454"><a href="#test_fsw_embedding-454"><span class="linenos">454</span></a>    <span class="c1"># print(S.to_dense())</span>
</span><span id="test_fsw_embedding-455"><a href="#test_fsw_embedding-455"><span class="linenos">455</span></a>
</span><span id="test_fsw_embedding-456"><a href="#test_fsw_embedding-456"><span class="linenos">456</span></a>    <span class="c1"># print(&#39;W nnz: &#39;, len(W.values()) )</span>
</span><span id="test_fsw_embedding-457"><a href="#test_fsw_embedding-457"><span class="linenos">457</span></a>    <span class="c1"># print(&#39;S nnz: &#39;, len(S.values()) )</span>
</span><span id="test_fsw_embedding-458"><a href="#test_fsw_embedding-458"><span class="linenos">458</span></a>
</span><span id="test_fsw_embedding-459"><a href="#test_fsw_embedding-459"><span class="linenos">459</span></a>    <span class="c1"># W2 = sw_embedding.sparse_mul_expand(W, W.sum(dim=-1).unsqueeze(-1))</span>
</span><span id="test_fsw_embedding-460"><a href="#test_fsw_embedding-460"><span class="linenos">460</span></a>    <span class="c1"># print(&#39;W2 shape: &#39;, W2.shape)</span>
</span><span id="test_fsw_embedding-461"><a href="#test_fsw_embedding-461"><span class="linenos">461</span></a>    <span class="c1"># print(&#39;W2 error: &#39;, torch.norm( W2.to_dense() - W.to_dense() * W.to_dense().sum(dim=-1,keepdim=True) ))</span>
</span><span id="test_fsw_embedding-462"><a href="#test_fsw_embedding-462"><span class="linenos">462</span></a>
</span><span id="test_fsw_embedding-463"><a href="#test_fsw_embedding-463"><span class="linenos">463</span></a>    <span class="c1"># exit()</span>
</span><span id="test_fsw_embedding-464"><a href="#test_fsw_embedding-464"><span class="linenos">464</span></a>
</span><span id="test_fsw_embedding-465"><a href="#test_fsw_embedding-465"><span class="linenos">465</span></a>    <span class="c1"># W_orig = W.to_dense()</span>
</span><span id="test_fsw_embedding-466"><a href="#test_fsw_embedding-466"><span class="linenos">466</span></a>
</span><span id="test_fsw_embedding-467"><a href="#test_fsw_embedding-467"><span class="linenos">467</span></a>    <span class="c1"># W = W * ( W.sum(dim=-1).to_dense().unsqueeze(-1).reciprocal() )</span>
</span><span id="test_fsw_embedding-468"><a href="#test_fsw_embedding-468"><span class="linenos">468</span></a>    <span class="c1"># # Here W is sparse and normalied</span>
</span><span id="test_fsw_embedding-469"><a href="#test_fsw_embedding-469"><span class="linenos">469</span></a>
</span><span id="test_fsw_embedding-470"><a href="#test_fsw_embedding-470"><span class="linenos">470</span></a>    <span class="c1"># sums = -W.sum(dim=-1).unsqueeze(-1)</span>
</span><span id="test_fsw_embedding-471"><a href="#test_fsw_embedding-471"><span class="linenos">471</span></a>    <span class="c1"># W_walled = torch.cat((W, sums), dim=-1).coalesce()</span>
</span><span id="test_fsw_embedding-472"><a href="#test_fsw_embedding-472"><span class="linenos">472</span></a>
</span><span id="test_fsw_embedding-473"><a href="#test_fsw_embedding-473"><span class="linenos">473</span></a>    <span class="c1"># inds = W_walled.indices()</span>
</span><span id="test_fsw_embedding-474"><a href="#test_fsw_embedding-474"><span class="linenos">474</span></a>    <span class="c1"># vals = W_walled.values().cumsum(dim=0)</span>
</span><span id="test_fsw_embedding-475"><a href="#test_fsw_embedding-475"><span class="linenos">475</span></a>    <span class="c1"># subset = (inds[-1,:] &lt; n)</span>
</span><span id="test_fsw_embedding-476"><a href="#test_fsw_embedding-476"><span class="linenos">476</span></a>
</span><span id="test_fsw_embedding-477"><a href="#test_fsw_embedding-477"><span class="linenos">477</span></a>    <span class="c1"># W_sparse_cumsum = torch.sparse_coo_tensor(indices=inds[:,subset], values=vals[subset], size=W.shape)</span>
</span><span id="test_fsw_embedding-478"><a href="#test_fsw_embedding-478"><span class="linenos">478</span></a>
</span><span id="test_fsw_embedding-479"><a href="#test_fsw_embedding-479"><span class="linenos">479</span></a>    <span class="c1"># B = nn.functional.normalize(W_orig,dim=-1,p=1.0).cumsum(dim=-1)</span>
</span><span id="test_fsw_embedding-480"><a href="#test_fsw_embedding-480"><span class="linenos">480</span></a>    <span class="c1"># B[W.to_dense()==0] = 0</span>
</span><span id="test_fsw_embedding-481"><a href="#test_fsw_embedding-481"><span class="linenos">481</span></a>
</span><span id="test_fsw_embedding-482"><a href="#test_fsw_embedding-482"><span class="linenos">482</span></a>    <span class="c1"># print(&#39;Numerical error: &#39;, torch.norm(W_sparse_cumsum.to_dense()-B).item())</span>
</span><span id="test_fsw_embedding-483"><a href="#test_fsw_embedding-483"><span class="linenos">483</span></a>
</span><span id="test_fsw_embedding-484"><a href="#test_fsw_embedding-484"><span class="linenos">484</span></a>    <span class="c1">####################################################################</span>
</span><span id="test_fsw_embedding-485"><a href="#test_fsw_embedding-485"><span class="linenos">485</span></a>
</span><span id="test_fsw_embedding-486"><a href="#test_fsw_embedding-486"><span class="linenos">486</span></a>
</span><span id="test_fsw_embedding-487"><a href="#test_fsw_embedding-487"><span class="linenos">487</span></a>
</span><span id="test_fsw_embedding-488"><a href="#test_fsw_embedding-488"><span class="linenos">488</span></a>
</span><span id="test_fsw_embedding-489"><a href="#test_fsw_embedding-489"><span class="linenos">489</span></a>    <span class="n">X1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">d</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="test_fsw_embedding-490"><a href="#test_fsw_embedding-490"><span class="linenos">490</span></a>    <span class="n">W1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">-</span><span class="mf">0.2</span><span class="p">)</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
</span><span id="test_fsw_embedding-491"><a href="#test_fsw_embedding-491"><span class="linenos">491</span></a>
</span><span id="test_fsw_embedding-492"><a href="#test_fsw_embedding-492"><span class="linenos">492</span></a>    <span class="k">if</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="test_fsw_embedding-493"><a href="#test_fsw_embedding-493"><span class="linenos">493</span></a>        <span class="n">X1</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-494"><a href="#test_fsw_embedding-494"><span class="linenos">494</span></a>        <span class="n">X2</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-495"><a href="#test_fsw_embedding-495"><span class="linenos">495</span></a>
</span><span id="test_fsw_embedding-496"><a href="#test_fsw_embedding-496"><span class="linenos">496</span></a>        <span class="n">W1</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-497"><a href="#test_fsw_embedding-497"><span class="linenos">497</span></a>        <span class="n">W2</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="test_fsw_embedding-498"><a href="#test_fsw_embedding-498"><span class="linenos">498</span></a>
</span><span id="test_fsw_embedding-499"><a href="#test_fsw_embedding-499"><span class="linenos">499</span></a>    <span class="n">embed</span> <span class="o">=</span> <span class="n">FSWEmbedding</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">learnable_frequencies</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">learnable_slices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="test_fsw_embedding-500"><a href="#test_fsw_embedding-500"><span class="linenos">500</span></a>    <span class="n">E</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">W1</span><span class="p">)</span>
</span></pre></div>


    

                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>